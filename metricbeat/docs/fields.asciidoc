
////
This file is generated! See _meta/fields.yml and scripts/generate_fields_docs.py
////

[[exported-fields]]
= Exported fields

[partintro]

--
This document describes the fields that are exported by Metricbeat. They are
grouped in the following categories:

* <<exported-fields-aerospike>>
* <<exported-fields-apache>>
* <<exported-fields-aws>>
* <<exported-fields-beat-common>>
* <<exported-fields-beat>>
* <<exported-fields-ceph>>
* <<exported-fields-cloud>>
* <<exported-fields-cockroachdb>>
* <<exported-fields-common>>
* <<exported-fields-consul>>
* <<exported-fields-coredns>>
* <<exported-fields-couchbase>>
* <<exported-fields-couchdb>>
* <<exported-fields-docker-processor>>
* <<exported-fields-docker>>
* <<exported-fields-dropwizard>>
* <<exported-fields-ecs>>
* <<exported-fields-elasticsearch>>
* <<exported-fields-envoyproxy>>
* <<exported-fields-etcd>>
* <<exported-fields-golang>>
* <<exported-fields-graphite>>
* <<exported-fields-haproxy>>
* <<exported-fields-host-processor>>
* <<exported-fields-http>>
* <<exported-fields-jolokia>>
* <<exported-fields-jolokia-autodiscover>>
* <<exported-fields-kafka>>
* <<exported-fields-kibana>>
* <<exported-fields-kubernetes-processor>>
* <<exported-fields-kubernetes>>
* <<exported-fields-kvm>>
* <<exported-fields-logstash>>
* <<exported-fields-memcached>>
* <<exported-fields-mongodb>>
* <<exported-fields-mssql>>
* <<exported-fields-munin>>
* <<exported-fields-mysql>>
* <<exported-fields-nats>>
* <<exported-fields-nginx>>
* <<exported-fields-oracle>>
* <<exported-fields-php_fpm>>
* <<exported-fields-postgresql>>
* <<exported-fields-process>>
* <<exported-fields-prometheus>>
* <<exported-fields-rabbitmq>>
* <<exported-fields-redis>>
* <<exported-fields-statsd>>
* <<exported-fields-system>>
* <<exported-fields-traefik>>
* <<exported-fields-uwsgi>>
* <<exported-fields-vsphere>>
* <<exported-fields-windows>>
* <<exported-fields-zookeeper>>

--
[[exported-fields-aerospike]]
== Aerospike fields

Aerospike module



[float]
=== aerospike




[float]
=== namespace

namespace



[float]
=== client

Client stats.



[float]
=== delete

Client delete transactions stats.



*`aerospike.namespace.client.delete.error`*::
+
--
Number of client delete transactions that failed with an error.


type: long

--

*`aerospike.namespace.client.delete.not_found`*::
+
--
Number of client delete transactions that resulted in a not found.


type: long

--

*`aerospike.namespace.client.delete.success`*::
+
--
Number of successful client delete transactions.


type: long

--

*`aerospike.namespace.client.delete.timeout`*::
+
--
Number of client delete transactions that timed out.


type: long

--

[float]
=== read

Client read transactions stats.



*`aerospike.namespace.client.read.error`*::
+
--
Number of client read transaction errors.


type: long

--

*`aerospike.namespace.client.read.not_found`*::
+
--
Number of client read transaction that resulted in not found.


type: long

--

*`aerospike.namespace.client.read.success`*::
+
--
Number of successful client read transactions.


type: long

--

*`aerospike.namespace.client.read.timeout`*::
+
--
Number of client read transaction that timed out.


type: long

--

[float]
=== write

Client write transactions stats.



*`aerospike.namespace.client.write.error`*::
+
--
Number of client write transactions that failed with an error.


type: long

--

*`aerospike.namespace.client.write.success`*::
+
--
Number of successful client write transactions.


type: long

--

*`aerospike.namespace.client.write.timeout`*::
+
--
Number of client write transactions that timed out.


type: long

--

[float]
=== device

Disk storage stats



*`aerospike.namespace.device.available.pct`*::
+
--
Measures the minimum contiguous disk space across all disks in a namespace.


type: scaled_float

format: percent

--

*`aerospike.namespace.device.free.pct`*::
+
--
Percentage of disk capacity free for this namespace.


type: scaled_float

format: percent

--

*`aerospike.namespace.device.total.bytes`*::
+
--
Total bytes of disk space allocated to this namespace on this node.


type: long

format: bytes

--

*`aerospike.namespace.device.used.bytes`*::
+
--
Total bytes of disk space used by this namespace on this node.


type: long

format: bytes

--

*`aerospike.namespace.hwm_breached`*::
+
--
If true, Aerospike has breached 'high-water-[disk|memory]-pct' for this namespace.


type: boolean

--

[float]
=== memory

Memory storage stats.



*`aerospike.namespace.memory.free.pct`*::
+
--
Percentage of memory capacity free for this namespace on this node.


type: scaled_float

format: percent

--

*`aerospike.namespace.memory.used.data.bytes`*::
+
--
Amount of memory occupied by data for this namespace on this node.


type: long

format: bytes

--

*`aerospike.namespace.memory.used.index.bytes`*::
+
--
Amount of memory occupied by the index for this namespace on this node.


type: long

format: bytes

--

*`aerospike.namespace.memory.used.sindex.bytes`*::
+
--
Amount of memory occupied by secondary indexes for this namespace on this node.


type: long

format: bytes

--

*`aerospike.namespace.memory.used.total.bytes`*::
+
--
Total bytes of memory used by this namespace on this node.


type: long

format: bytes

--

*`aerospike.namespace.name`*::
+
--
Namespace name


type: keyword

--

*`aerospike.namespace.node.host`*::
+
--
Node host


type: keyword

--

*`aerospike.namespace.node.name`*::
+
--
Node name


type: keyword

--

[float]
=== objects

Records stats.



*`aerospike.namespace.objects.master`*::
+
--
Number of records on this node which are active masters.


type: long

--

*`aerospike.namespace.objects.total`*::
+
--
Number of records in this namespace for this node.


type: long

--

*`aerospike.namespace.stop_writes`*::
+
--
If true this namespace is currently not allowing writes.


type: boolean

--

[[exported-fields-apache]]
== Apache fields

Apache HTTPD server metricsets collected from the Apache web server.



[float]
=== apache

`apache` contains the metrics that were scraped from Apache.



[float]
=== status

`status` contains the metrics that were scraped from the Apache status page.



*`apache.status.hostname`*::
+
--
Apache hostname.


type: keyword

--

*`apache.status.total_accesses`*::
+
--
Total number of access requests.


type: long

--

*`apache.status.total_kbytes`*::
+
--
Total number of kilobytes served.


type: long

--

*`apache.status.requests_per_sec`*::
+
--
Requests per second.


type: scaled_float

--

*`apache.status.bytes_per_sec`*::
+
--
Bytes per second.


type: scaled_float

--

*`apache.status.bytes_per_request`*::
+
--
Bytes per request.


type: scaled_float

--

*`apache.status.workers.busy`*::
+
--
Number of busy workers.


type: long

--

*`apache.status.workers.idle`*::
+
--
Number of idle workers.


type: long

--

[float]
=== uptime

Uptime stats.



*`apache.status.uptime.server_uptime`*::
+
--
Server uptime in seconds.


type: long

--

*`apache.status.uptime.uptime`*::
+
--
Server uptime.


type: long

--

[float]
=== cpu

CPU stats.



*`apache.status.cpu.load`*::
+
--
CPU Load.


type: scaled_float

--

*`apache.status.cpu.user`*::
+
--
CPU user load.


type: scaled_float

--

*`apache.status.cpu.system`*::
+
--
System cpu.


type: scaled_float

--

*`apache.status.cpu.children_user`*::
+
--
CPU of children user.


type: scaled_float

--

*`apache.status.cpu.children_system`*::
+
--
CPU of children system.


type: scaled_float

--

[float]
=== connections

Connection stats.



*`apache.status.connections.total`*::
+
--
Total connections.


type: long

--

*`apache.status.connections.async.writing`*::
+
--
Async connection writing.


type: long

--

*`apache.status.connections.async.keep_alive`*::
+
--
Async keeped alive connections.


type: long

--

*`apache.status.connections.async.closing`*::
+
--
Async closed connections.


type: long

--

[float]
=== load

Load averages.



*`apache.status.load.1`*::
+
--
Load average for the last minute.


type: scaled_float

--

*`apache.status.load.5`*::
+
--
Load average for the last 5 minutes.


type: scaled_float

--

*`apache.status.load.15`*::
+
--
Load average for the last 15 minutes.


type: scaled_float

--

[float]
=== scoreboard

Scoreboard metrics.



*`apache.status.scoreboard.starting_up`*::
+
--
Starting up.


type: long

--

*`apache.status.scoreboard.reading_request`*::
+
--
Reading requests.


type: long

--

*`apache.status.scoreboard.sending_reply`*::
+
--
Sending Reply.


type: long

--

*`apache.status.scoreboard.keepalive`*::
+
--
Keep alive.


type: long

--

*`apache.status.scoreboard.dns_lookup`*::
+
--
Dns Lookups.


type: long

--

*`apache.status.scoreboard.closing_connection`*::
+
--
Closing connections.


type: long

--

*`apache.status.scoreboard.logging`*::
+
--
Logging


type: long

--

*`apache.status.scoreboard.gracefully_finishing`*::
+
--
Gracefully finishing.


type: long

--

*`apache.status.scoreboard.idle_cleanup`*::
+
--
Idle cleanups.


type: long

--

*`apache.status.scoreboard.open_slot`*::
+
--
Open slots.


type: long

--

*`apache.status.scoreboard.waiting_for_connection`*::
+
--
Waiting for connections.


type: long

--

*`apache.status.scoreboard.total`*::
+
--
Total.


type: long

--

[[exported-fields-aws]]
== aws fields

`aws` module collects AWS monitoring metrics from AWS Cloudwatch.



[float]
=== aws
<<<<<<< HEAD
=======

>>>>>>> upstream/master



*`aws.tags.*`*::
+
--
Tag key value pairs from aws resources.


type: object

--

[float]
=== cloudwatch

`cloudwatch` contains the metrics that were scraped from AWS CloudWatch which contains monitoring metrics sent by different namespaces.



*`aws.cloudwatch.namespace`*::
+
--
The namespace specified when query cloudwatch api.


type: keyword

--

*`aws.cloudwatch.metrics.*.*`*::
+
--
Metrics that returned from Cloudwatch api query.


type: object

--

*`aws.cloudwatch.dimensions.*`*::
+
--
Cloudwatch metric dimensions.


type: object

--

[float]
<<<<<<< HEAD
=======
=== ebs

`ebs` contains the metrics that were scraped from AWS CloudWatch which contains monitoring metrics sent by AWS EBS.


[float]
>>>>>>> upstream/master
=== ec2

`ec2` contains the metrics that were scraped from AWS CloudWatch which contains monitoring metrics sent by AWS EC2.



*`aws.ec2.cpu.total.pct`*::
+
--
The percentage of allocated EC2 compute units that are currently in use on the instance.


type: scaled_float

--

*`aws.ec2.cpu.credit_usage`*::
+
--
The number of CPU credits spent by the instance for CPU utilization.


type: long

--

*`aws.ec2.cpu.credit_balance`*::
+
--
The number of earned CPU credits that an instance has accrued since it was launched or started.


type: long

--

*`aws.ec2.cpu.surplus_credit_balance`*::
+
--
The number of surplus credits that have been spent by an unlimited instance when its CPUCreditBalance value is zero.


type: long

--

*`aws.ec2.cpu.surplus_credits_charged`*::
+
--
The number of spent surplus credits that are not paid down by earned CPU credits, and which thus incur an additional charge.


type: long

--

*`aws.ec2.network.in.packets`*::
+
--
The number of packets received on all network interfaces by the instance.


type: long

--

*`aws.ec2.network.in.packets_per_sec`*::
+
--
<<<<<<< HEAD
=======
The number of packets per second sent out on all network interfaces by the instance.


type: long

--

*`aws.ec2.network.out.packets`*::
+
--
>>>>>>> upstream/master
The number of packets sent out on all network interfaces by the instance.


type: long

--

*`aws.ec2.network.out.packets_per_sec`*::
+
--
<<<<<<< HEAD
=======
The number of packets per second sent out on all network interfaces by the instance.


type: long

--

*`aws.ec2.network.in.bytes`*::
+
--
>>>>>>> upstream/master
The number of bytes received on all network interfaces by the instance.


type: long

format: bytes

--

*`aws.ec2.network.in.bytes_per_sec`*::
+
--
<<<<<<< HEAD
=======
The number of bytes per second received on all network interfaces by the instance.


type: long

--

*`aws.ec2.network.out.bytes`*::
+
--
>>>>>>> upstream/master
The number of bytes sent out on all network interfaces by the instance.


type: long

format: bytes

--

*`aws.ec2.network.out.bytes_per_sec`*::
+
--
<<<<<<< HEAD
=======
The number of bytes per second sent out on all network interfaces by the instance.


type: long

--

*`aws.ec2.diskio.read.bytes`*::
+
--
>>>>>>> upstream/master
Bytes read from all instance store volumes available to the instance.


type: long

format: bytes

--

*`aws.ec2.diskio.read.bytes_per_sec`*::
+
--
<<<<<<< HEAD
=======
Bytes read per second from all instance store volumes available to the instance.


type: long

--

*`aws.ec2.diskio.write.bytes`*::
+
--
>>>>>>> upstream/master
Bytes written to all instance store volumes available to the instance.


type: long

format: bytes

--

*`aws.ec2.diskio.write.bytes_per_sec`*::
+
--
<<<<<<< HEAD
=======
Bytes written per second to all instance store volumes available to the instance.


type: long

--

*`aws.ec2.diskio.read.ops`*::
+
--
>>>>>>> upstream/master
Completed read operations from all instance store volumes available to the instance in a specified period of time.


type: long

--

*`aws.ec2.diskio.read.ops_per_sec`*::
+
--
<<<<<<< HEAD
=======
Completed read operations per second from all instance store volumes available to the instance in a specified period of time.


type: long

--

*`aws.ec2.diskio.write.ops`*::
+
--
>>>>>>> upstream/master
Completed write operations to all instance store volumes available to the instance in a specified period of time.


type: long

--

*`aws.ec2.diskio.write.ops_per_sec`*::
+
--
<<<<<<< HEAD
=======
Completed write operations per second to all instance store volumes available to the instance in a specified period of time.


type: long

--

*`aws.ec2.status.check_failed`*::
+
--
>>>>>>> upstream/master
Reports whether the instance has passed both the instance status check and the system status check in the last minute.


type: long

--

*`aws.ec2.status.check_failed_system`*::
+
--
Reports whether the instance has passed the system status check in the last minute.


type: long

--

*`aws.ec2.status.check_failed_instance`*::
+
--
Reports whether the instance has passed the instance status check in the last minute.


type: long

--

*`aws.ec2.instance.core.count`*::
+
--
The number of CPU cores for the instance.


type: integer

--

*`aws.ec2.instance.image.id`*::
+
--
The ID of the image used to launch the instance.


type: keyword

--

*`aws.ec2.instance.monitoring.state`*::
+
--
Indicates whether detailed monitoring is enabled.


type: keyword

--

*`aws.ec2.instance.private.dns_name`*::
+
--
The private DNS name of the network interface.


type: keyword

--

*`aws.ec2.instance.private.ip`*::
+
--
The private IPv4 address associated with the network interface.


type: ip

--

*`aws.ec2.instance.public.dns_name`*::
+
--
The public DNS name of the instance.


type: keyword

--

*`aws.ec2.instance.public.ip`*::
+
--
The address of the Elastic IP address (IPv4) bound to the network interface.


type: ip

--

*`aws.ec2.instance.state.code`*::
+
--
The state of the instance, as a 16-bit unsigned integer.


type: integer

--

*`aws.ec2.instance.state.name`*::
+
--
The state of the instance (pending | running | shutting-down | terminated | stopping | stopped).


type: keyword

--

*`aws.ec2.instance.threads_per_core`*::
+
--
The number of threads per CPU core.


type: integer

--

[float]
<<<<<<< HEAD
=== s3_daily_storage
=======
=== elb
>>>>>>> upstream/master

`elb` contains the metrics that were scraped from AWS CloudWatch which contains monitoring metrics sent by AWS ELB.


[float]
=== rds

`rds` contains the metrics that were scraped from AWS CloudWatch which contains monitoring metrics sent by AWS RDS.



*`aws.rds.cpu.total.pct`*::
+
--
<<<<<<< HEAD
Name of a S3 bucket.
=======
The percentage of CPU utilization.

>>>>>>> upstream/master

type: scaled_float

format: percent

type: keyword

--

*`aws.rds.cpu.credit_usage`*::
+
--
<<<<<<< HEAD
The amount of data in bytes stored in a bucket.
=======
The number of CPU credits spent by the instance for CPU utilization.

>>>>>>> upstream/master

type: long

type: long

format: bytes

--

*`aws.rds.cpu.credit_balance`*::
+
--
<<<<<<< HEAD
The total number of objects stored in a bucket for all storage classes.
=======
The number of earned CPU credits that an instance has accrued since it was launched or started.

>>>>>>> upstream/master

type: long

type: long

--

<<<<<<< HEAD
[float]
=== s3_request
=======
*`aws.rds.database_connections`*::
+
--
The number of database connections in use.
>>>>>>> upstream/master


type: long

--

*`aws.rds.db_instance.arn`*::
+
--
<<<<<<< HEAD
Name of a S3 bucket.
=======
Amazon Resource Name(ARN) for each rds.

>>>>>>> upstream/master

type: keyword

type: keyword

--

*`aws.rds.db_instance.class`*::
+
--
<<<<<<< HEAD
The total number of HTTP requests made to an Amazon S3 bucket, regardless of type.
=======
Contains the name of the compute and memory capacity class of the DB instance.

>>>>>>> upstream/master

type: keyword

type: long

--

*`aws.rds.db_instance.identifier`*::
+
--
<<<<<<< HEAD
The number of HTTP GET requests made for objects in an Amazon S3 bucket.
=======
Contains a user-supplied database identifier. This identifier is the unique key that identifies a DB instance.

>>>>>>> upstream/master

type: keyword

type: long

--

*`aws.rds.db_instance.status`*::
+
--
<<<<<<< HEAD
The number of HTTP PUT requests made for objects in an Amazon S3 bucket.
=======
Specifies the current state of this database.

>>>>>>> upstream/master

type: keyword

type: long

--

*`aws.rds.disk_queue_depth`*::
+
--
<<<<<<< HEAD
The number of HTTP DELETE requests made for objects in an Amazon S3 bucket.
=======
The number of outstanding IOs (read/write requests) waiting to access the disk.

>>>>>>> upstream/master

type: long

type: long

--

*`aws.rds.failed_sql_server_agent_jobs`*::
+
--
<<<<<<< HEAD
The number of HTTP HEAD requests made to an Amazon S3 bucket.
=======
The number of failed SQL Server Agent jobs during the last minute.

>>>>>>> upstream/master

type: long

type: long

--

*`aws.rds.freeable_memory.bytes`*::
+
--
<<<<<<< HEAD
The number of HTTP POST requests made to an Amazon S3 bucket.
=======
The amount of available random access memory.

>>>>>>> upstream/master

type: long

format: bytes

type: long

--

*`aws.rds.free_storage.bytes`*::
+
--
<<<<<<< HEAD
The number of Amazon S3 SELECT Object Content requests made for objects in an Amazon S3 bucket.
=======
The amount of available storage space.

>>>>>>> upstream/master

type: long

format: bytes

type: long

--

*`aws.rds.maximum_used_transaction_ids`*::
+
--
<<<<<<< HEAD
The number of bytes of data scanned with Amazon S3 SELECT Object Content requests in an Amazon S3 bucket.
=======
The maximum transaction ID that has been used. Applies to PostgreSQL.

>>>>>>> upstream/master

type: long

type: long

format: bytes

--

*`aws.rds.oldest_replication_slot_lag.mb`*::
+
--
<<<<<<< HEAD
The number of bytes of data returned with Amazon S3 SELECT Object Content requests in an Amazon S3 bucket.
=======
The lagging size of the replica lagging the most in terms of WAL data received. Applies to PostgreSQL.

>>>>>>> upstream/master

type: long

type: long

format: bytes

--

*`aws.rds.read_io.ops_per_sec`*::
+
--
<<<<<<< HEAD
The number of HTTP requests that list the contents of a bucket.
=======
The average number of disk read I/O operations per second.

>>>>>>> upstream/master

type: float

type: long

--

*`aws.rds.replica_lag.sec`*::
+
--
<<<<<<< HEAD
The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body.
=======
The amount of time a Read Replica DB instance lags behind the source DB instance. Applies to MySQL, MariaDB, and PostgreSQL Read Replicas.

>>>>>>> upstream/master

type: long

format: duration

type: long

format: bytes

--

*`aws.rds.swap_usage.bytes`*::
+
--
<<<<<<< HEAD
The number bytes uploaded that contain a request body, made to an Amazon S3 bucket.
=======
The amount of swap space used on the DB instance. This metric is not available for SQL Server.

>>>>>>> upstream/master

type: long

format: bytes

type: long

format: bytes

--

*`aws.rds.transaction_logs_generation`*::
+
--
<<<<<<< HEAD
The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1.
=======
The disk space used by transaction logs. Applies to PostgreSQL.

>>>>>>> upstream/master

type: long

type: long

--

*`aws.rds.write_io.ops_per_sec`*::
+
--
<<<<<<< HEAD
The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1.
=======
The average number of disk write I/O operations per second.

>>>>>>> upstream/master

type: float

type: long

--

*`aws.rds.queries`*::
+
--
<<<<<<< HEAD
The per-request time from the complete request being received by an Amazon S3 bucket to when the response starts to be returned.
=======
The average number of queries executed per second.

>>>>>>> upstream/master

type: long

type: long

format: duration

--

*`aws.rds.deadlocks`*::
+
--
<<<<<<< HEAD
The elapsed per-request time from the first byte received to the last byte sent to an Amazon S3 bucket.
=======
The average number of deadlocks in the database per second.

>>>>>>> upstream/master

type: long

type: long

format: duration

--

<<<<<<< HEAD
[float]
=== sqs

`sqs` contains the metrics that were scraped from AWS CloudWatch which contains monitoring metrics sent by AWS SQS.



*`aws.sqs.oldest_message_age.sec`*::
+
--
The approximate age of the oldest non-deleted message in the queue.
=======
*`aws.rds.volume_used.bytes`*::
+
--
The amount of storage used by your Aurora DB instance, in bytes.

>>>>>>> upstream/master

type: long

format: bytes

type: long

format: duration

--

*`aws.rds.free_local_storage.bytes`*::
+
--
<<<<<<< HEAD
TThe number of messages in the queue that are delayed and not available for reading immediately.
=======
The amount of storage available for temporary tables and logs, in bytes.

>>>>>>> upstream/master

type: long

format: bytes

type: long

--

*`aws.rds.login_failures`*::
+
--
<<<<<<< HEAD
The number of messages that are in flight.
=======
The average number of failed login attempts per second.

>>>>>>> upstream/master

type: long

type: long

--

*`aws.rds.throughput.commit`*::
+
--
<<<<<<< HEAD
The number of messages available for retrieval from the queue.
=======
The average number of commit operations per second.

>>>>>>> upstream/master

type: long

type: long

--

*`aws.rds.throughput.delete`*::
+
--
<<<<<<< HEAD
The number of messages deleted from the queue.
=======
The average number of delete queries per second.

>>>>>>> upstream/master

type: long

type: long

--

*`aws.rds.throughput.ddl`*::
+
--
<<<<<<< HEAD
The number of messages returned by calls to the ReceiveMessage action.
=======
The average number of DDL requests per second.

>>>>>>> upstream/master

type: long

type: long

--

*`aws.rds.throughput.dml`*::
+
--
<<<<<<< HEAD
The number of messages added to a queue.
=======
The average number of inserts, updates, and deletes per second.

>>>>>>> upstream/master

type: long

type: long

--

*`aws.rds.throughput.insert`*::
+
--
<<<<<<< HEAD
The number of ReceiveMessage API calls that did not return a message.
=======
The average number of insert queries per second.

>>>>>>> upstream/master

type: long

type: long

--

*`aws.rds.throughput.network`*::
+
--
<<<<<<< HEAD
The size of messages added to a queue.


type: long

format: bytes
=======
The amount of network throughput both received from and transmitted to clients by each instance in the Aurora MySQL DB cluster, in bytes per second.


type: long
>>>>>>> upstream/master

--

*`aws.rds.throughput.network_receive`*::
+
--
<<<<<<< HEAD
SQS queue name
=======
The incoming (Receive) network traffic on the DB instance, including both customer database traffic and Amazon RDS traffic used for monitoring and replication.

>>>>>>> upstream/master

type: long

type: keyword

--

*`aws.rds.throughput.network_transmit`*::
+
--
<<<<<<< HEAD
Hostname of the agent.
=======
The outgoing (Transmit) network traffic on the DB instance, including both customer database traffic and Amazon RDS traffic used for monitoring and replication.


type: long
>>>>>>> upstream/master

type: keyword

--

*`aws.rds.throughput.read`*::
+
--
The average amount of time taken per disk I/O operation.


type: long

--

*`aws.rds.throughput.select`*::
+
--
<<<<<<< HEAD
Contains user configurable fields.
=======
The average number of select queries per second.

>>>>>>> upstream/master

type: long

type: object

--

<<<<<<< HEAD
[float]
=== error
=======
*`aws.rds.throughput.update`*::
+
--
The average number of update queries per second.
>>>>>>> upstream/master


type: long

--

*`aws.rds.throughput.write`*::
+
--
<<<<<<< HEAD
Error type.
=======
The average number of bytes written to disk per second.

>>>>>>> upstream/master

type: long

type: keyword

--

*`aws.rds.latency.commit`*::
+
--
The amount of latency for commit operations, in milliseconds.


type: long

format: duration

--

*`aws.rds.latency.ddl`*::
+
--
The amount of latency for data definition language (DDL) requests, in milliseconds.


type: long

format: duration

--

*`aws.rds.latency.dml`*::
+
--
<<<<<<< HEAD
Time series instance id

type: keyword

--
=======
The amount of latency for inserts, updates, and deletes, in milliseconds.


type: long
>>>>>>> upstream/master

format: duration

--

*`aws.rds.latency.insert`*::
+
--
The amount of latency for insert queries, in milliseconds.


<<<<<<< HEAD
[float]
=== ceph
=======
type: long
>>>>>>> upstream/master

format: duration

--

*`aws.rds.latency.read`*::
+
--
The average amount of time taken per disk I/O operation.

<<<<<<< HEAD
[float]
=== cluster_disk
=======
>>>>>>> upstream/master

type: long

format: duration

--

*`aws.rds.latency.select`*::
+
--
<<<<<<< HEAD
Available bytes of the cluster
=======
The amount of latency for select queries, in milliseconds.
>>>>>>> upstream/master


type: long

<<<<<<< HEAD
format: bytes
=======
format: duration
>>>>>>> upstream/master

--

*`aws.rds.latency.update`*::
+
--
<<<<<<< HEAD
Total bytes of the cluster
=======
The amount of latency for update queries, in milliseconds.
>>>>>>> upstream/master


type: long

<<<<<<< HEAD
format: bytes
=======
format: duration
>>>>>>> upstream/master

--

*`aws.rds.latency.write`*::
+
--
<<<<<<< HEAD
Used bytes of the cluster
=======
The average amount of time taken per disk I/O operation.
>>>>>>> upstream/master


type: long

<<<<<<< HEAD
format: bytes

--

[float]
=== cluster_health
=======
format: duration

--

*`aws.rds.disk_usage.bin_log.bytes`*::
+
--
The amount of disk space occupied by binary logs on the master. Applies to MySQL read replicas.
>>>>>>> upstream/master


type: long

format: bytes

--

*`aws.rds.disk_usage.replication_slot.mb`*::
+
--
<<<<<<< HEAD
Overall status of the cluster
=======
The disk space used by replication slot files. Applies to PostgreSQL.

>>>>>>> upstream/master

type: long

type: keyword

--

*`aws.rds.disk_usage.transaction_logs.mb`*::
+
--
<<<<<<< HEAD
Map version
=======
The disk space used by transaction logs. Applies to PostgreSQL.

>>>>>>> upstream/master

type: long

type: long

--

*`aws.rds.transactions.active`*::
+
--
<<<<<<< HEAD
timecheck round
=======
The average number of current transactions executing on an Aurora database instance per second.

>>>>>>> upstream/master

type: long

type: long

--

*`aws.rds.transactions.blocked`*::
+
--
<<<<<<< HEAD
Status of the round
=======
The average number of transactions in the database that are blocked per second.

>>>>>>> upstream/master

type: long

type: keyword

--

[float]
<<<<<<< HEAD
=== cluster_status
=======
=== s3_daily_storage
>>>>>>> upstream/master

`s3_daily_storage` contains the daily storage metrics that were scraped from AWS CloudWatch which contains monitoring metrics sent by AWS S3.



*`aws.s3_daily_storage.bucket.name`*::
+
--
<<<<<<< HEAD
Ceph Status version
=======
Name of a S3 bucket.

>>>>>>> upstream/master

type: keyword

type: long

--

*`aws.s3_daily_storage.bucket.size.bytes`*::
+
--
<<<<<<< HEAD
Cluster read throughput per second
=======
The amount of data in bytes stored in a bucket.
>>>>>>> upstream/master


type: long

format: bytes

--

*`aws.s3_daily_storage.number_of_objects`*::
+
--
<<<<<<< HEAD
Cluster write throughput per second


type: long

format: bytes
=======
The total number of objects stored in a bucket for all storage classes.


type: long

--

[float]
=== s3_request

`s3_request` contains request metrics that were scraped from AWS CloudWatch which contains monitoring metrics sent by AWS S3.
>>>>>>> upstream/master



*`aws.s3_request.bucket.name`*::
+
--
<<<<<<< HEAD
Cluster read iops per second
=======
Name of a S3 bucket.

>>>>>>> upstream/master

type: keyword

type: long

--

*`aws.s3_request.requests.total`*::
+
--
<<<<<<< HEAD
Cluster write iops per second
=======
The total number of HTTP requests made to an Amazon S3 bucket, regardless of type.

>>>>>>> upstream/master

type: long

type: long

--

*`aws.s3_request.requests.get`*::
+
--
<<<<<<< HEAD
Cluster misplace pg number
=======
The number of HTTP GET requests made for objects in an Amazon S3 bucket.

>>>>>>> upstream/master

type: long

type: long

--

*`aws.s3_request.requests.put`*::
+
--
<<<<<<< HEAD
Cluster misplace objects number
=======
The number of HTTP PUT requests made for objects in an Amazon S3 bucket.

>>>>>>> upstream/master

type: long

type: long

--

*`aws.s3_request.requests.delete`*::
+
--
<<<<<<< HEAD
Cluster misplace ratio


type: scaled_float

format: percent
=======
The number of HTTP DELETE requests made for objects in an Amazon S3 bucket.


type: long
>>>>>>> upstream/master

--

*`aws.s3_request.requests.head`*::
+
--
<<<<<<< HEAD
Cluster degraded pg number
=======
The number of HTTP HEAD requests made to an Amazon S3 bucket.

>>>>>>> upstream/master

type: long

type: long

--

*`aws.s3_request.requests.post`*::
+
--
<<<<<<< HEAD
Cluster degraded objects number
=======
The number of HTTP POST requests made to an Amazon S3 bucket.

>>>>>>> upstream/master

type: long

type: long

--

*`aws.s3_request.requests.select`*::
+
--
<<<<<<< HEAD
Cluster degraded ratio


type: scaled_float

format: percent
=======
The number of Amazon S3 SELECT Object Content requests made for objects in an Amazon S3 bucket.


type: long
>>>>>>> upstream/master

--

*`aws.s3_request.requests.select_scanned.bytes`*::
+
--
<<<<<<< HEAD
Cluster pg data bytes
=======
The number of bytes of data scanned with Amazon S3 SELECT Object Content requests in an Amazon S3 bucket.
>>>>>>> upstream/master


type: long

format: bytes

--

*`aws.s3_request.requests.select_returned.bytes`*::
+
--
<<<<<<< HEAD
Cluster available bytes
=======
The number of bytes of data returned with Amazon S3 SELECT Object Content requests in an Amazon S3 bucket.
>>>>>>> upstream/master


type: long

format: bytes

--

*`aws.s3_request.requests.list`*::
+
--
<<<<<<< HEAD
Cluster total bytes


type: long

format: bytes
=======
The number of HTTP requests that list the contents of a bucket.


type: long
>>>>>>> upstream/master

--

*`aws.s3_request.downloaded.bytes`*::
+
--
<<<<<<< HEAD
Cluster used bytes
=======
The number bytes downloaded for requests made to an Amazon S3 bucket, where the response includes a body.
>>>>>>> upstream/master


type: long

format: bytes

--

*`aws.s3_request.uploaded.bytes`*::
+
--
<<<<<<< HEAD
Pg state description


type: long

--

*`ceph.cluster_status.pg_state.count`*::
+
--
Shows how many pgs are in state of pg_state.state_name

=======
The number bytes uploaded that contain a request body, made to an Amazon S3 bucket.


type: long

format: bytes
>>>>>>> upstream/master

type: long

--

*`aws.s3_request.errors.4xx`*::
+
--
<<<<<<< HEAD
Cluster status version
=======
The number of HTTP 4xx client error status code requests made to an Amazon S3 bucket with a value of either 0 or 1.

>>>>>>> upstream/master

type: long

type: long

--

*`aws.s3_request.errors.5xx`*::
+
--
<<<<<<< HEAD
Is osd full
=======
The number of HTTP 5xx server error status code requests made to an Amazon S3 bucket with a value of either 0 or 1.

>>>>>>> upstream/master

type: long

type: boolean

--

*`aws.s3_request.latency.first_byte.ms`*::
+
--
<<<<<<< HEAD
Is osd near full


type: boolean

--

*`ceph.cluster_status.osd.num_osds`*::
+
--
Shows how many osds in the cluster

=======
The per-request time from the complete request being received by an Amazon S3 bucket to when the response starts to be returned.


type: long

format: duration
>>>>>>> upstream/master

type: long

--

*`aws.s3_request.latency.total_request.ms`*::
+
--
<<<<<<< HEAD
Shows how many osds are on the state of UP
=======
The elapsed per-request time from the first byte received to the last byte sent to an Amazon S3 bucket.

>>>>>>> upstream/master

type: long

<<<<<<< HEAD
type: long

--
=======
format: duration
>>>>>>> upstream/master

--
<<<<<<< HEAD
Shows how many osds are on the state of IN
=======

[float]
=== sqs
>>>>>>> upstream/master

`sqs` contains the metrics that were scraped from AWS CloudWatch which contains monitoring metrics sent by AWS SQS.

<<<<<<< HEAD
type: long

--
=======
>>>>>>> upstream/master


*`aws.sqs.oldest_message_age.sec`*::
+
--
<<<<<<< HEAD
Shows how many osds are on the state of REMAPPED
=======
The approximate age of the oldest non-deleted message in the queue.

>>>>>>> upstream/master

type: long

format: duration

type: long

--

*`aws.sqs.messages.delayed`*::
+
--
<<<<<<< HEAD
epoch number
=======
TThe number of messages in the queue that are delayed and not available for reading immediately.

>>>>>>> upstream/master

type: long

type: long

--

<<<<<<< HEAD
[float]
=== monitor_health

monitor_health stats data



*`ceph.monitor_health.available.pct`*::
+
--
Available percent of the MON
=======
*`aws.sqs.messages.not_visible`*::
+
--
The number of messages that are in flight.

>>>>>>> upstream/master

type: long

type: long

--

*`aws.sqs.messages.visible`*::
+
--
<<<<<<< HEAD
Health of the MON
=======
The number of messages available for retrieval from the queue.

>>>>>>> upstream/master

type: long

type: keyword

--

*`aws.sqs.messages.deleted`*::
+
--
<<<<<<< HEAD
Available KB of the MON
=======
The number of messages deleted from the queue.

>>>>>>> upstream/master

type: long

type: long

--

*`aws.sqs.messages.received`*::
+
--
<<<<<<< HEAD
Total KB of the MON
=======
The number of messages returned by calls to the ReceiveMessage action.

>>>>>>> upstream/master

type: long

type: long

--

*`aws.sqs.messages.sent`*::
+
--
<<<<<<< HEAD
Used KB of the MON
=======
The number of messages added to a queue.

>>>>>>> upstream/master

type: long

type: long

--

*`aws.sqs.empty_receives`*::
+
--
<<<<<<< HEAD
Time when was updated
=======
The number of ReceiveMessage API calls that did not return a message.

>>>>>>> upstream/master

type: long

type: date

--

*`aws.sqs.sent_message_size.bytes`*::
+
--
<<<<<<< HEAD
Name of the MON
=======
The size of messages added to a queue.

>>>>>>> upstream/master

type: long

format: bytes

type: keyword

--

*`aws.sqs.queue.name`*::
+
--
<<<<<<< HEAD
Log bytes of MON


type: long
=======
SQS queue name
>>>>>>> upstream/master

format: bytes

type: keyword

--
<<<<<<< HEAD
Misc bytes of MON


type: long
=======

[[exported-fields-beat-common]]
== Beat fields

Contains common beat fields available in all event types.
>>>>>>> upstream/master

format: bytes


*`agent.hostname`*::
+
--
<<<<<<< HEAD
SST bytes of MON


type: long

format: bytes
=======
Hostname of the agent.

type: keyword
>>>>>>> upstream/master

--

*`beat.timezone`*::
+
--
<<<<<<< HEAD
Total bytes of MON


type: long

format: bytes
=======
type: alias

alias to: event.timezone
>>>>>>> upstream/master

--

*`fields`*::
+
--
<<<<<<< HEAD
Last updated
=======
Contains user configurable fields.

>>>>>>> upstream/master

type: object

type: long

--

[float]
<<<<<<< HEAD
=== osd_df
=======
=== error
>>>>>>> upstream/master

Error fields containing additional info in case of errors.



*`error.type`*::
+
--
<<<<<<< HEAD
osd node id
=======
Error type.

>>>>>>> upstream/master

type: keyword

type: long

--

*`beat.name`*::
+
--
<<<<<<< HEAD
osd node name
=======
type: alias
>>>>>>> upstream/master

alias to: host.name

type: keyword

--

*`beat.hostname`*::
+
--
<<<<<<< HEAD
osd node type, illegal type include hdd, ssd etc.
=======
type: alias
>>>>>>> upstream/master

alias to: agent.hostname

type: keyword

--

*`timeseries.instance`*::
+
--
<<<<<<< HEAD
osd disk total volume


type: long

format: bytes
=======
Time series instance id
>>>>>>> upstream/master

type: keyword

--
<<<<<<< HEAD
osd disk usage volume


type: long

format: bytes

--

*`ceph.osd_df.available.bytes`*::
+
--
osd disk available volume


type: long
=======

[[exported-fields-beat]]
== Beat fields

Beat module



[float]
=== beat

>>>>>>> upstream/master

format: bytes


*`beat.id`*::
+
--
<<<<<<< HEAD
shows how many pg located on this osd
=======
Beat ID.

>>>>>>> upstream/master

type: keyword

type: long

--

*`beat.type`*::
+
--
<<<<<<< HEAD
osd disk usage percentage


type: scaled_float

format: percent
=======
Beat type.


type: keyword
>>>>>>> upstream/master

--

[float]
<<<<<<< HEAD
=== osd_tree
=======
=== state
>>>>>>> upstream/master

Beat state



*`beat.state.management.enabled`*::
+
--
<<<<<<< HEAD
osd or bucket node id
=======
Is central management enabled?

>>>>>>> upstream/master

type: boolean

type: long

--

*`beat.state.module.count`*::
+
--
<<<<<<< HEAD
osd or bucket node name
=======
Number of modules enabled

>>>>>>> upstream/master

type: integer

type: keyword

--

*`beat.state.output.name`*::
+
--
<<<<<<< HEAD
osd or bucket node type, illegal type include osd, host, root etc.
=======
Name of output used by Beat

>>>>>>> upstream/master

type: keyword

type: keyword

--

*`beat.state.queue.name`*::
+
--
<<<<<<< HEAD
osd or bucket node typeID
=======
Name of queue being used by Beat

>>>>>>> upstream/master

type: keyword

type: long

--

<<<<<<< HEAD
*`ceph.osd_tree.children`*::
+
--
bucket children list, separated by comma.


type: keyword

--
=======
[float]
=== stats

Beat stats


>>>>>>> upstream/master

*`beat.stats.uptime.ms`*::
+
--
<<<<<<< HEAD
osd node crush weight
=======
Beat uptime

>>>>>>> upstream/master

type: long

type: float

--

*`beat.stats.runtime.goroutines`*::
+
--
<<<<<<< HEAD
node depth
=======
Number of goroutines running in Beat

>>>>>>> upstream/master

type: long

type: long

--

<<<<<<< HEAD
*`ceph.osd_tree.exists`*::
+
--
is node still exist or not(1-yes, 0-no)


type: boolean

--

*`ceph.osd_tree.primary_affinity`*::
+
--
the weight of reading data from primary osd


type: float

--
=======
[float]
=== libbeat

Fields common to all Beats



[float]
=== output

Output stats


>>>>>>> upstream/master

*`beat.stats.libbeat.output.type`*::
+
--
<<<<<<< HEAD
the reweight of osd
=======
Type of output

>>>>>>> upstream/master

type: keyword

type: long

--

<<<<<<< HEAD
*`ceph.osd_tree.status`*::
+
--
status of osd, it should be up or down


type: keyword

--
=======
[float]
=== events

Event counters


>>>>>>> upstream/master

*`beat.stats.libbeat.output.events.acked`*::
+
--
<<<<<<< HEAD
the device class of osd, like hdd, ssd etc.
=======
Number of events acknowledged

>>>>>>> upstream/master

type: long

type: keyword

--

*`beat.stats.libbeat.output.events.active`*::
+
--
<<<<<<< HEAD
the parent node of this osd or bucket node
=======
Number of active events

>>>>>>> upstream/master

type: long

type: keyword

--

<<<<<<< HEAD
[float]
=== pool_disk

pool_disk



*`ceph.pool_disk.id`*::
+
--
Id of the pool
=======
*`beat.stats.libbeat.output.events.batches`*::
+
--
Number of event batches

>>>>>>> upstream/master

type: long

type: long

--

*`beat.stats.libbeat.output.events.dropped`*::
+
--
<<<<<<< HEAD
Name of the pool
=======
Number of events dropped

>>>>>>> upstream/master

type: long

type: keyword

--

*`beat.stats.libbeat.output.events.duplicates`*::
+
--
<<<<<<< HEAD
Available bytes of the pool


type: long

format: bytes
=======
Number of events duplicated


type: long
>>>>>>> upstream/master

--

*`beat.stats.libbeat.output.events.failed`*::
+
--
<<<<<<< HEAD
Number of objects of the pool
=======
Number of events failed

>>>>>>> upstream/master

type: long

type: long

--

*`beat.stats.libbeat.output.events.toomany`*::
+
--
<<<<<<< HEAD
Used bytes of the pool


type: long

format: bytes
=======
Number of too many events


type: long
>>>>>>> upstream/master

--

*`beat.stats.libbeat.output.events.total`*::
+
--
<<<<<<< HEAD
Used kb of the pool
=======
Total number of events

>>>>>>> upstream/master

type: long

type: long

--

[float]
=== read

Read stats



*`beat.stats.libbeat.output.read.bytes`*::
+
--
<<<<<<< HEAD
Name of the project in Google Cloud.
=======
Number of bytes read

>>>>>>> upstream/master

type: long

example: project-x

--

*`beat.stats.libbeat.output.read.errors`*::
+
--
Number of read errors


type: long

--

[float]
=== write

Write stats



*`beat.stats.libbeat.output.write.bytes`*::
+
--
Number of bytes written


type: long

--

*`beat.stats.libbeat.output.write.errors`*::
+
--
Number of write errors


type: long

--

[[exported-fields-ceph]]
== Ceph fields

Ceph module



[float]
=== ceph

`ceph` contains the metrics that were scraped from CEPH.



[float]
=== cluster_disk

cluster_disk



*`ceph.cluster_disk.available.bytes`*::
+
--
<<<<<<< HEAD
The name of the module that generated the event.


type: alias

alias to: event.module
=======
Available bytes of the cluster


type: long

format: bytes
>>>>>>> upstream/master

--

*`ceph.cluster_disk.total.bytes`*::
+
--
Total bytes of the cluster


type: long

format: bytes

--

*`ceph.cluster_disk.used.bytes`*::
+
--
<<<<<<< HEAD
Process group id.
=======
Used bytes of the cluster

>>>>>>> upstream/master

type: long

format: bytes

type: long

--

[float]
=== cluster_health

cluster_health



*`ceph.cluster_health.overall_status`*::
+
--
Overall status of the cluster


type: keyword

--

*`ceph.cluster_health.timechecks.epoch`*::
+
--
Map version


type: long

--

*`ceph.cluster_health.timechecks.round.value`*::
+
--
<<<<<<< HEAD
The document type. Always set to "doc".


example: metricsets

required: True
=======
timecheck round


type: long
>>>>>>> upstream/master

--

*`ceph.cluster_health.timechecks.round.status`*::
+
--
Status of the round


type: keyword

--

[float]
<<<<<<< HEAD
=== agent
=======
=== cluster_status
>>>>>>> upstream/master

cluster_status



*`ceph.cluster_status.version`*::
+
--
<<<<<<< HEAD
Overall health of the local server cluster

type: boolean

--

[float]
=== runtime
=======
Ceph Status version
>>>>>>> upstream/master


type: long

--

*`ceph.cluster_status.traffic.read_bytes`*::
+
--
<<<<<<< HEAD
Number of bytes of memory obtained from the OS.
=======
Cluster read throughput per second


type: long

format: bytes
>>>>>>> upstream/master

type: long

--

*`ceph.cluster_status.traffic.write_bytes`*::
+
--
<<<<<<< HEAD
Heap objects allocated
=======
Cluster write throughput per second


type: long

format: bytes
>>>>>>> upstream/master

type: long

--

*`ceph.cluster_status.traffic.read_op_per_sec`*::
+
--
<<<<<<< HEAD
Objects allocated on the heap and is a general memory pressure indicator. This may burst from time to time but should return to a steady state value.
=======
Cluster read iops per second


type: long
>>>>>>> upstream/master

type: long

--

*`ceph.cluster_status.traffic.write_op_per_sec`*::
+
--
<<<<<<< HEAD
Running goroutines and is a general load pressure indicator. This may burst from time to time but should return to a steady state value.

type: long

--
=======
Cluster write iops per second


type: long
>>>>>>> upstream/master

--

*`ceph.cluster_status.misplace.total`*::
+
--
<<<<<<< HEAD
Bytes allocated by the Consul process.

type: long

=======
Cluster misplace pg number


type: long

--

*`ceph.cluster_status.misplace.objects`*::
+
>>>>>>> upstream/master
--
Cluster misplace objects number

<<<<<<< HEAD
[float]
=== garbage_collector
=======
>>>>>>> upstream/master

type: long

--

*`ceph.cluster_status.misplace.ratio`*::
+
--
<<<<<<< HEAD
Garbage collector total executions
=======
Cluster misplace ratio


type: scaled_float

format: percent
>>>>>>> upstream/master

type: long

--

<<<<<<< HEAD
[float]
=== pause
=======
*`ceph.cluster_status.degraded.total`*::
+
--
Cluster degraded pg number
>>>>>>> upstream/master


type: long

--

*`ceph.cluster_status.degraded.objects`*::
+
--
<<<<<<< HEAD
Garbage collector pause time in nanoseconds

type: long

--
=======
Cluster degraded objects number


type: long
>>>>>>> upstream/master

--

*`ceph.cluster_status.degraded.ratio`*::
+
--
<<<<<<< HEAD
Nanoseconds consumed by stop-the-world garbage collection pauses since Consul started.

type: long

--
=======
Cluster degraded ratio


type: scaled_float
>>>>>>> upstream/master

format: percent

--

*`ceph.cluster_status.pg.data_bytes`*::
+
--
Cluster pg data bytes


<<<<<<< HEAD
[float]
=== coredns
=======
type: long
>>>>>>> upstream/master

format: bytes

--

*`ceph.cluster_status.pg.avail_bytes`*::
+
--
Cluster available bytes

<<<<<<< HEAD
[float]
=== stats
=======
>>>>>>> upstream/master

type: long

format: bytes

--

*`ceph.cluster_status.pg.total_bytes`*::
+
--
<<<<<<< HEAD
Total number of panics
=======
Cluster total bytes

>>>>>>> upstream/master

type: long

format: bytes

type: long

--

*`ceph.cluster_status.pg.used_bytes`*::
+
--
<<<<<<< HEAD
Total query count
=======
Cluster used bytes

>>>>>>> upstream/master

type: long

format: bytes

type: long

--

*`ceph.cluster_status.pg_state.state_name`*::
+
--
<<<<<<< HEAD
Request duration histogram buckets in nanoseconds
=======
Pg state description

>>>>>>> upstream/master

type: long

type: object

--

*`ceph.cluster_status.pg_state.count`*::
+
--
<<<<<<< HEAD
Requests duration, sum of durations in nanoseconds


type: long

format: duration
=======
Shows how many pgs are in state of pg_state.state_name


type: long
>>>>>>> upstream/master

--

*`ceph.cluster_status.pg_state.version`*::
+
--
<<<<<<< HEAD
Requests duration, number of requests
=======
Cluster status version

>>>>>>> upstream/master

type: long

type: long

--

*`ceph.cluster_status.osd.full`*::
+
--
<<<<<<< HEAD
Request Size histogram buckets
=======
Is osd full

>>>>>>> upstream/master

type: boolean

type: object

--

*`ceph.cluster_status.osd.nearfull`*::
+
--
<<<<<<< HEAD
Request Size histogram sum
=======
Is osd near full

>>>>>>> upstream/master

type: boolean

type: long

--

*`ceph.cluster_status.osd.num_osds`*::
+
--
<<<<<<< HEAD
Request Size histogram count
=======
Shows how many osds in the cluster

>>>>>>> upstream/master

type: long

type: long

--

*`ceph.cluster_status.osd.num_up_osds`*::
+
--
<<<<<<< HEAD
Number of queries that have the DO bit set
=======
Shows how many osds are on the state of UP

>>>>>>> upstream/master

type: long

type: long

--

*`ceph.cluster_status.osd.num_in_osds`*::
+
--
<<<<<<< HEAD
Counter of queries per zone and type
=======
Shows how many osds are on the state of IN

>>>>>>> upstream/master

type: long

type: long

--

*`ceph.cluster_status.osd.num_remapped_pgs`*::
+
--
<<<<<<< HEAD
Holds the query type of the request
=======
Shows how many osds are on the state of REMAPPED

>>>>>>> upstream/master

type: long

type: keyword

--

*`ceph.cluster_status.osd.epoch`*::
+
--
<<<<<<< HEAD
Counter of responses per zone and rcode
=======
epoch number

>>>>>>> upstream/master

type: long

type: long

--

<<<<<<< HEAD
*`coredns.stats.rcode`*::
+
--
Holds the rcode of the response


type: keyword

--
=======
[float]
=== monitor_health

monitor_health stats data


>>>>>>> upstream/master

*`ceph.monitor_health.available.pct`*::
+
--
<<<<<<< HEAD
The address family of the transport (1 = IP (IP version 4), 2 = IP6 (IP version 6))
=======
Available percent of the MON

>>>>>>> upstream/master

type: long

type: keyword

--

*`ceph.monitor_health.health`*::
+
--
<<<<<<< HEAD
Response Size histogram buckets
=======
Health of the MON

>>>>>>> upstream/master

type: keyword

type: object

--

*`ceph.monitor_health.available.kb`*::
+
--
<<<<<<< HEAD
Response Size histogram sum
=======
Available KB of the MON

>>>>>>> upstream/master

type: long

type: long

--

*`ceph.monitor_health.total.kb`*::
+
--
<<<<<<< HEAD
Response Size histogram count
=======
Total KB of the MON

>>>>>>> upstream/master

type: long

type: long

--

*`ceph.monitor_health.used.kb`*::
+
--
<<<<<<< HEAD
The server responsible for the request
=======
Used KB of the MON

>>>>>>> upstream/master

type: long

type: keyword

--

*`ceph.monitor_health.last_updated`*::
+
--
<<<<<<< HEAD
The zonename used for the request/response
=======
Time when was updated

>>>>>>> upstream/master

type: date

type: keyword

--

*`ceph.monitor_health.name`*::
+
--
<<<<<<< HEAD
The transport of the response ("udp" or "tcp")
=======
Name of the MON

>>>>>>> upstream/master

type: keyword

type: keyword

--

*`ceph.monitor_health.store_stats.log.bytes`*::
+
--
<<<<<<< HEAD
Cache hits count for the cache plugin
=======
Log bytes of MON

>>>>>>> upstream/master

type: long

format: bytes

type: long

--

*`ceph.monitor_health.store_stats.misc.bytes`*::
+
--
<<<<<<< HEAD
Cache misses count for the cache plugin
=======
Misc bytes of MON

>>>>>>> upstream/master

type: long

<<<<<<< HEAD
type: long

--

[[exported-fields-couchbase]]
== Couchbase fields
=======
format: bytes
>>>>>>> upstream/master

--

*`ceph.monitor_health.store_stats.sst.bytes`*::
+
--
SST bytes of MON


<<<<<<< HEAD
[float]
=== couchbase
=======
type: long
>>>>>>> upstream/master

format: bytes

--

*`ceph.monitor_health.store_stats.total.bytes`*::
+
--
Total bytes of MON

<<<<<<< HEAD
[float]
=== bucket
=======
>>>>>>> upstream/master

type: long

format: bytes

--

*`ceph.monitor_health.store_stats.last_updated`*::
+
--
<<<<<<< HEAD
Name of the bucket.
=======
Last updated

>>>>>>> upstream/master

type: long

type: keyword

--

<<<<<<< HEAD
*`couchbase.bucket.type`*::
+
--
Type of the bucket.


type: keyword

--
=======
[float]
=== osd_df

ceph osd disk usage information


>>>>>>> upstream/master

*`ceph.osd_df.id`*::
+
--
<<<<<<< HEAD
Size of user data within buckets of the specified state that are resident in RAM.


type: long

format: bytes
=======
osd node id


type: long
>>>>>>> upstream/master

--

*`ceph.osd_df.name`*::
+
--
<<<<<<< HEAD
Number of disk fetches.
=======
osd node name

>>>>>>> upstream/master

type: keyword

type: long

--

*`ceph.osd_df.device_class`*::
+
--
<<<<<<< HEAD
Amount of disk used (bytes).


type: long

format: bytes
=======
osd node type, illegal type include hdd, ssd etc.


type: keyword
>>>>>>> upstream/master

--

*`ceph.osd_df.total.byte`*::
+
--
<<<<<<< HEAD
Amount of memory used by the bucket (bytes).
=======
osd disk total volume
>>>>>>> upstream/master


type: long

format: bytes

--

*`ceph.osd_df.used.byte`*::
+
--
<<<<<<< HEAD
Amount of RAM used by the bucket (bytes).
=======
osd disk usage volume
>>>>>>> upstream/master


type: long

format: bytes

--

*`ceph.osd_df.available.bytes`*::
+
--
<<<<<<< HEAD
Percentage of RAM used (for active objects) against the configured bucket size (%).


type: scaled_float

format: percent
=======
osd disk available volume


type: long

format: bytes
>>>>>>> upstream/master

--

*`ceph.osd_df.pg_num`*::
+
--
<<<<<<< HEAD
Number of operations per second.
=======
shows how many pg located on this osd

>>>>>>> upstream/master

type: long

type: long

--

*`ceph.osd_df.used.pct`*::
+
--
<<<<<<< HEAD
Number of items associated with the bucket.
=======
osd disk usage percentage

>>>>>>> upstream/master

type: scaled_float

format: percent

type: long

--

[float]
<<<<<<< HEAD
=== cluster
=======
=== osd_tree
>>>>>>> upstream/master

ceph osd tree info



*`ceph.osd_tree.id`*::
+
--
<<<<<<< HEAD
Free hard drive space in the cluster (bytes).


type: long

format: bytes
=======
osd or bucket node id


type: long
>>>>>>> upstream/master

--

*`ceph.osd_tree.name`*::
+
--
<<<<<<< HEAD
Hard drive quota total for the cluster (bytes).


type: long

format: bytes
=======
osd or bucket node name


type: keyword
>>>>>>> upstream/master

--

*`ceph.osd_tree.type`*::
+
--
<<<<<<< HEAD
Total hard drive space available to the cluster (bytes).


type: long

format: bytes
=======
osd or bucket node type, illegal type include osd, host, root etc.


type: keyword
>>>>>>> upstream/master

--

*`ceph.osd_tree.type_id`*::
+
--
<<<<<<< HEAD
Hard drive space used by the cluster (bytes).


type: long

format: bytes
=======
osd or bucket node typeID


type: long
>>>>>>> upstream/master

--

*`ceph.osd_tree.children`*::
+
--
<<<<<<< HEAD
Hard drive space used by the data in the cluster (bytes).


type: long

format: bytes
=======
bucket children list, separated by comma.


type: keyword
>>>>>>> upstream/master

--

*`ceph.osd_tree.crush_weight`*::
+
--
<<<<<<< HEAD
Max bucket count setting.
=======
osd node crush weight

>>>>>>> upstream/master

type: float

type: long

--

*`ceph.osd_tree.depth`*::
+
--
<<<<<<< HEAD
Memory quota setting for the Index service (Mbyte).
=======
node depth

>>>>>>> upstream/master

type: long

type: long

--

*`ceph.osd_tree.exists`*::
+
--
<<<<<<< HEAD
Memory quota setting for the cluster (Mbyte).
=======
is node still exist or not(1-yes, 0-no)

>>>>>>> upstream/master

type: boolean

type: long

--

*`ceph.osd_tree.primary_affinity`*::
+
--
<<<<<<< HEAD
RAM quota total for the cluster (bytes).


type: long

format: bytes
=======
the weight of reading data from primary osd


type: float
>>>>>>> upstream/master

--

*`ceph.osd_tree.reweight`*::
+
--
<<<<<<< HEAD
RAM quota used by the current node in the cluster (bytes).


type: long

format: bytes
=======
the reweight of osd


type: long
>>>>>>> upstream/master

--

*`ceph.osd_tree.status`*::
+
--
<<<<<<< HEAD
RAM quota used by the cluster (bytes).


type: long

format: bytes
=======
status of osd, it should be up or down


type: keyword
>>>>>>> upstream/master

--

*`ceph.osd_tree.device_class`*::
+
--
<<<<<<< HEAD
Ram quota used by the current node in the cluster (bytes)


type: long

format: bytes
=======
the device class of osd, like hdd, ssd etc.


type: keyword
>>>>>>> upstream/master

--

*`ceph.osd_tree.father`*::
+
--
<<<<<<< HEAD
Total RAM available to cluster (bytes).


type: long
=======
the parent node of this osd or bucket node
>>>>>>> upstream/master

format: bytes

type: keyword

--
<<<<<<< HEAD
RAM used by the cluster (bytes).


type: long
=======

[float]
=== pool_disk

pool_disk
>>>>>>> upstream/master

format: bytes


*`ceph.pool_disk.id`*::
+
--
<<<<<<< HEAD
RAM used by the data in the cluster (bytes).


type: long

format: bytes

--

[float]
=== node
=======
Id of the pool


type: long

--

*`ceph.pool_disk.name`*::
+
--
Name of the pool
>>>>>>> upstream/master


type: keyword

--

*`ceph.pool_disk.stats.available.bytes`*::
+
--
<<<<<<< HEAD
Number of get commands
=======
Available bytes of the pool

>>>>>>> upstream/master

type: long

format: bytes

type: long

--

*`ceph.pool_disk.stats.objects`*::
+
--
<<<<<<< HEAD
Amount of disk space used by Couch docs (bytes).


type: long

format: bytes
=======
Number of objects of the pool


type: long
>>>>>>> upstream/master

--

*`ceph.pool_disk.stats.used.bytes`*::
+
--
<<<<<<< HEAD
Data size of Couch docs associated with a node (bytes).
=======
Used bytes of the pool
>>>>>>> upstream/master


type: long

format: bytes

--

*`ceph.pool_disk.stats.used.kb`*::
+
--
<<<<<<< HEAD
Size of object data for spatial views (bytes).
=======
Used kb of the pool

>>>>>>> upstream/master

type: long

type: long

--

<<<<<<< HEAD
*`couchbase.node.couch.spatial.disk_size.bytes`*::
+
--
Amount of disk space used by spatial views (bytes).


type: long

--
=======
[[exported-fields-cloud]]
== Cloud provider metadata fields

Metadata from cloud providers added by the add_cloud_metadata processor.


>>>>>>> upstream/master

*`cloud.project.id`*::
+
--
<<<<<<< HEAD
Amount of disk space used by Couch views (bytes).
=======
Name of the project in Google Cloud.

>>>>>>> upstream/master

example: project-x

type: long

--

*`cloud.image.id`*::
+
--
<<<<<<< HEAD
Size of object data for Couch views (bytes).
=======
Image ID for the cloud instance.

>>>>>>> upstream/master

example: ami-abcd1234

type: long

--

*`meta.cloud.provider`*::
+
--
<<<<<<< HEAD
The CPU utilization rate (%).
=======
type: alias
>>>>>>> upstream/master

alias to: cloud.provider

type: scaled_float

--

*`meta.cloud.instance_id`*::
+
--
<<<<<<< HEAD
Number of current items.
=======
type: alias
>>>>>>> upstream/master

alias to: cloud.instance.id

type: long

--

*`meta.cloud.instance_name`*::
+
--
<<<<<<< HEAD
Total number of items associated with the node.
=======
type: alias
>>>>>>> upstream/master

alias to: cloud.instance.name

type: long

--

*`meta.cloud.machine_type`*::
+
--
<<<<<<< HEAD
Number of disk fetches performed since the server was started.
=======
type: alias
>>>>>>> upstream/master

alias to: cloud.machine.type

type: long

--

*`meta.cloud.availability_zone`*::
+
--
<<<<<<< HEAD
Number of get hits.
=======
type: alias
>>>>>>> upstream/master

alias to: cloud.availability_zone

type: long

--

*`meta.cloud.project_id`*::
+
--
<<<<<<< HEAD
The hostname of the node.
=======
type: alias
>>>>>>> upstream/master

alias to: cloud.project.id

type: keyword

--

*`meta.cloud.region`*::
+
--
<<<<<<< HEAD
Amount of memcached memory allocated (bytes).


type: long

format: bytes

--

*`couchbase.node.mcd_memory.reserved.bytes`*::
+
--
Amount of memcached memory reserved (bytes).


type: long

--

*`couchbase.node.memory.free.bytes`*::
+
--
Amount of memory free for the node (bytes).
=======
type: alias

alias to: cloud.region

--

[[exported-fields-cockroachdb]]
== CockroachDB fields

CockroachDB module




[[exported-fields-common]]
== Common fields
>>>>>>> upstream/master

Contains common fields available in all event types.

<<<<<<< HEAD
type: long

--
=======
>>>>>>> upstream/master


*`metricset.module`*::
+
--
<<<<<<< HEAD
Total memory available to the node (bytes).
=======
The name of the module that generated the event.

>>>>>>> upstream/master

type: alias

alias to: event.module

type: long

--

*`metricset.name`*::
+
--
<<<<<<< HEAD
Memory used by the node (bytes).
=======
The name of the metricset that generated the event.
>>>>>>> upstream/master


type: long

--

*`process.pgid`*::
+
--
<<<<<<< HEAD
Number of operations performed on Couchbase.
=======
Process group id.

>>>>>>> upstream/master

type: long

type: long

--

*`service.address`*::
+
--
<<<<<<< HEAD
Total swap size allocated (bytes).
=======
Address of the machine where the service is running. This field may not be present when the data was collected locally.
>>>>>>> upstream/master


type: long

--

*`service.hostname`*::
+
--
<<<<<<< HEAD
Amount of swap space used (bytes).
=======
Host name of the machine where the service is running.
>>>>>>> upstream/master


type: long

--

*`type`*::
+
--
<<<<<<< HEAD
Time during which the node was in operation (sec).
=======
The document type. Always set to "doc".

>>>>>>> upstream/master

example: metricsets

<<<<<<< HEAD
type: long

--
=======
required: True
>>>>>>> upstream/master

--
<<<<<<< HEAD
Number of items/documents that are replicas.
=======
>>>>>>> upstream/master

[[exported-fields-consul]]
== consul fields

<<<<<<< HEAD
type: long

--

[[exported-fields-couchdb]]
== couchdb fields
=======
Consul module
>>>>>>> upstream/master




[float]
<<<<<<< HEAD
=== couchdb
=======
=== agent
>>>>>>> upstream/master

Agent Metricset fetches metrics information from a Consul instance running as Agent



<<<<<<< HEAD
[float]
=== server
=======
>>>>>>> upstream/master

*`consul.agent.autopilot.healthy`*::
+
--
Overall health of the local server cluster

type: boolean

--

[float]
<<<<<<< HEAD
=== httpd
=======
=== runtime
>>>>>>> upstream/master

Runtime related metrics



*`consul.agent.runtime.sys.bytes`*::
+
--
<<<<<<< HEAD
Number of view reads
=======
Number of bytes of memory obtained from the OS.
>>>>>>> upstream/master

type: long

type: long

--

*`consul.agent.runtime.malloc_count`*::
+
--
<<<<<<< HEAD
Number of bulk requests
=======
Heap objects allocated
>>>>>>> upstream/master

type: long

type: long

--

*`consul.agent.runtime.heap_objects`*::
+
--
<<<<<<< HEAD
Number of clients for continuous _changes
=======
Objects allocated on the heap and is a general memory pressure indicator. This may burst from time to time but should return to a steady state value.
>>>>>>> upstream/master

type: long

type: long

--

*`consul.agent.runtime.goroutines`*::
+
--
<<<<<<< HEAD
Number of temporary view reads
=======
Running goroutines and is a general load pressure indicator. This may burst from time to time but should return to a steady state value.
>>>>>>> upstream/master

type: long

type: long

--


*`consul.agent.runtime.alloc.bytes`*::
+
--
<<<<<<< HEAD
Number of HTTP requests
=======
Bytes allocated by the Consul process.
>>>>>>> upstream/master

type: long

type: long

--

[float]
<<<<<<< HEAD
=== httpd_request_methods

HTTP request methods
=======
=== garbage_collector
>>>>>>> upstream/master

Garbage collector metrics


*`consul.agent.runtime.garbage_collector.runs`*::
+
--
<<<<<<< HEAD
Number of HTTP COPY requests
=======
Garbage collector total executions
>>>>>>> upstream/master

type: long

type: long

--

<<<<<<< HEAD
*`couchdb.server.httpd_request_methods.HEAD`*::
+
--
Number of HTTP HEAD requests


type: long

--
=======
[float]
=== pause

Time that the garbage collector has paused the app


>>>>>>> upstream/master

*`consul.agent.runtime.garbage_collector.pause.current.ns`*::
+
--
<<<<<<< HEAD
Number of HTTP POST requests
=======
Garbage collector pause time in nanoseconds
>>>>>>> upstream/master

type: long

type: long

--


*`consul.agent.runtime.garbage_collector.pause.total.ns`*::
+
--
<<<<<<< HEAD
Number of HTTP DELETE requests
=======
Nanoseconds consumed by stop-the-world garbage collection pauses since Consul started.
>>>>>>> upstream/master

type: long

type: long

--

<<<<<<< HEAD
*`couchdb.server.httpd_request_methods.GET`*::
+
--
Number of HTTP GET requests


type: long

--

*`couchdb.server.httpd_request_methods.PUT`*::
+
--
Number of HTTP PUT requests


type: long

--

[float]
=== httpd_status_codes
=======
[[exported-fields-coredns]]
== coredns fields

coredns Module



[float]
=== coredns

`coredns` contains statistics that were read from coreDNS



[float]
=== stats
>>>>>>> upstream/master

Contains statistics related to the coreDNS service



*`coredns.stats.panic.count`*::
+
--
<<<<<<< HEAD
Number of HTTP 200 OK responses
=======
Total number of panics

>>>>>>> upstream/master

type: long

type: long

--

*`coredns.stats.dns.request.count`*::
+
--
<<<<<<< HEAD
Number of HTTP 201 Created responses
=======
Total query count

>>>>>>> upstream/master

type: long

type: long

--

*`coredns.stats.dns.request.duration.ns.bucket.*`*::
+
--
<<<<<<< HEAD
Number of HTTP 202 Accepted responses
=======
Request duration histogram buckets in nanoseconds

>>>>>>> upstream/master

type: object

type: long

--

*`coredns.stats.dns.request.duration.ns.sum`*::
+
--
<<<<<<< HEAD
Number of HTTP 301 Moved Permanently responses


type: long

--

*`couchdb.server.httpd_status_codes.304`*::
+
--
Number of HTTP 304 Not Modified responses

=======
Requests duration, sum of durations in nanoseconds


type: long

format: duration
>>>>>>> upstream/master

type: long

--

*`coredns.stats.dns.request.duration.ns.count`*::
+
--
<<<<<<< HEAD
Number of HTTP 400 Bad Request responses
=======
Requests duration, number of requests

>>>>>>> upstream/master

type: long

type: long

--

*`coredns.stats.dns.request.size.bytes.bucket.*`*::
+
--
<<<<<<< HEAD
Number of HTTP 401 Unauthorized responses
=======
Request Size histogram buckets

>>>>>>> upstream/master

type: object

type: long

--

*`coredns.stats.dns.request.size.bytes.sum`*::
+
--
<<<<<<< HEAD
Number of HTTP 403 Forbidden responses
=======
Request Size histogram sum

>>>>>>> upstream/master

type: long

type: long

--

*`coredns.stats.dns.request.size.bytes.count`*::
+
--
<<<<<<< HEAD
Number of HTTP 404 Not Found responses
=======
Request Size histogram count

>>>>>>> upstream/master

type: long

type: long

--

*`coredns.stats.dns.request.do.count`*::
+
--
<<<<<<< HEAD
Number of HTTP 405 Method Not Allowed responses
=======
Number of queries that have the DO bit set

>>>>>>> upstream/master

type: long

type: long

--

*`coredns.stats.dns.request.type.count`*::
+
--
<<<<<<< HEAD
Number of HTTP 409 Conflict responses
=======
Counter of queries per zone and type

>>>>>>> upstream/master

type: long

type: long

--

*`coredns.stats.type`*::
+
--
<<<<<<< HEAD
Number of HTTP 412 Precondition Failed responses
=======
Holds the query type of the request

>>>>>>> upstream/master

type: keyword

type: long

--

*`coredns.stats.dns.response.rcode.count`*::
+
--
<<<<<<< HEAD
Number of HTTP 500 Internal Server Error responses
=======
Counter of responses per zone and rcode

>>>>>>> upstream/master

type: long

type: long

--

<<<<<<< HEAD
[float]
=== couchdb

couchdb statistics



*`couchdb.server.couchdb.database_writes`*::
+
--
Number of times a database was changed
=======
*`coredns.stats.rcode`*::
+
--
Holds the rcode of the response

>>>>>>> upstream/master

type: keyword

type: long

--

*`coredns.stats.family`*::
+
--
<<<<<<< HEAD
Number of open databases
=======
The address family of the transport (1 = IP (IP version 4), 2 = IP6 (IP version 6))

>>>>>>> upstream/master

type: keyword

type: long

--

*`coredns.stats.dns.response.size.bytes.bucket.*`*::
+
--
<<<<<<< HEAD
Number of authentication cache misses
=======
Response Size histogram buckets

>>>>>>> upstream/master

type: object

type: long

--

*`coredns.stats.dns.response.size.bytes.sum`*::
+
--
<<<<<<< HEAD
Length of a request inside CouchDB without MochiWeb
=======
Response Size histogram sum

>>>>>>> upstream/master

type: long

type: long

--

*`coredns.stats.dns.response.size.bytes.count`*::
+
--
<<<<<<< HEAD
Number of times a document was read from a database
=======
Response Size histogram count

>>>>>>> upstream/master

type: long

type: long

--

*`coredns.stats.server`*::
+
--
<<<<<<< HEAD
Number of authentication cache hits
=======
The server responsible for the request

>>>>>>> upstream/master

type: keyword

type: long

--

*`coredns.stats.zone`*::
+
--
<<<<<<< HEAD
Number of file descriptors CouchDB has open
=======
The zonename used for the request/response

>>>>>>> upstream/master

type: keyword

type: long

--

*`coredns.stats.proto`*::
+
--
The transport of the response ("udp" or "tcp")


type: keyword

--

*`coredns.stats.dns.cache.hits.count`*::
+
--
Cache hits count for the cache plugin


type: long

--

*`coredns.stats.dns.cache.misses.count`*::
+
--
<<<<<<< HEAD
Image labels.
=======
Cache misses count for the cache plugin

>>>>>>> upstream/master

type: long

type: object

--

[[exported-fields-couchbase]]
== Couchbase fields

Metrics collected from Couchbase servers.



[float]
<<<<<<< HEAD
=== docker
=======
=== couchbase
>>>>>>> upstream/master

`couchbase` contains the metrics that were scraped from Couchbase.



[float]
<<<<<<< HEAD
=== container
=======
=== bucket
>>>>>>> upstream/master

Couchbase bucket metrics.



*`couchbase.bucket.name`*::
+
--
<<<<<<< HEAD
Command that was executed in the Docker container.
=======
Name of the bucket.

>>>>>>> upstream/master

type: keyword

type: keyword

--

*`couchbase.bucket.type`*::
+
--
<<<<<<< HEAD
Date when the container was created.
=======
Type of the bucket.

>>>>>>> upstream/master

type: keyword

type: date

--

*`couchbase.bucket.data.used.bytes`*::
+
--
<<<<<<< HEAD
Container status.
=======
Size of user data within buckets of the specified state that are resident in RAM.

>>>>>>> upstream/master

type: long

format: bytes

type: keyword

--

*`couchbase.bucket.disk.fetches`*::
+
--
<<<<<<< HEAD
Container IP addresses.
=======
Number of disk fetches.

>>>>>>> upstream/master

type: long

type: ip

--

<<<<<<< HEAD
[float]
=== size

Container size metrics.



*`docker.container.size.root_fs`*::
+
--
Total size of all the files in the container.
=======
*`couchbase.bucket.disk.used.bytes`*::
+
--
Amount of disk used (bytes).

>>>>>>> upstream/master

type: long

format: bytes

type: long

--

*`couchbase.bucket.memory.used.bytes`*::
+
--
<<<<<<< HEAD
Size of the files that have been created or changed since creation.
=======
Amount of memory used by the bucket (bytes).

>>>>>>> upstream/master

type: long

<<<<<<< HEAD
type: long

--
=======
format: bytes
>>>>>>> upstream/master

--
<<<<<<< HEAD
Image tags.


type: keyword

=======

*`couchbase.bucket.quota.ram.bytes`*::
+
>>>>>>> upstream/master
--
Amount of RAM used by the bucket (bytes).

<<<<<<< HEAD
[float]
=== cpu
=======
>>>>>>> upstream/master

type: long

format: bytes

--

*`couchbase.bucket.quota.use.pct`*::
+
--
<<<<<<< HEAD
Percentage of time in kernel space.
=======
Percentage of RAM used (for active objects) against the configured bucket size (%).
>>>>>>> upstream/master


type: scaled_float

<<<<<<< HEAD
format: percentage
=======
format: percent
>>>>>>> upstream/master

--

*`couchbase.bucket.ops_per_sec`*::
+
--
<<<<<<< HEAD
CPU ticks in kernel space.
=======
Number of operations per second.

>>>>>>> upstream/master

type: long

type: long

--

*`couchbase.bucket.item_count`*::
+
--
<<<<<<< HEAD
Percentage of total CPU time in the system.


type: scaled_float

format: percentage

--

*`docker.cpu.system.ticks`*::
+
--
CPU system ticks.


type: long

--
=======
Number of items associated with the bucket.


type: long

--

[float]
=== cluster

Couchbase cluster metrics.


>>>>>>> upstream/master

*`couchbase.cluster.hdd.free.bytes`*::
+
--
<<<<<<< HEAD
Percentage of time in user space.


type: scaled_float

format: percentage
=======
Free hard drive space in the cluster (bytes).


type: long

format: bytes
>>>>>>> upstream/master

--

*`couchbase.cluster.hdd.quota.total.bytes`*::
+
--
<<<<<<< HEAD
CPU ticks in user space.
=======
Hard drive quota total for the cluster (bytes).

>>>>>>> upstream/master

type: long

format: bytes

type: long

--

*`couchbase.cluster.hdd.total.bytes`*::
+
--
<<<<<<< HEAD
Total CPU usage.


type: scaled_float

format: percentage
=======
Total hard drive space available to the cluster (bytes).


type: long

format: bytes
>>>>>>> upstream/master

--

*`couchbase.cluster.hdd.used.value.bytes`*::
+
--
<<<<<<< HEAD
Percentage of CPU time in this core.


type: object

format: percentage
=======
Hard drive space used by the cluster (bytes).


type: long

format: bytes
>>>>>>> upstream/master

--

*`couchbase.cluster.hdd.used.by_data.bytes`*::
+
--
<<<<<<< HEAD
Number of CPU ticks in this core.


type: object

--

[float]
=== diskio
=======
Hard drive space used by the data in the cluster (bytes).

>>>>>>> upstream/master

type: long

format: bytes

--

<<<<<<< HEAD
[float]
=== read
=======
*`couchbase.cluster.max_bucket_count`*::
+
--
Max bucket count setting.
>>>>>>> upstream/master


type: long

--

*`couchbase.cluster.quota.index_memory.mb`*::
+
--
<<<<<<< HEAD
Number of reads during the life of the container
=======
Memory quota setting for the Index service (Mbyte).

>>>>>>> upstream/master

type: long

type: long

--

*`couchbase.cluster.quota.memory.mb`*::
+
--
<<<<<<< HEAD
Bytes read during the life of the container


type: long

format: bytes
=======
Memory quota setting for the cluster (Mbyte).


type: long
>>>>>>> upstream/master

--

*`couchbase.cluster.ram.quota.total.value.bytes`*::
+
--
<<<<<<< HEAD
Number of current reads per second
=======
RAM quota total for the cluster (bytes).

>>>>>>> upstream/master

type: long

format: bytes

type: long

--

*`couchbase.cluster.ram.quota.total.per_node.bytes`*::
+
--
RAM quota used by the current node in the cluster (bytes).


<<<<<<< HEAD
Number of current reads per second
=======
type: long

format: bytes
>>>>>>> upstream/master

--

<<<<<<< HEAD
type: scaled_float

=======
*`couchbase.cluster.ram.quota.used.value.bytes`*::
+
>>>>>>> upstream/master
--
RAM quota used by the cluster (bytes).

<<<<<<< HEAD
[float]
=== write
=======
>>>>>>> upstream/master

type: long

format: bytes

--

*`couchbase.cluster.ram.quota.used.per_node.bytes`*::
+
--
<<<<<<< HEAD
Number of writes during the life of the container
=======
Ram quota used by the current node in the cluster (bytes)

>>>>>>> upstream/master

type: long

format: bytes

type: long

--

*`couchbase.cluster.ram.total.bytes`*::
+
--
<<<<<<< HEAD
Bytes written during the life of the container
=======
Total RAM available to cluster (bytes).
>>>>>>> upstream/master


type: long

format: bytes

--

*`couchbase.cluster.ram.used.value.bytes`*::
+
--
<<<<<<< HEAD
Number of current writes per second
=======
RAM used by the cluster (bytes).

>>>>>>> upstream/master

type: long

format: bytes

type: long

--

*`couchbase.cluster.ram.used.by_data.bytes`*::
+
--
RAM used by the data in the cluster (bytes).

<<<<<<< HEAD
deprecated[6.4]

Number of current writes per second
=======

type: long
>>>>>>> upstream/master

format: bytes

type: scaled_float

--

[float]
<<<<<<< HEAD
=== summary
=======
=== node
>>>>>>> upstream/master

Couchbase node metrics.



*`couchbase.node.cmd_get`*::
+
--
<<<<<<< HEAD
Number of I/O operations during the life of the container
=======
Number of get commands

>>>>>>> upstream/master

type: long

type: long

--

*`couchbase.node.couch.docs.disk_size.bytes`*::
+
--
<<<<<<< HEAD
Bytes read and written during the life of the container
=======
Amount of disk space used by Couch docs (bytes).
>>>>>>> upstream/master


type: long

format: bytes

--

*`couchbase.node.couch.docs.data_size.bytes`*::
+
--
<<<<<<< HEAD
Number of current operations per second
=======
Data size of Couch docs associated with a node (bytes).

>>>>>>> upstream/master

type: long

format: bytes

type: long

--

*`couchbase.node.couch.spatial.data_size.bytes`*::
+
--
Size of object data for spatial views (bytes).

<<<<<<< HEAD
deprecated[6.4]

Number of reads and writes per second
=======
>>>>>>> upstream/master

type: long

type: scaled_float

--

<<<<<<< HEAD
[float]
=== event
=======
*`couchbase.node.couch.spatial.disk_size.bytes`*::
+
--
Amount of disk space used by spatial views (bytes).
>>>>>>> upstream/master


type: long

--

*`couchbase.node.couch.views.disk_size.bytes`*::
+
--
<<<<<<< HEAD
Event status
=======
Amount of disk space used by Couch views (bytes).

>>>>>>> upstream/master

type: long

type: keyword

--

*`couchbase.node.couch.views.data_size.bytes`*::
+
--
<<<<<<< HEAD
Event id when available
=======
Size of object data for Couch views (bytes).

>>>>>>> upstream/master

type: long

type: keyword

--

*`couchbase.node.cpu_utilization_rate.pct`*::
+
--
<<<<<<< HEAD
Event source
=======
The CPU utilization rate (%).

>>>>>>> upstream/master

type: scaled_float

type: keyword

--

*`couchbase.node.current_items.value`*::
+
--
<<<<<<< HEAD
The type of object emitting the event
=======
Number of current items.

>>>>>>> upstream/master

type: long

type: keyword

--

*`couchbase.node.current_items.total`*::
+
--
<<<<<<< HEAD
The type of event
=======
Total number of items associated with the node.

>>>>>>> upstream/master

type: long

type: keyword

--

<<<<<<< HEAD
[float]
=== actor
=======
*`couchbase.node.ep_bg_fetched`*::
+
--
Number of disk fetches performed since the server was started.
>>>>>>> upstream/master


type: long

--

*`couchbase.node.get_hits`*::
+
--
<<<<<<< HEAD
The ID of the object emitting the event
=======
Number of get hits.

>>>>>>> upstream/master

type: long

type: keyword

--

*`couchbase.node.hostname`*::
+
--
<<<<<<< HEAD
Various key/value attributes of the object, depending on its type
=======
The hostname of the node.

>>>>>>> upstream/master

type: keyword

type: object

--

<<<<<<< HEAD
[float]
=== healthcheck
=======
*`couchbase.node.mcd_memory.allocated.bytes`*::
+
--
Amount of memcached memory allocated (bytes).
>>>>>>> upstream/master


type: long

format: bytes

--

*`couchbase.node.mcd_memory.reserved.bytes`*::
+
--
<<<<<<< HEAD
concurent failed check
=======
Amount of memcached memory reserved (bytes).

>>>>>>> upstream/master

type: long

type: integer

--

*`couchbase.node.memory.free.bytes`*::
+
--
<<<<<<< HEAD
Healthcheck status code
=======
Amount of memory free for the node (bytes).

>>>>>>> upstream/master

type: long

type: keyword

--

<<<<<<< HEAD
[float]
=== event
=======
*`couchbase.node.memory.total.bytes`*::
+
--
Total memory available to the node (bytes).
>>>>>>> upstream/master


type: long

--

*`couchbase.node.memory.used.bytes`*::
+
--
<<<<<<< HEAD
Healthcheck end date
=======
Memory used by the node (bytes).

>>>>>>> upstream/master

type: long

type: date

--

*`couchbase.node.ops`*::
+
--
<<<<<<< HEAD
Healthcheck start date
=======
Number of operations performed on Couchbase.

>>>>>>> upstream/master

type: long

type: date

--

*`couchbase.node.swap.total.bytes`*::
+
--
<<<<<<< HEAD
Healthcheck output
=======
Total swap size allocated (bytes).

>>>>>>> upstream/master

type: long

type: keyword

--

*`couchbase.node.swap.used.bytes`*::
+
--
<<<<<<< HEAD
Healthcheck status code
=======
Amount of swap space used (bytes).

>>>>>>> upstream/master

type: long

type: integer

--

<<<<<<< HEAD
[float]
=== image

Docker image metrics.
=======
*`couchbase.node.uptime.sec`*::
+
--
Time during which the node was in operation (sec).
>>>>>>> upstream/master


type: long

<<<<<<< HEAD
[float]
=== id
=======
--
>>>>>>> upstream/master

*`couchbase.node.vb_replica_curr_items`*::
+
--
Number of items/documents that are replicas.


type: long

--
<<<<<<< HEAD
Unique image identifier given upon its creation.
=======

[[exported-fields-couchdb]]
== couchdb fields
>>>>>>> upstream/master

couchdb module

<<<<<<< HEAD
type: keyword

--

*`docker.image.id.parent`*::
+
--
Identifier of the image, if it exists, from which the current image directly descends.


type: keyword

--

*`docker.image.created`*::
+
--
Date and time when the image was created.


type: date

--

[float]
=== size
=======


[float]
=== couchdb




[float]
=== server

Contains CouchDB server stats



[float]
=== httpd
>>>>>>> upstream/master

HTTP statistics



*`couchdb.server.httpd.view_reads`*::
+
--
<<<<<<< HEAD
Size of the image.
=======
Number of view reads

>>>>>>> upstream/master

type: long

type: long

--

*`couchdb.server.httpd.bulk_requests`*::
+
--
<<<<<<< HEAD
Total size of the all cached images associated to the current image.
=======
Number of bulk requests

>>>>>>> upstream/master

type: long

type: long

--

*`couchdb.server.httpd.clients_requesting_changes`*::
+
--
<<<<<<< HEAD
Image labels.
=======
Number of clients for continuous _changes

>>>>>>> upstream/master

type: long

type: object

--

*`couchdb.server.httpd.temporary_view_reads`*::
+
--
<<<<<<< HEAD
Image tags.
=======
Number of temporary view reads

>>>>>>> upstream/master

type: long

type: keyword

--

<<<<<<< HEAD
[float]
=== info
=======
*`couchdb.server.httpd.requests`*::
+
--
Number of HTTP requests
>>>>>>> upstream/master


type: long

--

[float]
<<<<<<< HEAD
=== containers
=======
=== httpd_request_methods
>>>>>>> upstream/master

HTTP request methods



*`couchdb.server.httpd_request_methods.COPY`*::
+
--
<<<<<<< HEAD
Total number of paused containers.
=======
Number of HTTP COPY requests

>>>>>>> upstream/master

type: long

type: long

--

*`couchdb.server.httpd_request_methods.HEAD`*::
+
--
<<<<<<< HEAD
Total number of running containers.
=======
Number of HTTP HEAD requests

>>>>>>> upstream/master

type: long

type: long

--

*`couchdb.server.httpd_request_methods.POST`*::
+
--
<<<<<<< HEAD
Total number of stopped containers.
=======
Number of HTTP POST requests

>>>>>>> upstream/master

type: long

type: long

--

*`couchdb.server.httpd_request_methods.DELETE`*::
+
--
<<<<<<< HEAD
Total number of existing containers.
=======
Number of HTTP DELETE requests

>>>>>>> upstream/master

type: long

type: long

--

*`couchdb.server.httpd_request_methods.GET`*::
+
--
<<<<<<< HEAD
Unique Docker host identifier.
=======
Number of HTTP GET requests

>>>>>>> upstream/master

type: long

type: keyword

--

*`couchdb.server.httpd_request_methods.PUT`*::
+
--
<<<<<<< HEAD
Total number of existing images.
=======
Number of HTTP PUT requests

>>>>>>> upstream/master

type: long

type: long

--

[float]
<<<<<<< HEAD
=== memory
=======
=== httpd_status_codes
>>>>>>> upstream/master

HTTP status codes statistics



*`couchdb.server.httpd_status_codes.200`*::
+
--
<<<<<<< HEAD
Fail counter.
=======
Number of HTTP 200 OK responses

>>>>>>> upstream/master

type: long

type: scaled_float

--

*`couchdb.server.httpd_status_codes.201`*::
+
--
<<<<<<< HEAD
Memory limit.


type: long

format: bytes

--

[float]
=== rss

RSS memory stats.



*`docker.memory.rss.total`*::
+
--
Total memory resident set size.


type: long

format: bytes
=======
Number of HTTP 201 Created responses


type: long

--

*`couchdb.server.httpd_status_codes.202`*::
+
--
Number of HTTP 202 Accepted responses


type: long
>>>>>>> upstream/master

--

*`couchdb.server.httpd_status_codes.301`*::
+
--
<<<<<<< HEAD
Memory resident set size percentage.


type: scaled_float

format: percentage

--

[float]
=== usage

Usage memory stats.



*`docker.memory.usage.max`*::
+
--
Max memory usage.


type: long

format: bytes
=======
Number of HTTP 301 Moved Permanently responses


type: long

--

*`couchdb.server.httpd_status_codes.304`*::
+
--
Number of HTTP 304 Not Modified responses


type: long
>>>>>>> upstream/master

--

*`couchdb.server.httpd_status_codes.400`*::
+
--
<<<<<<< HEAD
Memory usage percentage.


type: scaled_float

format: percentage
=======
Number of HTTP 400 Bad Request responses


type: long
>>>>>>> upstream/master

--

*`couchdb.server.httpd_status_codes.401`*::
+
--
<<<<<<< HEAD
Total memory usage.


type: long

format: bytes

--

[float]
=== network

Network metrics.



*`docker.network.interface`*::
+
--
Network interface name.
=======
Number of HTTP 401 Unauthorized responses


type: long

--

*`couchdb.server.httpd_status_codes.403`*::
+
--
Number of HTTP 403 Forbidden responses

>>>>>>> upstream/master

type: long

type: keyword

--

<<<<<<< HEAD
[float]
=== in
=======
*`couchdb.server.httpd_status_codes.404`*::
+
--
Number of HTTP 404 Not Found responses
>>>>>>> upstream/master


type: long

--

*`couchdb.server.httpd_status_codes.405`*::
+
--
<<<<<<< HEAD
Total number of incoming bytes.


type: long

format: bytes
=======
Number of HTTP 405 Method Not Allowed responses


type: long
>>>>>>> upstream/master

--

*`couchdb.server.httpd_status_codes.409`*::
+
--
<<<<<<< HEAD
Total number of dropped incoming packets.
=======
Number of HTTP 409 Conflict responses

>>>>>>> upstream/master

type: long

type: scaled_float

--

*`couchdb.server.httpd_status_codes.412`*::
+
--
<<<<<<< HEAD
Total errors on incoming packets.
=======
Number of HTTP 412 Precondition Failed responses

>>>>>>> upstream/master

type: long

type: long

--

*`couchdb.server.httpd_status_codes.500`*::
+
--
<<<<<<< HEAD
Total number of incoming packets.
=======
Number of HTTP 500 Internal Server Error responses

>>>>>>> upstream/master

type: long

type: long

--

[float]
<<<<<<< HEAD
=== out
=======
=== couchdb
>>>>>>> upstream/master

couchdb statistics



*`couchdb.server.couchdb.database_writes`*::
+
--
<<<<<<< HEAD
Total number of outgoing bytes.


type: long

format: bytes
=======
Number of times a database was changed


type: long
>>>>>>> upstream/master

--

*`couchdb.server.couchdb.open_databases`*::
+
--
<<<<<<< HEAD
Total number of dropped outgoing packets.
=======
Number of open databases

>>>>>>> upstream/master

type: long

type: scaled_float

--

*`couchdb.server.couchdb.auth_cache_misses`*::
+
--
<<<<<<< HEAD
Total errors on outgoing packets.
=======
Number of authentication cache misses

>>>>>>> upstream/master

type: long

type: long

--

*`couchdb.server.couchdb.request_time`*::
+
--
<<<<<<< HEAD
Total number of outgoing packets.
=======
Length of a request inside CouchDB without MochiWeb

>>>>>>> upstream/master

type: long

type: long

--

<<<<<<< HEAD
[float]
=== inbound

Incoming network stats since the container started.



*`docker.network.inbound.bytes`*::
+
--
Total number of incoming bytes.


type: long

format: bytes
=======
*`couchdb.server.couchdb.database_reads`*::
+
--
Number of times a document was read from a database
>>>>>>> upstream/master


<<<<<<< HEAD
*`docker.network.inbound.dropped`*::
+
--
Total number of dropped incoming packets.


=======
>>>>>>> upstream/master
type: long

--

*`couchdb.server.couchdb.auth_cache_hits`*::
+
--
<<<<<<< HEAD
Total errors on incoming packets.
=======
Number of authentication cache hits

>>>>>>> upstream/master

type: long

type: long

--

*`couchdb.server.couchdb.open_os_files`*::
+
--
<<<<<<< HEAD
Total number of incoming packets.
=======
Number of file descriptors CouchDB has open

>>>>>>> upstream/master

type: long

type: long

--

<<<<<<< HEAD
[float]
=== outbound
=======
[[exported-fields-docker-processor]]
== Docker fields
>>>>>>> upstream/master

Docker stats collected from Docker.




*`docker.container.id`*::
+
--
<<<<<<< HEAD
Total number of outgoing bytes.


type: long

format: bytes
=======
type: alias

alias to: container.id
>>>>>>> upstream/master

--

*`docker.container.image`*::
+
--
<<<<<<< HEAD
Total number of dropped outgoing packets.
=======
type: alias
>>>>>>> upstream/master

alias to: container.image.name

type: long

--

*`docker.container.name`*::
+
--
<<<<<<< HEAD
Total errors on outgoing packets.
=======
type: alias
>>>>>>> upstream/master

alias to: container.name

type: long

--

*`docker.container.labels`*::
+
--
<<<<<<< HEAD
Total number of outgoing packets.
=======
Image labels.

>>>>>>> upstream/master

type: object

type: long

--

[[exported-fields-docker]]
== Docker fields

Docker stats collected from Docker.



[float]
<<<<<<< HEAD
=== dropwizard
=======
=== docker
>>>>>>> upstream/master

Information and statistics about docker's running containers.



[float]
=== container

Docker container metrics.



*`docker.container.command`*::
+
--
<<<<<<< HEAD
Date/time when the event originated.
This is the date/time extracted from the event, typically representing when the event was generated by the source.
If the event source has no original timestamp, this value is typically populated by the first time the event was received by the pipeline.
Required field for all events.

type: date

example: 2016-05-23T08:05:34.853Z
=======
Command that was executed in the Docker container.
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: keyword

>>>>>>> upstream/master
--

*`docker.container.created`*::
+
--
<<<<<<< HEAD
Custom key/value pairs.
Can be used to add meta information to events. Should not contain nested objects. All values are stored as keyword.
Example: `docker` and `k8s` labels.
=======
Date when the container was created.


type: date
>>>>>>> upstream/master

type: object

example: {'application': 'foo-bar', 'env': 'production'}

--

*`docker.container.status`*::
+
--
<<<<<<< HEAD
For log events the message field contains the log message, optimized for viewing in a log viewer.
For structured logs without an original message field, other fields can be concatenated to form a human-readable summary of the event.
If multiple messages exist, they can be combined into one message.
=======
Container status.


type: keyword
>>>>>>> upstream/master

type: text

example: Hello World

--

*`docker.container.ip_addresses`*::
+
--
<<<<<<< HEAD
List of keywords used to tag each event.

type: keyword
=======
Container IP addresses.
>>>>>>> upstream/master


<<<<<<< HEAD
--

[float]
=== agent
=======
type: ip

--

[float]
=== size
>>>>>>> upstream/master

Container size metrics.



*`docker.container.size.root_fs`*::
+
--
<<<<<<< HEAD
Ephemeral identifier of this agent (if one exists).
This id normally changes across restarts, but `agent.id` does not.

type: keyword
=======
Total size of all the files in the container.
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: long

>>>>>>> upstream/master
--

*`docker.container.size.rw`*::
+
--
<<<<<<< HEAD
Unique identifier of this agent (if one exists).
Example: For Beats this would be beat.id.

type: keyword
=======
Size of the files that have been created or changed since creation.
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: long

>>>>>>> upstream/master
--

*`docker.container.tags`*::
+
--
<<<<<<< HEAD
Custom name of the agent.
This is a name that can be given to an agent. This can be helpful if for example two Filebeat instances are running on the same host but a human readable separation is needed on which Filebeat instance data is coming from.
If no name is given, the name is often left empty.
=======
Image tags.


type: keyword
>>>>>>> upstream/master

type: keyword

example: foo

--

<<<<<<< HEAD
*`agent.type`*::
+
--
Type of the agent.
The agent type stays always the same and should be given by the agent used. In case of Filebeat the agent would always be Filebeat also if two Filebeat instances are run on the same machine.

type: keyword
=======
[float]
=== cpu
>>>>>>> upstream/master

Runtime CPU metrics.

<<<<<<< HEAD
--
=======

>>>>>>> upstream/master

*`docker.cpu.kernel.pct`*::
+
--
<<<<<<< HEAD
Version of the agent.

type: keyword

example: 6.0.0-rc2

--

[float]
=== client
=======
Percentage of time in kernel space.


type: scaled_float
>>>>>>> upstream/master

format: percent

--

*`docker.cpu.kernel.ticks`*::
+
--
<<<<<<< HEAD
Some event client addresses are defined ambiguously. The event will sometimes list an IP, a domain or a unix socket.  You should always store the raw address in the `.address` field.
Then it should be duplicated to `.ip` or `.domain`, depending on which one it is.
=======
CPU ticks in kernel space.


type: long
>>>>>>> upstream/master

type: keyword

--

*`docker.cpu.system.pct`*::
+
--
<<<<<<< HEAD
Bytes sent from the client to the server.

type: long
=======
Percentage of total CPU time in the system.
>>>>>>> upstream/master


type: scaled_float

<<<<<<< HEAD
=======
format: percent

>>>>>>> upstream/master
--

*`docker.cpu.system.ticks`*::
+
--
<<<<<<< HEAD
Client domain.
=======
CPU system ticks.


type: long
>>>>>>> upstream/master

type: keyword

--

*`docker.cpu.user.pct`*::
+
--
<<<<<<< HEAD
City name.

type: keyword
=======
Percentage of time in user space.
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: scaled_float

format: percent

>>>>>>> upstream/master
--

*`docker.cpu.user.ticks`*::
+
--
<<<<<<< HEAD
Name of the continent.

type: keyword
=======
CPU ticks in user space.
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: long

>>>>>>> upstream/master
--

*`docker.cpu.total.pct`*::
+
--
<<<<<<< HEAD
Country ISO code.

type: keyword
=======
Total CPU usage.
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: scaled_float

format: percent

>>>>>>> upstream/master
--

*`docker.cpu.core.*.pct`*::
+
--
<<<<<<< HEAD
Country name.

type: keyword
=======
Percentage of CPU time in this core.
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: object

format: percent

>>>>>>> upstream/master
--

*`docker.cpu.core.*.ticks`*::
+
--
<<<<<<< HEAD
Longitude and latitude.

type: geo_point
=======
Number of CPU ticks in this core.
>>>>>>> upstream/master


<<<<<<< HEAD
--

*`client.geo.name`*::
+
--
User-defined description of a location, at the level of granularity they care about.
Could be the name of their data centers, the floor number, if this describes a local physical entity, city names.
Not typically used in automated geolocation.

type: keyword

example: boston-dc

--

*`client.geo.region_iso_code`*::
+
--
Region ISO code.

type: keyword
=======
type: object

--

[float]
=== diskio

Disk I/O metrics.



[float]
=== read
>>>>>>> upstream/master

Accumulated reads during the life of the container

<<<<<<< HEAD
--
=======

>>>>>>> upstream/master

*`docker.diskio.read.ops`*::
+
--
<<<<<<< HEAD
Region name.

type: keyword
=======
Number of reads during the life of the container
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: long

>>>>>>> upstream/master
--

*`docker.diskio.read.bytes`*::
+
--
<<<<<<< HEAD
IP address of the client.
Can be one or multiple IPv4 or IPv6 addresses.
=======
Bytes read during the life of the container


type: long

format: bytes
>>>>>>> upstream/master

type: ip

--

*`docker.diskio.read.rate`*::
+
--
<<<<<<< HEAD
MAC address of the client.
=======
Number of current reads per second


type: long
>>>>>>> upstream/master

type: keyword

--

*`docker.diskio.reads`*::
+
--
<<<<<<< HEAD
Packets sent from the client to the server.

type: long
=======
>>>>>>> upstream/master

deprecated[6.4]

<<<<<<< HEAD
=======
Number of current reads per second


type: scaled_float

>>>>>>> upstream/master
--

[float]
=== write

Accumulated writes during the life of the container



*`docker.diskio.write.ops`*::
+
--
<<<<<<< HEAD
Port of the client.
=======
Number of writes during the life of the container


type: long
>>>>>>> upstream/master

type: long

--

*`docker.diskio.write.bytes`*::
+
--
<<<<<<< HEAD
User email address.
=======
Bytes written during the life of the container


type: long

format: bytes
>>>>>>> upstream/master

type: keyword

--

*`docker.diskio.write.rate`*::
+
--
<<<<<<< HEAD
User's full name, if available.

type: keyword
=======
Number of current writes per second
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: long

>>>>>>> upstream/master
--

*`docker.diskio.writes`*::
+
--
<<<<<<< HEAD
Unique identifier for the group on the system/platform.
=======

deprecated[6.4]

Number of current writes per second


type: scaled_float
>>>>>>> upstream/master

type: keyword

--

[float]
=== summary

Accumulated reads and writes during the life of the container



*`docker.diskio.summary.ops`*::
+
--
<<<<<<< HEAD
Name of the group.
=======
Number of I/O operations during the life of the container


type: long
>>>>>>> upstream/master

type: keyword

--

*`docker.diskio.summary.bytes`*::
+
--
<<<<<<< HEAD
Unique user hash to correlate information for a user in anonymized form.
Useful if `user.id` or `user.name` contain confidential information and cannot be used.
=======
Bytes read and written during the life of the container


type: long

format: bytes
>>>>>>> upstream/master

type: keyword

--

*`docker.diskio.summary.rate`*::
+
--
<<<<<<< HEAD
One or multiple unique identifiers of the user.
=======
Number of current operations per second


type: long
>>>>>>> upstream/master

type: keyword

--

*`docker.diskio.total`*::
+
--
<<<<<<< HEAD
Short name or login of the user.

type: keyword
=======
>>>>>>> upstream/master

deprecated[6.4]

<<<<<<< HEAD
--

[float]
=== cloud
=======
Number of reads and writes per second


type: scaled_float

--

[float]
=== event
>>>>>>> upstream/master

Docker event



*`docker.event.status`*::
+
--
<<<<<<< HEAD
The cloud account or organization id used to identify different entities in a multi-tenant environment.
Examples: AWS account id, Google Cloud ORG Id, or other unique identifier.

type: keyword
=======
Event status
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: keyword

>>>>>>> upstream/master
--

*`docker.event.id`*::
+
--
<<<<<<< HEAD
Availability zone in which this host is running.

type: keyword
=======
Event id when available
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: keyword

>>>>>>> upstream/master
--

*`docker.event.from`*::
+
--
<<<<<<< HEAD
Instance ID of the host machine.

type: keyword
=======
Event source
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: keyword

>>>>>>> upstream/master
--

*`docker.event.type`*::
+
--
<<<<<<< HEAD
Instance name of the host machine.
=======
The type of object emitting the event


type: keyword
>>>>>>> upstream/master

type: keyword

--

*`docker.event.action`*::
+
--
<<<<<<< HEAD
Machine type of the host machine.

type: keyword
=======
The type of event
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: keyword

>>>>>>> upstream/master
--

[float]
=== actor

Actor



*`docker.event.actor.id`*::
+
--
<<<<<<< HEAD
Name of the cloud provider. Example values are aws, azure, gcp, or digitalocean.

type: keyword
=======
The ID of the object emitting the event
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: keyword

>>>>>>> upstream/master
--

*`docker.event.actor.attributes`*::
+
--
<<<<<<< HEAD
Region in which this host is running.

type: keyword
=======
Various key/value attributes of the object, depending on its type
>>>>>>> upstream/master


<<<<<<< HEAD
--

[float]
=== container
=======
type: object

--

[float]
=== healthcheck
>>>>>>> upstream/master

Docker healthcheck metrics.
Healthcheck data will only be available from docker containers where the docker `HEALTHCHECK` instruction has been used to build the docker image.



*`docker.healthcheck.failingstreak`*::
+
--
<<<<<<< HEAD
Unique container id.
=======
concurent failed check


type: integer
>>>>>>> upstream/master

type: keyword

--

*`docker.healthcheck.status`*::
+
--
<<<<<<< HEAD
Name of the image the container was built on.
=======
Healthcheck status code


type: keyword
>>>>>>> upstream/master

type: keyword

--

[float]
=== event

event fields.



*`docker.healthcheck.event.end_date`*::
+
--
<<<<<<< HEAD
Container image tag.
=======
Healthcheck end date


type: date
>>>>>>> upstream/master

type: keyword

--

*`docker.healthcheck.event.start_date`*::
+
--
<<<<<<< HEAD
Image labels.
=======
Healthcheck start date


type: date
>>>>>>> upstream/master

type: object

--

*`docker.healthcheck.event.output`*::
+
--
<<<<<<< HEAD
Container name.
=======
Healthcheck output


type: keyword
>>>>>>> upstream/master

type: keyword

--

*`docker.healthcheck.event.exit_code`*::
+
--
<<<<<<< HEAD
Runtime managing this container.

type: keyword
=======
Healthcheck status code
>>>>>>> upstream/master


<<<<<<< HEAD
--

[float]
=== destination
=======
type: integer

--

[float]
=== image
>>>>>>> upstream/master

Docker image metrics.


<<<<<<< HEAD
*`destination.address`*::
+
--
Some event destination addresses are defined ambiguously. The event will sometimes list an IP, a domain or a unix socket.  You should always store the raw address in the `.address` field.
Then it should be duplicated to `.ip` or `.domain`, depending on which one it is.

type: keyword

--
=======

[float]
=== id

The image layers identifier.
>>>>>>> upstream/master



*`docker.image.id.current`*::
+
--
<<<<<<< HEAD
Bytes sent from the destination to the source.

type: long

example: 184
=======
Unique image identifier given upon its creation.
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: keyword

>>>>>>> upstream/master
--

*`docker.image.id.parent`*::
+
--
<<<<<<< HEAD
Destination domain.
=======
Identifier of the image, if it exists, from which the current image directly descends.


type: keyword
>>>>>>> upstream/master

type: keyword

--

*`docker.image.created`*::
+
--
<<<<<<< HEAD
=======
Date and time when the image was created.


type: date

--

[float]
=== size

Image size layers.



*`docker.image.size.virtual`*::
+
--
Size of the image.


type: long

--

*`docker.image.size.regular`*::
+
--
Total size of the all cached images associated to the current image.


type: long

--

*`docker.image.labels`*::
+
--
Image labels.


type: object

--

*`docker.image.tags`*::
+
--
Image tags.


type: keyword

--

[float]
=== info

Info metrics based on https://docs.docker.com/engine/reference/api/docker_remote_api_v1.24/#/display-system-wide-information.



[float]
=== containers

Overall container stats.



*`docker.info.containers.paused`*::
+
--
Total number of paused containers.


type: long

--

*`docker.info.containers.running`*::
+
--
Total number of running containers.


type: long

--

*`docker.info.containers.stopped`*::
+
--
Total number of stopped containers.


type: long

--

*`docker.info.containers.total`*::
+
--
Total number of existing containers.


type: long

--

*`docker.info.id`*::
+
--
Unique Docker host identifier.


type: keyword

--

*`docker.info.images`*::
+
--
Total number of existing images.


type: long

--

[float]
=== memory

Memory metrics.



*`docker.memory.stats.*`*::
+
--
Raw memory stats from the cgroups memory.stat interface


type: object

--

[float]
=== commit

Committed bytes on Windows



*`docker.memory.commit.total`*::
+
--
Total bytes


type: long

format: bytes

--

*`docker.memory.commit.peak`*::
+
--
Peak committed bytes on Windows


type: long

format: bytes

--

*`docker.memory.private_working_set.total`*::
+
--
private working sets on Windows


type: long

format: bytes

--

*`docker.memory.fail.count`*::
+
--
Fail counter.


type: scaled_float

--

*`docker.memory.limit`*::
+
--
Memory limit.


type: long

format: bytes

--

[float]
=== rss

RSS memory stats.



*`docker.memory.rss.total`*::
+
--
Total memory resident set size.


type: long

format: bytes

--

*`docker.memory.rss.pct`*::
+
--
Memory resident set size percentage.


type: scaled_float

format: percent

--

[float]
=== usage

Usage memory stats.



*`docker.memory.usage.max`*::
+
--
Max memory usage.


type: long

format: bytes

--

*`docker.memory.usage.pct`*::
+
--
Memory usage percentage.


type: scaled_float

format: percent

--

*`docker.memory.usage.total`*::
+
--
Total memory usage.


type: long

format: bytes

--

[float]
=== network

Network metrics.



*`docker.network.interface`*::
+
--
Network interface name.


type: keyword

--

[float]
=== in

Incoming network stats per second.



*`docker.network.in.bytes`*::
+
--
Total number of incoming bytes.


type: long

format: bytes

--

*`docker.network.in.dropped`*::
+
--
Total number of dropped incoming packets.


type: scaled_float

--

*`docker.network.in.errors`*::
+
--
Total errors on incoming packets.


type: long

--

*`docker.network.in.packets`*::
+
--
Total number of incoming packets.


type: long

--

[float]
=== out

Outgoing network stats per second.



*`docker.network.out.bytes`*::
+
--
Total number of outgoing bytes.


type: long

format: bytes

--

*`docker.network.out.dropped`*::
+
--
Total number of dropped outgoing packets.


type: scaled_float

--

*`docker.network.out.errors`*::
+
--
Total errors on outgoing packets.


type: long

--

*`docker.network.out.packets`*::
+
--
Total number of outgoing packets.


type: long

--

[float]
=== inbound

Incoming network stats since the container started.



*`docker.network.inbound.bytes`*::
+
--
Total number of incoming bytes.


type: long

format: bytes

--

*`docker.network.inbound.dropped`*::
+
--
Total number of dropped incoming packets.


type: long

--

*`docker.network.inbound.errors`*::
+
--
Total errors on incoming packets.


type: long

--

*`docker.network.inbound.packets`*::
+
--
Total number of incoming packets.


type: long

--

[float]
=== outbound

Outgoing network stats since the container started.



*`docker.network.outbound.bytes`*::
+
--
Total number of outgoing bytes.


type: long

format: bytes

--

*`docker.network.outbound.dropped`*::
+
--
Total number of dropped outgoing packets.


type: long

--

*`docker.network.outbound.errors`*::
+
--
Total errors on outgoing packets.


type: long

--

*`docker.network.outbound.packets`*::
+
--
Total number of outgoing packets.


type: long

--

[[exported-fields-dropwizard]]
== Dropwizard fields

Stats collected from Dropwizard.



[float]
=== dropwizard




[[exported-fields-ecs]]
== ECS fields

ECS Fields.


*`@timestamp`*::
+
--
Date/time when the event originated.
This is the date/time extracted from the event, typically representing when the event was generated by the source.
If the event source has no original timestamp, this value is typically populated by the first time the event was received by the pipeline.
Required field for all events.

type: date

example: 2016-05-23T08:05:34.853Z

required: True

--

*`labels`*::
+
--
Custom key/value pairs.
Can be used to add meta information to events. Should not contain nested objects. All values are stored as keyword.
Example: `docker` and `k8s` labels.

type: object

example: {'application': 'foo-bar', 'env': 'production'}

--

*`message`*::
+
--
For log events the message field contains the log message, optimized for viewing in a log viewer.
For structured logs without an original message field, other fields can be concatenated to form a human-readable summary of the event.
If multiple messages exist, they can be combined into one message.

type: text

example: Hello World

--

*`tags`*::
+
--
List of keywords used to tag each event.

type: keyword

example: ["production", "env2"]

--

[float]
=== agent

The agent fields contain the data about the software entity, if any, that collects, detects, or observes events on a host, or takes measurements on a host.
Examples include Beats. Agents may also run on observers. ECS agent.* fields shall be populated with details of the agent running on the host or observer where the event happened or the measurement was taken.


*`agent.ephemeral_id`*::
+
--
Ephemeral identifier of this agent (if one exists).
This id normally changes across restarts, but `agent.id` does not.

type: keyword

example: 8a4f500f

--

*`agent.id`*::
+
--
Unique identifier of this agent (if one exists).
Example: For Beats this would be beat.id.

type: keyword

example: 8a4f500d

--

*`agent.name`*::
+
--
Custom name of the agent.
This is a name that can be given to an agent. This can be helpful if for example two Filebeat instances are running on the same host but a human readable separation is needed on which Filebeat instance data is coming from.
If no name is given, the name is often left empty.

type: keyword

example: foo

--

*`agent.type`*::
+
--
Type of the agent.
The agent type stays always the same and should be given by the agent used. In case of Filebeat the agent would always be Filebeat also if two Filebeat instances are run on the same machine.

type: keyword

example: filebeat

--

*`agent.version`*::
+
--
Version of the agent.

type: keyword

example: 6.0.0-rc2

--

[float]
=== client

A client is defined as the initiator of a network connection for events regarding sessions, connections, or bidirectional flow records.
For TCP events, the client is the initiator of the TCP connection that sends the SYN packet(s). For other protocols, the client is generally the initiator or requestor in the network transaction. Some systems use the term "originator" to refer the client in TCP connections. The client fields describe details about the system acting as the client in the network event. Client fields are usually populated in conjunction with server fields. Client fields are generally not populated for packet-level events.
Client / server representations can add semantic context to an exchange, which is helpful to visualize the data in certain situations. If your context falls in that category, you should still ensure that source and destination are filled appropriately.


*`client.address`*::
+
--
Some event client addresses are defined ambiguously. The event will sometimes list an IP, a domain or a unix socket.  You should always store the raw address in the `.address` field.
Then it should be duplicated to `.ip` or `.domain`, depending on which one it is.

type: keyword

--

*`client.bytes`*::
+
--
Bytes sent from the client to the server.

type: long

example: 184

format: bytes

--

*`client.domain`*::
+
--
Client domain.

type: keyword

--

*`client.geo.city_name`*::
+
--
City name.

type: keyword

example: Montreal

--

*`client.geo.continent_name`*::
+
--
Name of the continent.

type: keyword

example: North America

--

*`client.geo.country_iso_code`*::
+
--
Country ISO code.

type: keyword

example: CA

--

*`client.geo.country_name`*::
+
--
Country name.

type: keyword

example: Canada

--

*`client.geo.location`*::
+
--
Longitude and latitude.

type: geo_point

example: { "lon": -73.614830, "lat": 45.505918 }

--

*`client.geo.name`*::
+
--
User-defined description of a location, at the level of granularity they care about.
Could be the name of their data centers, the floor number, if this describes a local physical entity, city names.
Not typically used in automated geolocation.

type: keyword

example: boston-dc

--

*`client.geo.region_iso_code`*::
+
--
Region ISO code.

type: keyword

example: CA-QC

--

*`client.geo.region_name`*::
+
--
Region name.

type: keyword

example: Quebec

--

*`client.ip`*::
+
--
IP address of the client.
Can be one or multiple IPv4 or IPv6 addresses.

type: ip

--

*`client.mac`*::
+
--
MAC address of the client.

type: keyword

--

*`client.packets`*::
+
--
Packets sent from the client to the server.

type: long

example: 12

--

*`client.port`*::
+
--
Port of the client.

type: long

format: string

--

*`client.user.email`*::
+
--
User email address.

type: keyword

--

*`client.user.full_name`*::
+
--
User's full name, if available.

type: keyword

example: Albert Einstein

--

*`client.user.group.id`*::
+
--
Unique identifier for the group on the system/platform.

type: keyword

--

*`client.user.group.name`*::
+
--
Name of the group.

type: keyword

--

*`client.user.hash`*::
+
--
Unique user hash to correlate information for a user in anonymized form.
Useful if `user.id` or `user.name` contain confidential information and cannot be used.

type: keyword

--

*`client.user.id`*::
+
--
One or multiple unique identifiers of the user.

type: keyword

--

*`client.user.name`*::
+
--
Short name or login of the user.

type: keyword

example: albert

--

[float]
=== cloud

Fields related to the cloud or infrastructure the events are coming from.


*`cloud.account.id`*::
+
--
The cloud account or organization id used to identify different entities in a multi-tenant environment.
Examples: AWS account id, Google Cloud ORG Id, or other unique identifier.

type: keyword

example: 666777888999

--

*`cloud.availability_zone`*::
+
--
Availability zone in which this host is running.

type: keyword

example: us-east-1c

--

*`cloud.instance.id`*::
+
--
Instance ID of the host machine.

type: keyword

example: i-1234567890abcdef0

--

*`cloud.instance.name`*::
+
--
Instance name of the host machine.

type: keyword

--

*`cloud.machine.type`*::
+
--
Machine type of the host machine.

type: keyword

example: t2.medium

--

*`cloud.provider`*::
+
--
Name of the cloud provider. Example values are aws, azure, gcp, or digitalocean.

type: keyword

example: aws

--

*`cloud.region`*::
+
--
Region in which this host is running.

type: keyword

example: us-east-1

--

[float]
=== container

Container fields are used for meta information about the specific container that is the source of information.
These fields help correlate data based containers from any runtime.


*`container.id`*::
+
--
Unique container id.

type: keyword

--

*`container.image.name`*::
+
--
Name of the image the container was built on.

type: keyword

--

*`container.image.tag`*::
+
--
Container image tag.

type: keyword

--

*`container.labels`*::
+
--
Image labels.

type: object

--

*`container.name`*::
+
--
Container name.

type: keyword

--

*`container.runtime`*::
+
--
Runtime managing this container.

type: keyword

example: docker

--

[float]
=== destination

Destination fields describe details about the destination of a packet/event.
Destination fields are usually populated in conjunction with source fields.


*`destination.address`*::
+
--
Some event destination addresses are defined ambiguously. The event will sometimes list an IP, a domain or a unix socket.  You should always store the raw address in the `.address` field.
Then it should be duplicated to `.ip` or `.domain`, depending on which one it is.

type: keyword

--

*`destination.bytes`*::
+
--
Bytes sent from the destination to the source.

type: long

example: 184

format: bytes

--

*`destination.domain`*::
+
--
Destination domain.

type: keyword

--

*`destination.geo.city_name`*::
+
--
City name.

type: keyword

example: Montreal

--

*`destination.geo.continent_name`*::
+
--
Name of the continent.

type: keyword

example: North America

--

*`destination.geo.country_iso_code`*::
+
--
Country ISO code.

type: keyword

example: CA

--

*`destination.geo.country_name`*::
+
--
Country name.

type: keyword

example: Canada

--

*`destination.geo.location`*::
+
--
Longitude and latitude.

type: geo_point

example: { "lon": -73.614830, "lat": 45.505918 }

--

*`destination.geo.name`*::
+
--
User-defined description of a location, at the level of granularity they care about.
Could be the name of their data centers, the floor number, if this describes a local physical entity, city names.
Not typically used in automated geolocation.

type: keyword

example: boston-dc

--

*`destination.geo.region_iso_code`*::
+
--
Region ISO code.

type: keyword

example: CA-QC

--

*`destination.geo.region_name`*::
+
--
Region name.

type: keyword

example: Quebec

--

*`destination.ip`*::
+
--
IP address of the destination.
Can be one or multiple IPv4 or IPv6 addresses.

type: ip

--

*`destination.mac`*::
+
--
MAC address of the destination.

type: keyword

--

*`destination.packets`*::
+
--
Packets sent from the destination to the source.

type: long

example: 12

--

*`destination.port`*::
+
--
Port of the destination.

type: long

format: string

--

*`destination.user.email`*::
+
--
User email address.

type: keyword

--

*`destination.user.full_name`*::
+
--
User's full name, if available.

type: keyword

example: Albert Einstein

--

*`destination.user.group.id`*::
+
--
Unique identifier for the group on the system/platform.

type: keyword

--

*`destination.user.group.name`*::
+
--
Name of the group.

type: keyword

--

*`destination.user.hash`*::
+
--
Unique user hash to correlate information for a user in anonymized form.
Useful if `user.id` or `user.name` contain confidential information and cannot be used.

type: keyword

--

*`destination.user.id`*::
+
--
One or multiple unique identifiers of the user.

type: keyword

--

*`destination.user.name`*::
+
--
Short name or login of the user.

type: keyword

example: albert

--

[float]
=== ecs

Meta-information specific to ECS.


*`ecs.version`*::
+
--
ECS version this event conforms to. `ecs.version` is a required field and must exist in all events.
When querying across multiple indices -- which may conform to slightly different ECS versions -- this field lets integrations adjust to the schema version of the events.

type: keyword

example: 1.0.0

required: True

--

[float]
=== error

These fields can represent errors of any kind.
Use them for errors that happen while fetching events or in cases where the event itself contains an error.


*`error.code`*::
+
--
Error code describing the error.

type: keyword

--

*`error.id`*::
+
--
Unique identifier for the error.

type: keyword

--

*`error.message`*::
+
--
Error message.

type: text

--

[float]
=== event

The event fields are used for context information about the log or metric event itself.
A log is defined as an event containing details of something that happened. Log events must include the time at which the thing happened. Examples of log events include a process starting on a host, a network packet being sent from a source to a destination, or a network connection between a client and a server being initiated or closed. A metric is defined as an event containing one or more numerical or categorical measurements and the time at which the measurement was taken. Examples of metric events include memory pressure measured on a host, or vulnerabilities measured on a scanned host.


*`event.action`*::
+
--
The action captured by the event.
This describes the information in the event. It is more specific than `event.category`. Examples are `group-add`, `process-started`, `file-created`. The value is normally defined by the implementer.

type: keyword

example: user-password-change

--

*`event.category`*::
+
--
Event category.
This contains high-level information about the contents of the event. It is more generic than `event.action`, in the sense that typically a category contains multiple actions. Warning: In future versions of ECS, we plan to provide a list of acceptable values for this field, please use with caution.

type: keyword

example: user-management

--

*`event.created`*::
+
--
event.created contains the date/time when the event was first read by an agent, or by your pipeline.
This field is distinct from @timestamp in that @timestamp typically contain the time extracted from the original event.
In most situations, these two timestamps will be slightly different. The difference can be used to calculate the delay between your source generating an event, and the time when your agent first processed it. This can be used to monitor your agent's or pipeline's ability to keep up with your event source.
In case the two timestamps are identical, @timestamp should be used.

type: date

--

*`event.dataset`*::
+
--
Name of the dataset.
The concept of a `dataset` (fileset / metricset) is used in Beats as a subset of modules. It contains the information which is currently stored in metricset.name and metricset.module or fileset.name.

type: keyword

example: stats

--

*`event.duration`*::
+
--
Duration of the event in nanoseconds.
If event.start and event.end are known this value should be the difference between the end and start time.

type: long

format: duration

--

*`event.end`*::
+
--
event.end contains the date when the event ended or when the activity was last observed.

type: date

--

*`event.hash`*::
+
--
Hash (perhaps logstash fingerprint) of raw field to be able to demonstrate log integrity.

type: keyword

example: 123456789012345678901234567890ABCD

--

*`event.id`*::
+
--
Unique ID to describe the event.

type: keyword

example: 8a4f500d

--

*`event.kind`*::
+
--
The kind of the event.
This gives information about what type of information the event contains, without being specific to the contents of the event.  Examples are `event`, `state`, `alarm`. Warning: In future versions of ECS, we plan to provide a list of acceptable values for this field, please use with caution.

type: keyword

example: state

--

*`event.module`*::
+
--
Name of the module this data is coming from.
This information is coming from the modules used in Beats or Logstash.

type: keyword

example: mysql

--

*`event.original`*::
+
--
Raw text message of entire event. Used to demonstrate log integrity.
This field is not indexed and doc_values are disabled. It cannot be searched, but it can be retrieved from `_source`.

type: keyword

example: Sep 19 08:26:10 host CEF:0&#124;Security&#124; threatmanager&#124;1.0&#124;100&#124; worm successfully stopped&#124;10&#124;src=10.0.0.1 dst=2.1.2.2spt=1232

--

*`event.outcome`*::
+
--
The outcome of the event.
If the event describes an action, this fields contains the outcome of that action. Examples outcomes are `success` and `failure`. Warning: In future versions of ECS, we plan to provide a list of acceptable values for this field, please use with caution.

type: keyword

example: success

--

*`event.risk_score`*::
+
--
Risk score or priority of the event (e.g. security solutions). Use your system's original value here.

type: float

--

*`event.risk_score_norm`*::
+
--
Normalized risk score or priority of the event, on a scale of 0 to 100.
This is mainly useful if you use more than one system that assigns risk scores, and you want to see a normalized value across all systems.

type: float

--

*`event.severity`*::
+
--
Severity describes the original severity of the event. What the different severity values mean can very different between use cases. It's up to the implementer to make sure severities are consistent across events.

type: long

example: 7

format: string

--

*`event.start`*::
+
--
event.start contains the date when the event started or when the activity was first observed.

type: date

--

*`event.timezone`*::
+
--
This field should be populated when the event's timestamp does not include timezone information already (e.g. default Syslog timestamps). It's optional otherwise.
Acceptable timezone formats are: a canonical ID (e.g. "Europe/Amsterdam"), abbreviated (e.g. "EST") or an HH:mm differential (e.g. "-05:00").

type: keyword

--

*`event.type`*::
+
--
Reserved for future usage.
Please avoid using this field for user data.

type: keyword

--

[float]
=== file

A file is defined as a set of information that has been created on, or has existed on a filesystem.
File objects can be associated with host events, network events, and/or file events (e.g., those produced by File Integrity Monitoring [FIM] products or services). File fields provide details about the affected file associated with the event or metric.


*`file.ctime`*::
+
--
Last time file metadata changed.

type: date

--

*`file.device`*::
+
--
Device that is the source of the file.

type: keyword

--

*`file.extension`*::
+
--
File extension.
This should allow easy filtering by file extensions.

type: keyword

example: png

--

*`file.gid`*::
+
--
Primary group ID (GID) of the file.

type: keyword

--

*`file.group`*::
+
--
Primary group name of the file.

type: keyword

--

*`file.inode`*::
+
--
Inode representing the file in the filesystem.

type: keyword

--

*`file.mode`*::
+
--
Mode of the file in octal representation.

type: keyword

example: 416

--

*`file.mtime`*::
+
--
Last time file content was modified.

type: date

--

*`file.owner`*::
+
--
File owner's username.

type: keyword

--

*`file.path`*::
+
--
Path to the file.

type: keyword

--

*`file.size`*::
+
--
File size in bytes (field is only added when `type` is `file`).

type: long

--

*`file.target_path`*::
+
--
Target path for symlinks.

type: keyword

--

*`file.type`*::
+
--
File type (file, dir, or symlink).

type: keyword

--

*`file.uid`*::
+
--
The user ID (UID) or security identifier (SID) of the file owner.

type: keyword

--

[float]
=== geo

Geo fields can carry data about a specific location related to an event.
This geolocation information can be derived from techniques such as Geo IP, or be user-supplied.


*`geo.city_name`*::
+
--
City name.

type: keyword

example: Montreal

--

*`geo.continent_name`*::
+
--
Name of the continent.

type: keyword

example: North America

--

*`geo.country_iso_code`*::
+
--
Country ISO code.

type: keyword

example: CA

--

*`geo.country_name`*::
+
--
Country name.

type: keyword

example: Canada

--

*`geo.location`*::
+
--
Longitude and latitude.

type: geo_point

example: { "lon": -73.614830, "lat": 45.505918 }

--

*`geo.name`*::
+
--
User-defined description of a location, at the level of granularity they care about.
Could be the name of their data centers, the floor number, if this describes a local physical entity, city names.
Not typically used in automated geolocation.

type: keyword

example: boston-dc

--

*`geo.region_iso_code`*::
+
--
Region ISO code.

type: keyword

example: CA-QC

--

*`geo.region_name`*::
+
--
Region name.

type: keyword

example: Quebec

--

[float]
=== group

The group fields are meant to represent groups that are relevant to the event.


*`group.id`*::
+
--
Unique identifier for the group on the system/platform.

type: keyword

--

*`group.name`*::
+
--
Name of the group.

type: keyword

--

[float]
=== host

A host is defined as a general computing instance.
ECS host.* fields should be populated with details about the host on which the event happened, or from which the measurement was taken. Host types include hardware, virtual machines, Docker containers, and Kubernetes nodes.


*`host.architecture`*::
+
--
Operating system architecture.

type: keyword

example: x86_64

--

*`host.geo.city_name`*::
+
--
City name.

type: keyword

example: Montreal

--

*`host.geo.continent_name`*::
+
--
Name of the continent.

type: keyword

example: North America

--

*`host.geo.country_iso_code`*::
+
--
Country ISO code.

type: keyword

example: CA

--

*`host.geo.country_name`*::
+
--
Country name.

type: keyword

example: Canada

--

*`host.geo.location`*::
+
--
Longitude and latitude.

type: geo_point

example: { "lon": -73.614830, "lat": 45.505918 }

--

*`host.geo.name`*::
+
--
User-defined description of a location, at the level of granularity they care about.
Could be the name of their data centers, the floor number, if this describes a local physical entity, city names.
Not typically used in automated geolocation.

type: keyword

example: boston-dc

--

*`host.geo.region_iso_code`*::
+
--
Region ISO code.

type: keyword

example: CA-QC

--

*`host.geo.region_name`*::
+
--
Region name.

type: keyword

example: Quebec

--

*`host.hostname`*::
+
--
Hostname of the host.
It normally contains what the `hostname` command returns on the host machine.

type: keyword

--

*`host.id`*::
+
--
Unique host id.
As hostname is not always unique, use values that are meaningful in your environment.
Example: The current usage of `beat.name`.

type: keyword

--

*`host.ip`*::
+
--
Host ip address.

type: ip

--

*`host.mac`*::
+
--
Host mac address.

type: keyword

--

*`host.name`*::
+
--
Name of the host.
It can contain what `hostname` returns on Unix systems, the fully qualified domain name, or a name specified by the user. The sender decides which value to use.

type: keyword

--

*`host.os.family`*::
+
--
OS family (such as redhat, debian, freebsd, windows).

type: keyword

example: debian

--

*`host.os.full`*::
+
--
Operating system name, including the version or code name.

type: keyword

example: Mac OS Mojave

--

*`host.os.kernel`*::
+
--
Operating system kernel version as a raw string.

type: keyword

example: 4.4.0-112-generic

--

*`host.os.name`*::
+
--
Operating system name, without the version.

type: keyword

example: Mac OS X

--

*`host.os.platform`*::
+
--
Operating system platform (such centos, ubuntu, windows).

type: keyword

example: darwin

--

*`host.os.version`*::
+
--
Operating system version as a raw string.

type: keyword

example: 10.14.1

--

*`host.type`*::
+
--
Type of host.
For Cloud providers this can be the machine type like `t2.medium`. If vm, this could be the container, for example, or other information meaningful in your environment.

type: keyword

--

*`host.user.email`*::
+
--
User email address.

type: keyword

--

*`host.user.full_name`*::
+
--
User's full name, if available.

type: keyword

example: Albert Einstein

--

*`host.user.group.id`*::
+
--
Unique identifier for the group on the system/platform.

type: keyword

--

*`host.user.group.name`*::
+
--
Name of the group.

type: keyword

--

*`host.user.hash`*::
+
--
Unique user hash to correlate information for a user in anonymized form.
Useful if `user.id` or `user.name` contain confidential information and cannot be used.

type: keyword

--

*`host.user.id`*::
+
--
One or multiple unique identifiers of the user.

type: keyword

--

*`host.user.name`*::
+
--
Short name or login of the user.

type: keyword

example: albert

--

[float]
=== http

Fields related to HTTP activity. Use the `url` field set to store the url of the request.


*`http.request.body.bytes`*::
+
--
Size in bytes of the request body.

type: long

example: 887

format: bytes

--

*`http.request.body.content`*::
+
--
The full HTTP request body.

type: keyword

example: Hello world

--

*`http.request.bytes`*::
+
--
Total size in bytes of the request (body and headers).

type: long

example: 1437

format: bytes

--

*`http.request.method`*::
+
--
HTTP request method.
The field value must be normalized to lowercase for querying. See the documentation section "Implementing ECS".

type: keyword

example: get, post, put

--

*`http.request.referrer`*::
+
--
Referrer for this HTTP request.

type: keyword

example: https://blog.example.com/

--

*`http.response.body.bytes`*::
+
--
Size in bytes of the response body.

type: long

example: 887

format: bytes

--

*`http.response.body.content`*::
+
--
The full HTTP response body.

type: keyword

example: Hello world

--

*`http.response.bytes`*::
+
--
Total size in bytes of the response (body and headers).

type: long

example: 1437

format: bytes

--

*`http.response.status_code`*::
+
--
HTTP response status code.

type: long

example: 404

format: string

--

*`http.version`*::
+
--
HTTP version.

type: keyword

example: 1.1

--

[float]
=== log

Fields which are specific to log events.


*`log.level`*::
+
--
Original log level of the log event.
Some examples are `warn`, `error`, `i`.

type: keyword

example: err

--

*`log.original`*::
+
--
This is the original log message and contains the full log message before splitting it up in multiple parts.
In contrast to the `message` field which can contain an extracted part of the log message, this field contains the original, full log message. It can have already some modifications applied like encoding or new lines removed to clean up the log message.
This field is not indexed and doc_values are disabled so it can't be queried but the value can be retrieved from `_source`.

type: keyword

example: Sep 19 08:26:10 localhost My log

--

[float]
=== network

The network is defined as the communication path over which a host or network event happens.
The network.* fields should be populated with details about the network activity associated with an event.


*`network.application`*::
+
--
A name given to an application level protocol. This can be arbitrarily assigned for things like microservices, but also apply to things like skype, icq, facebook, twitter. This would be used in situations where the vendor or service can be decoded such as from the source/dest IP owners, ports, or wire format.
The field value must be normalized to lowercase for querying. See the documentation section "Implementing ECS".

type: keyword

example: aim

--

*`network.bytes`*::
+
--
Total bytes transferred in both directions.
If `source.bytes` and `destination.bytes` are known, `network.bytes` is their sum.

type: long

example: 368

format: bytes

--

*`network.community_id`*::
+
--
A hash of source and destination IPs and ports, as well as the protocol used in a communication. This is a tool-agnostic standard to identify flows.
Learn more at https://github.com/corelight/community-id-spec.

type: keyword

example: 1:hO+sN4H+MG5MY/8hIrXPqc4ZQz0=

--

*`network.direction`*::
+
--
Direction of the network traffic.
Recommended values are:
  * inbound
  * outbound
  * internal
  * external
  * unknown

When mapping events from a host-based monitoring context, populate this field from the host's point of view.
When mapping events from a network or perimeter-based monitoring context, populate this field from the point of view of your network perimeter.

type: keyword

example: inbound

--

*`network.forwarded_ip`*::
+
--
Host IP address when the source IP address is the proxy.

type: ip

example: 192.1.1.2

--

*`network.iana_number`*::
+
--
IANA Protocol Number (https://www.iana.org/assignments/protocol-numbers/protocol-numbers.xhtml). Standardized list of protocols. This aligns well with NetFlow and sFlow related logs which use the IANA Protocol Number.

type: keyword

example: 6

--

*`network.name`*::
+
--
Name given by operators to sections of their network.

type: keyword

example: Guest Wifi

--

*`network.packets`*::
+
--
Total packets transferred in both directions.
If `source.packets` and `destination.packets` are known, `network.packets` is their sum.

type: long

example: 24

--

*`network.protocol`*::
+
--
L7 Network protocol name. ex. http, lumberjack, transport protocol.
The field value must be normalized to lowercase for querying. See the documentation section "Implementing ECS".

type: keyword

example: http

--

*`network.transport`*::
+
--
Same as network.iana_number, but instead using the Keyword name of the transport layer (udp, tcp, ipv6-icmp, etc.)
The field value must be normalized to lowercase for querying. See the documentation section "Implementing ECS".

type: keyword

example: tcp

--

*`network.type`*::
+
--
In the OSI Model this would be the Network Layer. ipv4, ipv6, ipsec, pim, etc
The field value must be normalized to lowercase for querying. See the documentation section "Implementing ECS".

type: keyword

example: ipv4

--

[float]
=== observer

An observer is defined as a special network, security, or application device used to detect, observe, or create network, security, or application-related events and metrics.
This could be a custom hardware appliance or a server that has been configured to run special network, security, or application software. Examples include firewalls, intrusion detection/prevention systems, network monitoring sensors, web application firewalls, data loss prevention systems, and APM servers. The observer.* fields shall be populated with details of the system, if any, that detects, observes and/or creates a network, security, or application event or metric. Message queues and ETL components used in processing events or metrics are not considered observers in ECS.


*`observer.geo.city_name`*::
+
--
>>>>>>> upstream/master
City name.

type: keyword

example: Montreal

<<<<<<< HEAD
=======
--

*`observer.geo.continent_name`*::
+
--
Name of the continent.

type: keyword

example: North America

--

*`observer.geo.country_iso_code`*::
+
--
Country ISO code.

type: keyword

example: CA

--

*`observer.geo.country_name`*::
+
--
Country name.

type: keyword

example: Canada

--

*`observer.geo.location`*::
+
--
Longitude and latitude.

type: geo_point

example: { "lon": -73.614830, "lat": 45.505918 }

--

*`observer.geo.name`*::
+
--
User-defined description of a location, at the level of granularity they care about.
Could be the name of their data centers, the floor number, if this describes a local physical entity, city names.
Not typically used in automated geolocation.

type: keyword

example: boston-dc

--

*`observer.geo.region_iso_code`*::
+
--
Region ISO code.

type: keyword

example: CA-QC

--

*`observer.geo.region_name`*::
+
--
Region name.

type: keyword

example: Quebec

--

*`observer.hostname`*::
+
--
Hostname of the observer.

type: keyword

--

*`observer.ip`*::
+
--
IP address of the observer.

type: ip

--

*`observer.mac`*::
+
--
MAC address of the observer

type: keyword

--

*`observer.os.family`*::
+
--
OS family (such as redhat, debian, freebsd, windows).

type: keyword

example: debian

--

*`observer.os.full`*::
+
--
Operating system name, including the version or code name.

type: keyword

example: Mac OS Mojave

--

*`observer.os.kernel`*::
+
--
Operating system kernel version as a raw string.

type: keyword

example: 4.4.0-112-generic

--

*`observer.os.name`*::
+
--
Operating system name, without the version.

type: keyword

example: Mac OS X

--

*`observer.os.platform`*::
+
--
Operating system platform (such centos, ubuntu, windows).

type: keyword

example: darwin

--

*`observer.os.version`*::
+
--
Operating system version as a raw string.

type: keyword

example: 10.14.1

>>>>>>> upstream/master
--

*`observer.serial_number`*::
+
--
<<<<<<< HEAD
Name of the continent.
=======
Observer serial number.
>>>>>>> upstream/master

type: keyword

--

<<<<<<< HEAD
=======
*`observer.type`*::
+
--
The type of the observer the data is coming from.
There is no predefined list of observer types. Some examples are `forwarder`, `firewall`, `ids`, `ips`, `proxy`, `poller`, `sensor`, `APM server`.

type: keyword

example: firewall

>>>>>>> upstream/master
--

*`observer.vendor`*::
+
--
<<<<<<< HEAD
Country ISO code.
=======
observer vendor information.
>>>>>>> upstream/master

type: keyword

--

<<<<<<< HEAD
=======
*`observer.version`*::
+
--
Observer version.

type: keyword

>>>>>>> upstream/master
--

[float]
=== organization

The organization fields enrich data with information about the company or entity the data is associated with.
These fields help you arrange or filter data stored in an index by one or multiple organizations.


*`organization.id`*::
+
--
<<<<<<< HEAD
Country name.
=======
Unique identifier for the organization.
>>>>>>> upstream/master

type: keyword

--

<<<<<<< HEAD
=======
*`organization.name`*::
+
--
Organization name.

type: keyword

>>>>>>> upstream/master
--

[float]
=== os

The OS fields contain information about the operating system.


*`os.family`*::
+
--
<<<<<<< HEAD
Longitude and latitude.

type: geo_point
=======
OS family (such as redhat, debian, freebsd, windows).
>>>>>>> upstream/master

type: keyword

<<<<<<< HEAD
=======
example: debian

>>>>>>> upstream/master
--

*`os.full`*::
+
--
<<<<<<< HEAD
User-defined description of a location, at the level of granularity they care about.
Could be the name of their data centers, the floor number, if this describes a local physical entity, city names.
Not typically used in automated geolocation.
=======
Operating system name, including the version or code name.

type: keyword

example: Mac OS Mojave
>>>>>>> upstream/master

type: keyword

example: boston-dc

--

*`os.kernel`*::
+
--
<<<<<<< HEAD
Region ISO code.

type: keyword
=======
Operating system kernel version as a raw string.
>>>>>>> upstream/master

type: keyword

<<<<<<< HEAD
=======
example: 4.4.0-112-generic

>>>>>>> upstream/master
--

*`os.name`*::
+
--
<<<<<<< HEAD
Region name.

type: keyword
=======
Operating system name, without the version.
>>>>>>> upstream/master

type: keyword

<<<<<<< HEAD
=======
example: Mac OS X

>>>>>>> upstream/master
--

*`os.platform`*::
+
--
<<<<<<< HEAD
IP address of the destination.
Can be one or multiple IPv4 or IPv6 addresses.
=======
Operating system platform (such centos, ubuntu, windows).

type: keyword

example: darwin
>>>>>>> upstream/master

type: ip

--

*`os.version`*::
+
--
<<<<<<< HEAD
MAC address of the destination.
=======
Operating system version as a raw string.

type: keyword

example: 10.14.1
>>>>>>> upstream/master

type: keyword

--

[float]
=== process

These fields contain information about a process.
These fields can help you correlate metrics information with a process id/name from a log message.  The `process.pid` often stays in the metric itself and is copied to the global field for correlation.


*`process.args`*::
+
--
<<<<<<< HEAD
Packets sent from the destination to the source.

type: long
=======
Array of process arguments.
May be filtered to protect sensitive information.
>>>>>>> upstream/master

type: keyword

<<<<<<< HEAD
=======
example: ['ssh', '-l', 'user', '10.0.0.16']

>>>>>>> upstream/master
--

*`process.executable`*::
+
--
<<<<<<< HEAD
Port of the destination.
=======
Absolute path to the process executable.

type: keyword

example: /usr/bin/ssh
>>>>>>> upstream/master

type: long

--

*`process.name`*::
+
--
<<<<<<< HEAD
User email address.
=======
Process name.
Sometimes called program name or similar.

type: keyword

example: ssh
>>>>>>> upstream/master

type: keyword

--

*`process.pid`*::
+
--
<<<<<<< HEAD
User's full name, if available.

type: keyword
=======
Process id.
>>>>>>> upstream/master

type: long

<<<<<<< HEAD
=======
example: 4242

format: string

>>>>>>> upstream/master
--

*`process.ppid`*::
+
--
<<<<<<< HEAD
Unique identifier for the group on the system/platform.
=======
Parent process' pid.

type: long

example: 4241

format: string
>>>>>>> upstream/master

type: keyword

--

*`process.start`*::
+
--
<<<<<<< HEAD
Name of the group.
=======
The time the process started.

type: date

example: 2016-05-23T08:05:34.853Z
>>>>>>> upstream/master

type: keyword

--

*`process.thread.id`*::
+
--
<<<<<<< HEAD
Unique user hash to correlate information for a user in anonymized form.
Useful if `user.id` or `user.name` contain confidential information and cannot be used.
=======
Thread ID.

type: long

example: 4242

format: string
>>>>>>> upstream/master

type: keyword

--

*`process.title`*::
+
--
<<<<<<< HEAD
One or multiple unique identifiers of the user.
=======
Process title.
The proctitle, some times the same as process name. Can also be different: for example a browser setting its title to the web page currently opened.

type: keyword
>>>>>>> upstream/master

type: keyword

--

*`process.working_directory`*::
+
--
<<<<<<< HEAD
Short name or login of the user.

type: keyword
=======
The working directory of the process.
>>>>>>> upstream/master

type: keyword

<<<<<<< HEAD
--

[float]
=== ecs
=======
example: /home/alice

--

[float]
=== related
>>>>>>> upstream/master

This field set is meant to facilitate pivoting around a piece of data.
Some pieces of information can be seen in many places in an ECS event. To facilitate searching for them, store an array of all seen values to their corresponding field in `related.`.
A concrete example is IP addresses, which can be under host, observer, source, destination, client, server, and network.forwarded_ip. If you append all IPs to `related.ip`, you can then search for a given IP trivially, no matter where it appeared, by querying `related.ip:a.b.c.d`.


*`related.ip`*::
+
--
<<<<<<< HEAD
ECS version this event conforms to. `ecs.version` is a required field and must exist in all events.
When querying across multiple indices -- which may conform to slightly different ECS versions -- this field lets integrations adjust to the schema version of the events.

type: keyword

example: 1.0.0

required: True

--

[float]
=== error
=======
All of the IPs seen on your event.

type: ip

--

[float]
=== server
>>>>>>> upstream/master

A Server is defined as the responder in a network connection for events regarding sessions, connections, or bidirectional flow records.
For TCP events, the server is the receiver of the initial SYN packet(s) of the TCP connection. For other protocols, the server is generally the responder in the network transaction. Some systems actually use the term "responder" to refer the server in TCP connections. The server fields describe details about the system acting as the server in the network event. Server fields are usually populated in conjunction with client fields. Server fields are generally not populated for packet-level events.
Client / server representations can add semantic context to an exchange, which is helpful to visualize the data in certain situations. If your context falls in that category, you should still ensure that source and destination are filled appropriately.


*`server.address`*::
+
--
<<<<<<< HEAD
Error code describing the error.

type: keyword

=======
Some event server addresses are defined ambiguously. The event will sometimes list an IP, a domain or a unix socket.  You should always store the raw address in the `.address` field.
Then it should be duplicated to `.ip` or `.domain`, depending on which one it is.

type: keyword

--

*`server.bytes`*::
+
>>>>>>> upstream/master
--
Bytes sent from the server to the client.

type: long

example: 184

format: bytes

--

*`server.domain`*::
+
--
<<<<<<< HEAD
Unique identifier for the error.

type: keyword

=======
Server domain.

type: keyword

--

*`server.geo.city_name`*::
+
>>>>>>> upstream/master
--
City name.

type: keyword

example: Montreal

--

*`server.geo.continent_name`*::
+
--
<<<<<<< HEAD
Error message.
=======
Name of the continent.

type: keyword

example: North America
>>>>>>> upstream/master

type: text

--

<<<<<<< HEAD
[float]
=== event
=======
*`server.geo.country_iso_code`*::
+
--
Country ISO code.
>>>>>>> upstream/master

type: keyword

example: CA

--

*`server.geo.country_name`*::
+
--
<<<<<<< HEAD
The action captured by the event.
This describes the information in the event. It is more specific than `event.category`. Examples are `group-add`, `process-started`, `file-created`. The value is normally defined by the implementer.

type: keyword
=======
Country name.
>>>>>>> upstream/master

type: keyword

<<<<<<< HEAD
=======
example: Canada

>>>>>>> upstream/master
--

*`server.geo.location`*::
+
--
<<<<<<< HEAD
Event category.
This contains high-level information about the contents of the event. It is more generic than `event.action`, in the sense that typically a category contains multiple actions. Warning: In future versions of ECS, we plan to provide a list of acceptable values for this field, please use with caution.
=======
Longitude and latitude.

type: geo_point

example: { "lon": -73.614830, "lat": 45.505918 }
>>>>>>> upstream/master

type: keyword

example: user-management

--

*`server.geo.name`*::
+
--
<<<<<<< HEAD
event.created contains the date/time when the event was first read by an agent, or by your pipeline.
This field is distinct from @timestamp in that @timestamp typically contain the time extracted from the original event.
In most situations, these two timestamps will be slightly different. The difference can be used to calculate the delay between your source generating an event, and the time when your agent first processed it. This can be used to monitor your agent's or pipeline's ability to keep up with your event source.
In case the two timestamps are identical, @timestamp should be used.
=======
User-defined description of a location, at the level of granularity they care about.
Could be the name of their data centers, the floor number, if this describes a local physical entity, city names.
Not typically used in automated geolocation.

type: keyword

example: boston-dc
>>>>>>> upstream/master

type: date

--

*`server.geo.region_iso_code`*::
+
--
<<<<<<< HEAD
Name of the dataset.
The concept of a `dataset` (fileset / metricset) is used in Beats as a subset of modules. It contains the information which is currently stored in metricset.name and metricset.module or fileset.name.

type: keyword
=======
Region ISO code.
>>>>>>> upstream/master

type: keyword

<<<<<<< HEAD
=======
example: CA-QC

>>>>>>> upstream/master
--

*`server.geo.region_name`*::
+
--
<<<<<<< HEAD
Duration of the event in nanoseconds.
If event.start and event.end are known this value should be the difference between the end and start time.

type: long
=======
Region name.
>>>>>>> upstream/master

type: keyword

<<<<<<< HEAD
=======
example: Quebec

>>>>>>> upstream/master
--

*`server.ip`*::
+
--
<<<<<<< HEAD
event.end contains the date when the event ended or when the activity was last observed.
=======
IP address of the server.
Can be one or multiple IPv4 or IPv6 addresses.

type: ip
>>>>>>> upstream/master

type: date

--

*`server.mac`*::
+
--
<<<<<<< HEAD
Hash (perhaps logstash fingerprint) of raw field to be able to demonstrate log integrity.

type: keyword

example: 123456789012345678901234567890ABCD

=======
MAC address of the server.

type: keyword

>>>>>>> upstream/master
--

*`server.packets`*::
+
--
<<<<<<< HEAD
Unique ID to describe the event.

type: keyword
=======
Packets sent from the server to the client.
>>>>>>> upstream/master

type: long

<<<<<<< HEAD
=======
example: 12

>>>>>>> upstream/master
--

*`server.port`*::
+
--
<<<<<<< HEAD
The kind of the event.
This gives information about what type of information the event contains, without being specific to the contents of the event.  Examples are `event`, `state`, `alarm`. Warning: In future versions of ECS, we plan to provide a list of acceptable values for this field, please use with caution.

type: keyword
=======
Port of the server.
>>>>>>> upstream/master

type: long

<<<<<<< HEAD
=======
format: string

>>>>>>> upstream/master
--

*`server.user.email`*::
+
--
<<<<<<< HEAD
Name of the module this data is coming from.
This information is coming from the modules used in Beats or Logstash.

type: keyword

example: mysql

=======
User email address.

type: keyword

>>>>>>> upstream/master
--

*`server.user.full_name`*::
+
--
<<<<<<< HEAD
Raw text message of entire event. Used to demonstrate log integrity.
This field is not indexed and doc_values are disabled. It cannot be searched, but it can be retrieved from `_source`.

type: keyword
=======
User's full name, if available.
>>>>>>> upstream/master

type: keyword

<<<<<<< HEAD
=======
example: Albert Einstein

>>>>>>> upstream/master
--

*`server.user.group.id`*::
+
--
<<<<<<< HEAD
The outcome of the event.
If the event describes an action, this fields contains the outcome of that action. Examples outcomes are `success` and `failure`. Warning: In future versions of ECS, we plan to provide a list of acceptable values for this field, please use with caution.

type: keyword

example: success

=======
Unique identifier for the group on the system/platform.

type: keyword

>>>>>>> upstream/master
--

*`server.user.group.name`*::
+
--
<<<<<<< HEAD
Risk score or priority of the event (e.g. security solutions). Use your system's original value here.
=======
Name of the group.

type: keyword
>>>>>>> upstream/master

type: float

--

*`server.user.hash`*::
+
--
<<<<<<< HEAD
Normalized risk score or priority of the event, on a scale of 0 to 100.
This is mainly useful if you use more than one system that assigns risk scores, and you want to see a normalized value across all systems.
=======
Unique user hash to correlate information for a user in anonymized form.
Useful if `user.id` or `user.name` contain confidential information and cannot be used.

type: keyword
>>>>>>> upstream/master

type: float

--

*`server.user.id`*::
+
--
<<<<<<< HEAD
Severity describes the original severity of the event. What the different severity values mean can very different between use cases. It's up to the implementer to make sure severities are consistent across events.

type: long

example: 7

=======
One or multiple unique identifiers of the user.

type: keyword

>>>>>>> upstream/master
--

*`server.user.name`*::
+
--
<<<<<<< HEAD
event.start contains the date when the event started or when the activity was first observed.
=======
Short name or login of the user.

type: keyword

example: albert
>>>>>>> upstream/master

type: date

--

[float]
=== service

The service fields describe the service for or from which the data was collected.
These fields help you find and correlate logs for a specific service and version.


*`service.ephemeral_id`*::
+
--
<<<<<<< HEAD
This field should be populated when the event's timestamp does not include timezone information already (e.g. default Syslog timestamps). It's optional otherwise.
Acceptable timezone formats are: a canonical ID (e.g. "Europe/Amsterdam"), abbreviated (e.g. "EST") or an HH:mm differential (e.g. "-05:00").
=======
Ephemeral identifier of this service (if one exists).
This id normally changes across restarts, but `service.id` does not.

type: keyword

example: 8a4f500f
>>>>>>> upstream/master

type: keyword

--

*`service.id`*::
+
--
<<<<<<< HEAD
Reserved for future usage.
Please avoid using this field for user data.
=======
Unique identifier of the running service.
This id should uniquely identify this service. This makes it possible to correlate logs and metrics for one specific service.
Example: If you are experiencing issues with one redis instance, you can filter on that id to see metrics and logs for that single instance.

type: keyword

example: d37e5ebfe0ae6c4972dbe9f0174a1637bb8247f6
>>>>>>> upstream/master

type: keyword

--

<<<<<<< HEAD
[float]
=== file
=======
*`service.name`*::
+
--
Name of the service data is collected from.
The name of the service is normally user given. This allows if two instances of the same service are running on the same machine they can be differentiated by the `service.name`.
Also it allows for distributed services that run on multiple hosts to correlate the related instances based on the name.
In the case of Elasticsearch the service.name could contain the cluster name. For Beats the service.name is by default a copy of the `service.type` field if no name is specified.
>>>>>>> upstream/master

type: keyword

example: elasticsearch-metrics

--

*`service.state`*::
+
--
<<<<<<< HEAD
Last time file metadata changed.
=======
Current state of the service.

type: keyword
>>>>>>> upstream/master

type: date

--

*`service.type`*::
+
--
<<<<<<< HEAD
Device that is the source of the file.
=======
The type of the service data is collected from.
The type can be used to group and correlate logs and metrics from one service type.
Example: If logs or metrics are collected from Elasticsearch, `service.type` would be `elasticsearch`.

type: keyword

example: elasticsearch
>>>>>>> upstream/master

type: keyword

--

*`service.version`*::
+
--
<<<<<<< HEAD
File extension.
This should allow easy filtering by file extensions.

type: keyword
=======
Version of the service the data was collected from.
This allows to look at a data set only for a specific version of a service.
>>>>>>> upstream/master

type: keyword

<<<<<<< HEAD
=======
example: 3.2.4

>>>>>>> upstream/master
--

[float]
=== source

Source fields describe details about the source of a packet/event.
Source fields are usually populated in conjunction with destination fields.


*`source.address`*::
+
--
<<<<<<< HEAD
Primary group ID (GID) of the file.
=======
Some event source addresses are defined ambiguously. The event will sometimes list an IP, a domain or a unix socket.  You should always store the raw address in the `.address` field.
Then it should be duplicated to `.ip` or `.domain`, depending on which one it is.

type: keyword
>>>>>>> upstream/master

type: keyword

--

*`source.bytes`*::
+
--
<<<<<<< HEAD
Primary group name of the file.
=======
Bytes sent from the source to the destination.

type: long

example: 184

format: bytes
>>>>>>> upstream/master

type: keyword

--

*`source.domain`*::
+
--
<<<<<<< HEAD
Inode representing the file in the filesystem.
=======
Source domain.

type: keyword
>>>>>>> upstream/master

type: keyword

--

*`source.geo.city_name`*::
+
--
<<<<<<< HEAD
Mode of the file in octal representation.

type: keyword
=======
City name.
>>>>>>> upstream/master

type: keyword

<<<<<<< HEAD
=======
example: Montreal

>>>>>>> upstream/master
--

*`source.geo.continent_name`*::
+
--
<<<<<<< HEAD
Last time file content was modified.
=======
Name of the continent.

type: keyword

example: North America
>>>>>>> upstream/master

type: date

--

*`source.geo.country_iso_code`*::
+
--
<<<<<<< HEAD
File owner's username.
=======
Country ISO code.

type: keyword

example: CA
>>>>>>> upstream/master

type: keyword

--

*`source.geo.country_name`*::
+
--
<<<<<<< HEAD
Path to the file.
=======
Country name.

type: keyword

example: Canada
>>>>>>> upstream/master

type: keyword

--

*`source.geo.location`*::
+
--
<<<<<<< HEAD
File size in bytes (field is only added when `type` is `file`).
=======
Longitude and latitude.

type: geo_point

example: { "lon": -73.614830, "lat": 45.505918 }
>>>>>>> upstream/master

type: long

--

*`source.geo.name`*::
+
--
<<<<<<< HEAD
Target path for symlinks.
=======
User-defined description of a location, at the level of granularity they care about.
Could be the name of their data centers, the floor number, if this describes a local physical entity, city names.
Not typically used in automated geolocation.

type: keyword

example: boston-dc
>>>>>>> upstream/master

type: keyword

--

*`source.geo.region_iso_code`*::
+
--
<<<<<<< HEAD
File type (file, dir, or symlink).
=======
Region ISO code.

type: keyword

example: CA-QC
>>>>>>> upstream/master

type: keyword

--

*`source.geo.region_name`*::
+
--
<<<<<<< HEAD
The user ID (UID) or security identifier (SID) of the file owner.
=======
Region name.

type: keyword

example: Quebec
>>>>>>> upstream/master

type: keyword

--

<<<<<<< HEAD
[float]
=== geo

Geo fields can carry data about a specific location related to an event.
This geolocation information can be derived from techniques such as Geo IP, or be user-supplied.


*`geo.city_name`*::
+
--
City name.

type: keyword

example: Montreal

=======
*`source.ip`*::
+
--
IP address of the source.
Can be one or multiple IPv4 or IPv6 addresses.

type: ip

>>>>>>> upstream/master
--

*`source.mac`*::
+
--
<<<<<<< HEAD
Name of the continent.

type: keyword

example: North America

=======
MAC address of the source.

type: keyword

>>>>>>> upstream/master
--

*`source.packets`*::
+
--
<<<<<<< HEAD
Country ISO code.

type: keyword
=======
Packets sent from the source to the destination.
>>>>>>> upstream/master

type: long

<<<<<<< HEAD
=======
example: 12

>>>>>>> upstream/master
--

*`source.port`*::
+
--
<<<<<<< HEAD
Country name.

type: keyword
=======
Port of the source.
>>>>>>> upstream/master

type: long

<<<<<<< HEAD
=======
format: string

>>>>>>> upstream/master
--

*`source.user.email`*::
+
--
<<<<<<< HEAD
Longitude and latitude.

type: geo_point

example: { "lon": -73.614830, "lat": 45.505918 }

=======
User email address.

type: keyword

>>>>>>> upstream/master
--

*`source.user.full_name`*::
+
--
<<<<<<< HEAD
User-defined description of a location, at the level of granularity they care about.
Could be the name of their data centers, the floor number, if this describes a local physical entity, city names.
Not typically used in automated geolocation.
=======
User's full name, if available.

type: keyword

example: Albert Einstein
>>>>>>> upstream/master

type: keyword

example: boston-dc

--

*`source.user.group.id`*::
+
--
<<<<<<< HEAD
Region ISO code.

type: keyword

example: CA-QC

=======
Unique identifier for the group on the system/platform.

type: keyword

>>>>>>> upstream/master
--

*`source.user.group.name`*::
+
--
<<<<<<< HEAD
Region name.

type: keyword

example: Quebec

--

[float]
=== group
=======
Name of the group.

type: keyword

--

*`source.user.hash`*::
+
--
Unique user hash to correlate information for a user in anonymized form.
Useful if `user.id` or `user.name` contain confidential information and cannot be used.
>>>>>>> upstream/master

type: keyword

--

*`source.user.id`*::
+
--
<<<<<<< HEAD
Unique identifier for the group on the system/platform.
=======
One or multiple unique identifiers of the user.

type: keyword
>>>>>>> upstream/master

type: keyword

--

*`source.user.name`*::
+
--
<<<<<<< HEAD
Name of the group.
=======
Short name or login of the user.

type: keyword

example: albert
>>>>>>> upstream/master

type: keyword

--

[float]
<<<<<<< HEAD
=== host
=======
=== url
>>>>>>> upstream/master

URL fields provide support for complete or partial URLs, and supports the breaking down into scheme, domain, path, and so on.


*`url.domain`*::
+
--
<<<<<<< HEAD
Operating system architecture.

type: keyword
=======
Domain of the url, such as "www.elastic.co".
In some cases a URL may refer to an IP and/or port directly, without a domain name. In this case, the IP address would go to the `domain` field.
>>>>>>> upstream/master

type: keyword

<<<<<<< HEAD
=======
example: www.elastic.co

>>>>>>> upstream/master
--

*`url.fragment`*::
+
--
<<<<<<< HEAD
City name.

type: keyword

example: Montreal

=======
Portion of the url after the `#`, such as "top".
The `#` is not part of the fragment.

type: keyword

>>>>>>> upstream/master
--

*`url.full`*::
+
--
<<<<<<< HEAD
Name of the continent.

type: keyword
=======
If full URLs are important to your use case, they should be stored in `url.full`, whether this field is reconstructed or present in the event source.
>>>>>>> upstream/master

type: keyword

<<<<<<< HEAD
=======
example: https://www.elastic.co:443/search?q=elasticsearch#top

>>>>>>> upstream/master
--

*`url.original`*::
+
--
<<<<<<< HEAD
Country ISO code.

type: keyword
=======
Unmodified original url as seen in the event source.
Note that in network monitoring, the observed URL may be a full URL, whereas in access logs, the URL is often just represented as a path.
This field is meant to represent the URL as it was observed, complete or not.
>>>>>>> upstream/master

type: keyword

<<<<<<< HEAD
=======
example: https://www.elastic.co:443/search?q=elasticsearch#top or /search?q=elasticsearch

>>>>>>> upstream/master
--

*`url.password`*::
+
--
<<<<<<< HEAD
Country name.

type: keyword

example: Canada

=======
Password of the request.

type: keyword

>>>>>>> upstream/master
--

*`url.path`*::
+
--
<<<<<<< HEAD
Longitude and latitude.

type: geo_point

example: { "lon": -73.614830, "lat": 45.505918 }

=======
Path of the request, such as "/search".

type: keyword

>>>>>>> upstream/master
--

*`url.port`*::
+
--
<<<<<<< HEAD
User-defined description of a location, at the level of granularity they care about.
Could be the name of their data centers, the floor number, if this describes a local physical entity, city names.
Not typically used in automated geolocation.
=======
Port of the request, such as 443.

type: long

example: 443

format: string
>>>>>>> upstream/master

type: keyword

example: boston-dc

--

*`url.query`*::
+
--
<<<<<<< HEAD
Region ISO code.

type: keyword

example: CA-QC

=======
The query field describes the query string of the request, such as "q=elasticsearch".
The `?` is excluded from the query string. If a URL contains no `?`, there is no query field. If there is a `?` but no query, the query field exists with an empty string. The `exists` query can be used to differentiate between the two cases.

type: keyword

>>>>>>> upstream/master
--

*`url.scheme`*::
+
--
<<<<<<< HEAD
Region name.

type: keyword
=======
Scheme of the request, such as "https".
Note: The `:` is not part of the scheme.
>>>>>>> upstream/master

type: keyword

<<<<<<< HEAD
=======
example: https

>>>>>>> upstream/master
--

*`url.username`*::
+
--
<<<<<<< HEAD
Hostname of the host.
It normally contains what the `hostname` command returns on the host machine.
=======
Username of the request.

type: keyword
>>>>>>> upstream/master

type: keyword

--

<<<<<<< HEAD
*`host.id`*::
+
--
Unique host id.
As hostname is not always unique, use values that are meaningful in your environment.
Example: The current usage of `beat.name`.

type: keyword

--
=======
[float]
=== user

The user fields describe information about the user that is relevant to the event.
Fields can have one entry or multiple entries. If a user has more than one id, provide an array that includes all of them.

>>>>>>> upstream/master

*`user.email`*::
+
--
<<<<<<< HEAD
Host ip address.
=======
User email address.

type: keyword
>>>>>>> upstream/master

type: ip

--

*`user.full_name`*::
+
--
<<<<<<< HEAD
Host mac address.
=======
User's full name, if available.

type: keyword

example: Albert Einstein
>>>>>>> upstream/master

type: keyword

--

*`user.group.id`*::
+
--
<<<<<<< HEAD
Name of the host.
It can contain what `hostname` returns on Unix systems, the fully qualified domain name, or a name specified by the user. The sender decides which value to use.
=======
Unique identifier for the group on the system/platform.

type: keyword
>>>>>>> upstream/master

type: keyword

--

*`user.group.name`*::
+
--
<<<<<<< HEAD
OS family (such as redhat, debian, freebsd, windows).

type: keyword

example: debian

=======
Name of the group.

type: keyword

>>>>>>> upstream/master
--

*`user.hash`*::
+
--
<<<<<<< HEAD
Operating system name, including the version or code name.

type: keyword

example: Mac OS Mojave

=======
Unique user hash to correlate information for a user in anonymized form.
Useful if `user.id` or `user.name` contain confidential information and cannot be used.

type: keyword

>>>>>>> upstream/master
--

*`user.id`*::
+
--
<<<<<<< HEAD
Operating system kernel version as a raw string.

type: keyword

example: 4.4.0-112-generic

=======
One or multiple unique identifiers of the user.

type: keyword

>>>>>>> upstream/master
--

*`user.name`*::
+
--
<<<<<<< HEAD
Operating system name, without the version.

type: keyword
=======
Short name or login of the user.
>>>>>>> upstream/master

type: keyword

<<<<<<< HEAD
=======
example: albert

>>>>>>> upstream/master
--

[float]
=== user_agent

The user_agent fields normally come from a browser request.
They often show up in web service logs coming from the parsed user agent string.


*`user_agent.device.name`*::
+
--
<<<<<<< HEAD
Operating system platform (such centos, ubuntu, windows).

type: keyword
=======
Name of the device.
>>>>>>> upstream/master

type: keyword

<<<<<<< HEAD
=======
example: iPhone

>>>>>>> upstream/master
--

*`user_agent.name`*::
+
--
<<<<<<< HEAD
Operating system version as a raw string.

type: keyword
=======
Name of the user agent.
>>>>>>> upstream/master

type: keyword

<<<<<<< HEAD
=======
example: Safari

>>>>>>> upstream/master
--

*`user_agent.original`*::
+
--
<<<<<<< HEAD
Type of host.
For Cloud providers this can be the machine type like `t2.medium`. If vm, this could be the container, for example, or other information meaningful in your environment.
=======
Unparsed version of the user_agent.

type: keyword

example: Mozilla/5.0 (iPhone; CPU iPhone OS 12_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/12.0 Mobile/15E148 Safari/604.1
>>>>>>> upstream/master

type: keyword

--

*`user_agent.os.family`*::
+
--
<<<<<<< HEAD
User email address.
=======
OS family (such as redhat, debian, freebsd, windows).

type: keyword

example: debian
>>>>>>> upstream/master

type: keyword

--

*`user_agent.os.full`*::
+
--
<<<<<<< HEAD
User's full name, if available.

type: keyword
=======
Operating system name, including the version or code name.
>>>>>>> upstream/master

type: keyword

<<<<<<< HEAD
=======
example: Mac OS Mojave

>>>>>>> upstream/master
--

*`user_agent.os.kernel`*::
+
--
<<<<<<< HEAD
Unique identifier for the group on the system/platform.
=======
Operating system kernel version as a raw string.

type: keyword

example: 4.4.0-112-generic
>>>>>>> upstream/master

type: keyword

--

*`user_agent.os.name`*::
+
--
<<<<<<< HEAD
Name of the group.
=======
Operating system name, without the version.

type: keyword

example: Mac OS X
>>>>>>> upstream/master

type: keyword

--

*`user_agent.os.platform`*::
+
--
<<<<<<< HEAD
Unique user hash to correlate information for a user in anonymized form.
Useful if `user.id` or `user.name` contain confidential information and cannot be used.
=======
Operating system platform (such centos, ubuntu, windows).

type: keyword

example: darwin
>>>>>>> upstream/master

type: keyword

--

*`user_agent.os.version`*::
+
--
<<<<<<< HEAD
One or multiple unique identifiers of the user.
=======
Operating system version as a raw string.

type: keyword

example: 10.14.1
>>>>>>> upstream/master

type: keyword

--

*`user_agent.version`*::
+
--
<<<<<<< HEAD
Short name or login of the user.

type: keyword
=======
Version of the user agent.
>>>>>>> upstream/master

type: keyword

<<<<<<< HEAD
--

[float]
=== http
=======
example: 12.0

--

[[exported-fields-elasticsearch]]
== Elasticsearch fields
>>>>>>> upstream/master

Elasticsearch module


<<<<<<< HEAD
*`http.request.body.bytes`*::
+
--
Size in bytes of the request body.

type: long
=======
>>>>>>> upstream/master

[float]
=== elasticsearch


<<<<<<< HEAD
--
=======

>>>>>>> upstream/master

*`elasticsearch.cluster.name`*::
+
--
<<<<<<< HEAD
The full HTTP request body.

type: keyword
=======
Elasticsearch cluster name.
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: keyword

>>>>>>> upstream/master
--

*`elasticsearch.cluster.id`*::
+
--
<<<<<<< HEAD
Total size in bytes of the request (body and headers).

type: long

example: 1437
=======
Elasticsearch cluster id.
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: keyword

>>>>>>> upstream/master
--

*`elasticsearch.cluster.state.id`*::
+
--
<<<<<<< HEAD
HTTP request method.
The field value must be normalized to lowercase for querying. See the documentation section "Implementing ECS".

type: keyword
=======
Elasticsearch state id.
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: keyword

>>>>>>> upstream/master
--

*`elasticsearch.node.id`*::
+
--
<<<<<<< HEAD
Referrer for this HTTP request.

type: keyword
=======
Node ID
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: keyword

>>>>>>> upstream/master
--

*`elasticsearch.node.name`*::
+
--
<<<<<<< HEAD
Size in bytes of the response body.

type: long

example: 887
=======
Node name.
>>>>>>> upstream/master


<<<<<<< HEAD
--

*`http.response.body.content`*::
+
--
The full HTTP response body.

type: keyword
=======
type: keyword

--

[float]
=== ccr
>>>>>>> upstream/master

Cross-cluster replication stats

<<<<<<< HEAD
--
=======

>>>>>>> upstream/master


*`elasticsearch.ccr.leader.index`*::
+
--
<<<<<<< HEAD
Total size in bytes of the response (body and headers).

type: long

example: 1437
=======
Name of leader index
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: keyword

>>>>>>> upstream/master
--

*`elasticsearch.ccr.leader.max_seq_no`*::
+
--
<<<<<<< HEAD
HTTP response status code.

type: long
=======
Maximum sequence number of operation on the leader shard
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: long

>>>>>>> upstream/master
--


*`elasticsearch.ccr.follower.index`*::
+
--
<<<<<<< HEAD
HTTP version.

type: keyword
=======
Name of follower index
>>>>>>> upstream/master


<<<<<<< HEAD
--

[float]
=== log

Fields which are specific to log events.


*`log.level`*::
+
--
Original log level of the log event.
Some examples are `warn`, `error`, `i`.

type: keyword
=======
type: keyword

--

*`elasticsearch.ccr.follower.shard.number`*::
+
--
Number of the shard within the index
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: long

>>>>>>> upstream/master
--

*`elasticsearch.ccr.follower.operations_written`*::
+
--
<<<<<<< HEAD
This is the original log message and contains the full log message before splitting it up in multiple parts.
In contrast to the `message` field which can contain an extracted part of the log message, this field contains the original, full log message. It can have already some modifications applied like encoding or new lines removed to clean up the log message.
This field is not indexed and doc_values are disabled so it can't be queried but the value can be retrieved from `_source`.
=======
Number of operations indexed (replicated) into the follower shard from the leader shard


type: long
>>>>>>> upstream/master

type: keyword

example: Sep 19 08:26:10 localhost My log

--

<<<<<<< HEAD
[float]
=== network

The network is defined as the communication path over which a host or network event happens.
The network.* fields should be populated with details about the network activity associated with an event.


*`network.application`*::
+
--
A name given to an application level protocol. This can be arbitrarily assigned for things like microservices, but also apply to things like skype, icq, facebook, twitter. This would be used in situations where the vendor or service can be decoded such as from the source/dest IP owners, ports, or wire format.
The field value must be normalized to lowercase for querying. See the documentation section "Implementing ECS".

type: keyword
=======
*`elasticsearch.ccr.follower.time_since_last_read.ms`*::
+
--
Time, in ms, since the follower last fetched from the leader
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: long

>>>>>>> upstream/master
--

*`elasticsearch.ccr.follower.global_checkpoint`*::
+
--
<<<<<<< HEAD
Total bytes transferred in both directions.
If `source.bytes` and `destination.bytes` are known, `network.bytes` is their sum.

type: long

example: 368
=======
Global checkpoint value on follower shard
>>>>>>> upstream/master


<<<<<<< HEAD
--

*`network.community_id`*::
+
--
A hash of source and destination IPs and ports, as well as the protocol used in a communication. This is a tool-agnostic standard to identify flows.
Learn more at https://github.com/corelight/community-id-spec.

type: keyword
=======
type: long

--

[float]
=== cluster.stats
>>>>>>> upstream/master

Cluster stats

<<<<<<< HEAD
--
=======

>>>>>>> upstream/master

*`elasticsearch.cluster.stats.status`*::
+
--
<<<<<<< HEAD
Direction of the network traffic.
Recommended values are:
  * inbound
  * outbound
  * internal
  * external
  * unknown
=======
Cluster status (green, yellow, red).


type: keyword

--

[float]
=== nodes
>>>>>>> upstream/master

Nodes statistics.

<<<<<<< HEAD
type: keyword

example: inbound

--
=======
>>>>>>> upstream/master


*`elasticsearch.cluster.stats.nodes.count`*::
+
--
<<<<<<< HEAD
Host IP address when the source IP address is the proxy.

type: ip
=======
Total number of nodes in cluster.
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: long

>>>>>>> upstream/master
--

*`elasticsearch.cluster.stats.nodes.master`*::
+
--
<<<<<<< HEAD
IANA Protocol Number (https://www.iana.org/assignments/protocol-numbers/protocol-numbers.xhtml). Standardized list of protocols. This aligns well with NetFlow and sFlow related logs which use the IANA Protocol Number.

type: keyword
=======
Number of master-eligible nodes in cluster.
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: long

>>>>>>> upstream/master
--

*`elasticsearch.cluster.stats.nodes.data`*::
+
--
<<<<<<< HEAD
Name given by operators to sections of their network.

type: keyword
=======
Number of data nodes in cluster.
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: long

>>>>>>> upstream/master
--

[float]
=== indices

Indices statistics.



*`elasticsearch.cluster.stats.indices.count`*::
+
--
<<<<<<< HEAD
Total packets transferred in both directions.
If `source.packets` and `destination.packets` are known, `network.packets` is their sum.

type: long
=======
Total number of indices in cluster.
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: long

>>>>>>> upstream/master
--

[float]
=== shards

Shard statistics.



*`elasticsearch.cluster.stats.indices.shards.count`*::
+
--
<<<<<<< HEAD
L7 Network protocol name. ex. http, lumberjack, transport protocol.
The field value must be normalized to lowercase for querying. See the documentation section "Implementing ECS".

type: keyword
=======
Total number of shards in cluster.
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: long

>>>>>>> upstream/master
--

*`elasticsearch.cluster.stats.indices.shards.primaries`*::
+
--
<<<<<<< HEAD
Same as network.iana_number, but instead using the Keyword name of the transport layer (udp, tcp, ipv6-icmp, etc.)
The field value must be normalized to lowercase for querying. See the documentation section "Implementing ECS".

type: keyword
=======
Total number of primary shards in cluster.
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: long

>>>>>>> upstream/master
--

*`elasticsearch.cluster.stats.indices.fielddata.memory.bytes`*::
+
--
<<<<<<< HEAD
In the OSI Model this would be the Network Layer. ipv4, ipv6, ipsec, pim, etc
The field value must be normalized to lowercase for querying. See the documentation section "Implementing ECS".

type: keyword
=======
Memory used for fielddata.
>>>>>>> upstream/master


<<<<<<< HEAD
--

[float]
=== observer
=======
type: long

--

[float]
=== index
>>>>>>> upstream/master

index



*`elasticsearch.index.name`*::
+
--
<<<<<<< HEAD
City name.

type: keyword
=======
Index name.
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: keyword

>>>>>>> upstream/master
--


*`elasticsearch.index.total.docs.count`*::
+
--
<<<<<<< HEAD
Name of the continent.

type: keyword
=======
Total number of documents in the index.
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: long

>>>>>>> upstream/master
--

*`elasticsearch.index.total.docs.deleted`*::
+
--
<<<<<<< HEAD
Country ISO code.

type: keyword
=======
Total number of deleted documents in the index.
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: long

>>>>>>> upstream/master
--

*`elasticsearch.index.total.store.size.bytes`*::
+
--
<<<<<<< HEAD
Country name.

type: keyword
=======
Total size of the index in bytes.
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: long

format: bytes

>>>>>>> upstream/master
--

*`elasticsearch.index.total.segments.count`*::
+
--
<<<<<<< HEAD
Longitude and latitude.

type: geo_point
=======
Total number of index segments.
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: long

>>>>>>> upstream/master
--

*`elasticsearch.index.total.segments.memory.bytes`*::
+
--
<<<<<<< HEAD
User-defined description of a location, at the level of granularity they care about.
Could be the name of their data centers, the floor number, if this describes a local physical entity, city names.
Not typically used in automated geolocation.
=======
Total number of memory used by the segments in bytes.


type: long

format: bytes
>>>>>>> upstream/master

type: keyword

example: boston-dc

--

[float]
=== index.recovery

index



*`elasticsearch.index.recovery.id`*::
+
--
<<<<<<< HEAD
Region ISO code.

type: keyword
=======
Shard recovery id.
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: long

>>>>>>> upstream/master
--

*`elasticsearch.index.recovery.type`*::
+
--
<<<<<<< HEAD
Region name.

type: keyword
=======
Shard recovery type.
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: keyword

>>>>>>> upstream/master
--

*`elasticsearch.index.recovery.primary`*::
+
--
<<<<<<< HEAD
Hostname of the observer.
=======
True if primary shard.


type: boolean
>>>>>>> upstream/master

type: keyword

--

*`elasticsearch.index.recovery.stage`*::
+
--
<<<<<<< HEAD
IP address of the observer.
=======
Recovery stage.


type: keyword
>>>>>>> upstream/master

type: ip

--

*`elasticsearch.index.recovery.target.id`*::
+
--
<<<<<<< HEAD
MAC address of the observer
=======
Target node id.


type: keyword
>>>>>>> upstream/master

type: keyword

--

*`elasticsearch.index.recovery.target.host`*::
+
--
<<<<<<< HEAD
OS family (such as redhat, debian, freebsd, windows).

type: keyword
=======
Target node host address (could be IP address or hostname).
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: keyword

>>>>>>> upstream/master
--

*`elasticsearch.index.recovery.target.name`*::
+
--
<<<<<<< HEAD
Operating system name, including the version or code name.

type: keyword
=======
Target node name.
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: keyword

>>>>>>> upstream/master
--

*`elasticsearch.index.recovery.source.id`*::
+
--
<<<<<<< HEAD
Operating system kernel version as a raw string.

type: keyword
=======
Source node id.
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: keyword

>>>>>>> upstream/master
--

*`elasticsearch.index.recovery.source.host`*::
+
--
<<<<<<< HEAD
Operating system name, without the version.

type: keyword
=======
Source node host address (could be IP address or hostname).
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: keyword

>>>>>>> upstream/master
--

*`elasticsearch.index.recovery.source.name`*::
+
--
<<<<<<< HEAD
Operating system platform (such centos, ubuntu, windows).

type: keyword
=======
Source node name.
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: keyword

>>>>>>> upstream/master
--

[float]
=== index.summary

index




*`elasticsearch.index.summary.primaries.docs.count`*::
+
--
<<<<<<< HEAD
Operating system version as a raw string.

type: keyword
=======
Total number of documents in the index.
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: long

>>>>>>> upstream/master
--

*`elasticsearch.index.summary.primaries.docs.deleted`*::
+
--
<<<<<<< HEAD
Observer serial number.
=======
Total number of deleted documents in the index.


type: long
>>>>>>> upstream/master

type: keyword

--

*`elasticsearch.index.summary.primaries.store.size.bytes`*::
+
--
<<<<<<< HEAD
The type of the observer the data is coming from.
There is no predefined list of observer types. Some examples are `forwarder`, `firewall`, `ids`, `ips`, `proxy`, `poller`, `sensor`, `APM server`.

type: keyword
=======
Total size of the index in bytes.
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: long

format: bytes

>>>>>>> upstream/master
--

*`elasticsearch.index.summary.primaries.segments.count`*::
+
--
<<<<<<< HEAD
observer vendor information.
=======
Total number of index segments.


type: long
>>>>>>> upstream/master

type: keyword

--

*`elasticsearch.index.summary.primaries.segments.memory.bytes`*::
+
--
<<<<<<< HEAD
Observer version.
=======
Total number of memory used by the segments in bytes.


type: long

format: bytes
>>>>>>> upstream/master

type: keyword

--

<<<<<<< HEAD
[float]
=== organization
=======
>>>>>>> upstream/master

*`elasticsearch.index.summary.total.docs.count`*::
+
--
Total number of documents in the index.


type: long

--

*`elasticsearch.index.summary.total.docs.deleted`*::
+
--
<<<<<<< HEAD
Unique identifier for the organization.
=======
Total number of deleted documents in the index.


type: long
>>>>>>> upstream/master

type: keyword

--

*`elasticsearch.index.summary.total.store.size.bytes`*::
+
--
<<<<<<< HEAD
Organization name.

type: keyword

--

[float]
=== os
=======
Total size of the index in bytes.


type: long
>>>>>>> upstream/master

format: bytes

--

*`elasticsearch.index.summary.total.segments.count`*::
+
--
<<<<<<< HEAD
OS family (such as redhat, debian, freebsd, windows).

type: keyword
=======
Total number of index segments.
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: long

>>>>>>> upstream/master
--

*`elasticsearch.index.summary.total.segments.memory.bytes`*::
+
--
<<<<<<< HEAD
Operating system name, including the version or code name.

type: keyword
=======
Total number of memory used by the segments in bytes.
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: long

format: bytes

>>>>>>> upstream/master
--

[float]
=== ml.job

ml



*`elasticsearch.ml.job.id`*::
+
--
<<<<<<< HEAD
Operating system kernel version as a raw string.

type: keyword
=======
Unique ml job id.
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: keyword

>>>>>>> upstream/master
--

*`elasticsearch.ml.job.state`*::
+
--
<<<<<<< HEAD
Operating system name, without the version.

type: keyword
=======
Job state.
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: keyword

>>>>>>> upstream/master
--

*`elasticsearch.ml.job.data_counts.processed_record_count`*::
+
--
<<<<<<< HEAD
Operating system platform (such centos, ubuntu, windows).

type: keyword
=======
Processed data events.
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: long

>>>>>>> upstream/master
--

*`elasticsearch.ml.job.data_counts.invalid_date_count`*::
+
--
<<<<<<< HEAD
Operating system version as a raw string.

type: keyword
=======
The number of records with either a missing date field or a date that could not be parsed.
>>>>>>> upstream/master


<<<<<<< HEAD
--

[float]
=== process
=======
type: long

--

[float]
=== node
>>>>>>> upstream/master

node



*`elasticsearch.node.version`*::
+
--
<<<<<<< HEAD
Array of process arguments.
May be filtered to protect sensitive information.

type: keyword
=======
Node version.
>>>>>>> upstream/master


<<<<<<< HEAD
--

*`process.executable`*::
+
--
Absolute path to the process executable.

type: keyword
=======
type: keyword

--

[float]
=== jvm
>>>>>>> upstream/master

JVM Info.

<<<<<<< HEAD
--
=======

>>>>>>> upstream/master

*`elasticsearch.node.jvm.version`*::
+
--
<<<<<<< HEAD
Process name.
Sometimes called program name or similar.

type: keyword
=======
JVM version.
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: keyword

>>>>>>> upstream/master
--

*`elasticsearch.node.jvm.memory.heap.init.bytes`*::
+
--
<<<<<<< HEAD
Process id.
=======
Heap init used by the JVM in bytes.


type: long

format: bytes
>>>>>>> upstream/master

type: long

--

*`elasticsearch.node.jvm.memory.heap.max.bytes`*::
+
--
<<<<<<< HEAD
Process parent id.
=======
Heap max used by the JVM in bytes.


type: long

format: bytes
>>>>>>> upstream/master

type: long

--

*`elasticsearch.node.jvm.memory.nonheap.init.bytes`*::
+
--
<<<<<<< HEAD
The time the process started.

type: date
=======
Non-Heap init used by the JVM in bytes.
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: long

format: bytes

>>>>>>> upstream/master
--

*`elasticsearch.node.jvm.memory.nonheap.max.bytes`*::
+
--
<<<<<<< HEAD
Thread ID.

type: long
=======
Non-Heap max used by the JVM in bytes.
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: long

format: bytes

>>>>>>> upstream/master
--

*`elasticsearch.node.process.mlockall`*::
+
--
<<<<<<< HEAD
Process title.
The proctitle, some times the same as process name. Can also be different: for example a browser setting its title to the web page currently opened.

type: keyword

--
=======
If process locked in memory.


type: boolean
>>>>>>> upstream/master

--
<<<<<<< HEAD
The working directory of the process.

type: keyword
=======
>>>>>>> upstream/master

[float]
=== node.stats

node_stats

<<<<<<< HEAD
--

[float]
=== related
=======


[float]
=== indices
>>>>>>> upstream/master

Node indices stats



*`elasticsearch.node.stats.indices.docs.count`*::
+
--
<<<<<<< HEAD
All of the IPs seen on your event.
=======
Total number of existing documents.


type: long
>>>>>>> upstream/master

type: ip

--

<<<<<<< HEAD
[float]
=== server
=======
*`elasticsearch.node.stats.indices.docs.deleted`*::
+
--
Total number of deleted documents.
>>>>>>> upstream/master


type: long

--

*`elasticsearch.node.stats.indices.segments.count`*::
+
--
<<<<<<< HEAD
Some event server addresses are defined ambiguously. The event will sometimes list an IP, a domain or a unix socket.  You should always store the raw address in the `.address` field.
Then it should be duplicated to `.ip` or `.domain`, depending on which one it is.
=======
Total number of segments.


type: long
>>>>>>> upstream/master

type: keyword

--

*`elasticsearch.node.stats.indices.segments.memory.bytes`*::
+
--
<<<<<<< HEAD
Bytes sent from the server to the client.

type: long
=======
Total size of segments in bytes.
>>>>>>> upstream/master


type: long

<<<<<<< HEAD
=======
format: bytes

>>>>>>> upstream/master
--

*`elasticsearch.node.stats.indices.store.size.bytes`*::
+
--
<<<<<<< HEAD
Server domain.

type: keyword

--
=======
Total size of the store in bytes.


type: long
>>>>>>> upstream/master

--
<<<<<<< HEAD
City name.

type: keyword
=======
>>>>>>> upstream/master

[float]
=== jvm.mem.pools

<<<<<<< HEAD
--

*`server.geo.continent_name`*::
+
--
Name of the continent.

type: keyword
=======
JVM memory pool stats


>>>>>>> upstream/master

[float]
=== old

<<<<<<< HEAD
--
=======
Old memory pool stats.

>>>>>>> upstream/master


*`elasticsearch.node.stats.jvm.mem.pools.old.max.bytes`*::
+
--
<<<<<<< HEAD
Country ISO code.

type: keyword
=======
Max bytes.
>>>>>>> upstream/master

type: long

<<<<<<< HEAD
=======
format: bytes

>>>>>>> upstream/master
--

*`elasticsearch.node.stats.jvm.mem.pools.old.peak.bytes`*::
+
--
<<<<<<< HEAD
Country name.

type: keyword
=======
Peak bytes.
>>>>>>> upstream/master

type: long

<<<<<<< HEAD
=======
format: bytes

>>>>>>> upstream/master
--

*`elasticsearch.node.stats.jvm.mem.pools.old.peak_max.bytes`*::
+
--
<<<<<<< HEAD
Longitude and latitude.

type: geo_point
=======
Peak max bytes.
>>>>>>> upstream/master

type: long

<<<<<<< HEAD
=======
format: bytes

>>>>>>> upstream/master
--

*`elasticsearch.node.stats.jvm.mem.pools.old.used.bytes`*::
+
--
<<<<<<< HEAD
User-defined description of a location, at the level of granularity they care about.
Could be the name of their data centers, the floor number, if this describes a local physical entity, city names.
Not typically used in automated geolocation.
=======
Used bytes.

type: long

format: bytes
>>>>>>> upstream/master

type: keyword

example: boston-dc

--

[float]
=== young

Young memory pool stats.



*`elasticsearch.node.stats.jvm.mem.pools.young.max.bytes`*::
+
--
<<<<<<< HEAD
Region ISO code.

type: keyword
=======
Max bytes.
>>>>>>> upstream/master

type: long

<<<<<<< HEAD
=======
format: bytes

>>>>>>> upstream/master
--

*`elasticsearch.node.stats.jvm.mem.pools.young.peak.bytes`*::
+
--
<<<<<<< HEAD
Region name.

type: keyword
=======
Peak bytes.
>>>>>>> upstream/master

type: long

<<<<<<< HEAD
=======
format: bytes

>>>>>>> upstream/master
--

*`elasticsearch.node.stats.jvm.mem.pools.young.peak_max.bytes`*::
+
--
<<<<<<< HEAD
IP address of the server.
Can be one or multiple IPv4 or IPv6 addresses.
=======
Peak max bytes.

type: long

format: bytes
>>>>>>> upstream/master

type: ip

--

*`elasticsearch.node.stats.jvm.mem.pools.young.used.bytes`*::
+
--
<<<<<<< HEAD
MAC address of the server.

type: keyword

--
=======
Used bytes.

type: long

format: bytes
>>>>>>> upstream/master

--
<<<<<<< HEAD
Packets sent from the server to the client.

type: long
=======
>>>>>>> upstream/master

[float]
=== survivor

<<<<<<< HEAD
--
=======
Survivor memory pool stats.

>>>>>>> upstream/master


*`elasticsearch.node.stats.jvm.mem.pools.survivor.max.bytes`*::
+
--
<<<<<<< HEAD
Port of the server.
=======
Max bytes.

type: long

format: bytes
>>>>>>> upstream/master

type: long

--

*`elasticsearch.node.stats.jvm.mem.pools.survivor.peak.bytes`*::
+
--
<<<<<<< HEAD
User email address.
=======
Peak bytes.

type: long

format: bytes
>>>>>>> upstream/master

type: keyword

--

*`elasticsearch.node.stats.jvm.mem.pools.survivor.peak_max.bytes`*::
+
--
<<<<<<< HEAD
User's full name, if available.

type: keyword
=======
Peak max bytes.
>>>>>>> upstream/master

type: long

<<<<<<< HEAD
=======
format: bytes

>>>>>>> upstream/master
--

*`elasticsearch.node.stats.jvm.mem.pools.survivor.used.bytes`*::
+
--
<<<<<<< HEAD
Unique identifier for the group on the system/platform.

type: keyword

--
=======
Used bytes.

type: long

format: bytes
>>>>>>> upstream/master

--
<<<<<<< HEAD
Name of the group.

type: keyword

--

*`server.user.hash`*::
+
--
Unique user hash to correlate information for a user in anonymized form.
Useful if `user.id` or `user.name` contain confidential information and cannot be used.

type: keyword

--
=======

[float]
=== jvm.gc.collectors

GC collector stats.



[float]
=== old.collection
>>>>>>> upstream/master

Old collection gc.



*`elasticsearch.node.stats.jvm.gc.collectors.old.collection.count`*::
+
--
<<<<<<< HEAD
One or multiple unique identifiers of the user.
=======


type: long
>>>>>>> upstream/master

type: keyword

--

*`elasticsearch.node.stats.jvm.gc.collectors.old.collection.ms`*::
+
--
<<<<<<< HEAD
Short name or login of the user.

type: keyword
=======
>>>>>>> upstream/master


<<<<<<< HEAD
--

[float]
=== service
=======
type: long

--

[float]
=== young.collection
>>>>>>> upstream/master

Young collection gc.



*`elasticsearch.node.stats.jvm.gc.collectors.young.collection.count`*::
+
--
<<<<<<< HEAD
Ephemeral identifier of this service (if one exists).
This id normally changes across restarts, but `service.id` does not.

type: keyword
=======
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: long

>>>>>>> upstream/master
--

*`elasticsearch.node.stats.jvm.gc.collectors.young.collection.ms`*::
+
--
<<<<<<< HEAD
Unique identifier of the running service.
This id should uniquely identify this service. This makes it possible to correlate logs and metrics for one specific service.
Example: If you are experiencing issues with one redis instance, you can filter on that id to see metrics and logs for that single instance.
=======


type: long
>>>>>>> upstream/master

type: keyword

example: d37e5ebfe0ae6c4972dbe9f0174a1637bb8247f6

--

<<<<<<< HEAD
*`service.name`*::
+
--
Name of the service data is collected from.
The name of the service is normally user given. This allows if two instances of the same service are running on the same machine they can be differentiated by the `service.name`.
Also it allows for distributed services that run on multiple hosts to correlate the related instances based on the name.
In the case of Elasticsearch the service.name could contain the cluster name. For Beats the service.name is by default a copy of the `service.type` field if no name is specified.

type: keyword

example: elasticsearch-metrics

--
=======
[float]
=== fs.summary

File system summary


>>>>>>> upstream/master

*`elasticsearch.node.stats.fs.summary.total.bytes`*::
+
--
<<<<<<< HEAD
Current state of the service.
=======


type: long

format: bytes
>>>>>>> upstream/master

type: keyword

--

*`elasticsearch.node.stats.fs.summary.free.bytes`*::
+
--
<<<<<<< HEAD
The type of the service data is collected from.
The type can be used to group and correlate logs and metrics from one service type.
Example: If logs or metrics are collected from Elasticsearch, `service.type` would be `elasticsearch`.
=======


type: long

format: bytes
>>>>>>> upstream/master

type: keyword

example: elasticsearch

--

*`elasticsearch.node.stats.fs.summary.available.bytes`*::
+
--
<<<<<<< HEAD
Version of the service the data was collected from.
This allows to look at a data set only for a specific version of a service.

type: keyword
=======
>>>>>>> upstream/master


<<<<<<< HEAD
--

[float]
=== source
=======
type: long

format: bytes

--

[float]
=== cluster.pending_task
>>>>>>> upstream/master

`cluster.pending_task` contains a pending task description.



*`elasticsearch.cluster.pending_task.insert_order`*::
+
--
<<<<<<< HEAD
Some event source addresses are defined ambiguously. The event will sometimes list an IP, a domain or a unix socket.  You should always store the raw address in the `.address` field.
Then it should be duplicated to `.ip` or `.domain`, depending on which one it is.
=======
Insert order


type: long
>>>>>>> upstream/master

type: keyword

--

*`elasticsearch.cluster.pending_task.priority`*::
+
--
<<<<<<< HEAD
Bytes sent from the source to the destination.

type: long

example: 184
=======
Priority
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: long

>>>>>>> upstream/master
--

*`elasticsearch.cluster.pending_task.source`*::
+
--
<<<<<<< HEAD
Source domain.
=======
Source. For example: put-mapping


type: keyword
>>>>>>> upstream/master

type: keyword

--

*`elasticsearch.cluster.pending_task.time_in_queue.ms`*::
+
--
<<<<<<< HEAD
City name.

type: keyword
=======
Time in queue
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: long

>>>>>>> upstream/master
--

[float]
=== shard

shard fields



*`elasticsearch.shard.primary`*::
+
--
<<<<<<< HEAD
Name of the continent.

type: keyword
=======
True if this is the primary shard.
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: boolean

>>>>>>> upstream/master
--

*`elasticsearch.shard.number`*::
+
--
<<<<<<< HEAD
Country ISO code.

type: keyword
=======
The number of this shard.
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: long

>>>>>>> upstream/master
--

*`elasticsearch.shard.state`*::
+
--
<<<<<<< HEAD
Country name.

type: keyword
=======
The state of this shard.
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: keyword

>>>>>>> upstream/master
--

*`elasticsearch.shard.relocating_node.name`*::
+
--
<<<<<<< HEAD
Longitude and latitude.

type: geo_point
=======
The node the shard was relocated from.
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: keyword

>>>>>>> upstream/master
--

[[exported-fields-envoyproxy]]
== envoyproxy fields

envoyproxy module



[float]
=== envoyproxy




[float]
=== server

Contains envoy proxy server stats




*`envoyproxy.server.cluster_manager.active_clusters`*::
+
--
<<<<<<< HEAD
User-defined description of a location, at the level of granularity they care about.
Could be the name of their data centers, the floor number, if this describes a local physical entity, city names.
Not typically used in automated geolocation.
=======
Number of currently active (warmed) clusters


type: integer
>>>>>>> upstream/master

type: keyword

example: boston-dc

--

*`envoyproxy.server.cluster_manager.cluster_added`*::
+
--
<<<<<<< HEAD
Region ISO code.

type: keyword
=======
Total clusters added (either via static config or CDS)
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: integer

>>>>>>> upstream/master
--

*`envoyproxy.server.cluster_manager.cluster_modified`*::
+
--
<<<<<<< HEAD
Region name.

type: keyword
=======
Total clusters modified (via CDS)
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: integer

>>>>>>> upstream/master
--

*`envoyproxy.server.cluster_manager.cluster_removed`*::
+
--
<<<<<<< HEAD
IP address of the source.
Can be one or multiple IPv4 or IPv6 addresses.
=======
Total clusters removed (via CDS)


type: integer
>>>>>>> upstream/master

type: ip

--

*`envoyproxy.server.cluster_manager.warming_clusters`*::
+
--
<<<<<<< HEAD
MAC address of the source.
=======
Number of currently warming (not active) clusters


type: integer
>>>>>>> upstream/master

type: keyword

--


*`envoyproxy.server.filesystem.flushed_by_timer`*::
+
--
<<<<<<< HEAD
Packets sent from the source to the destination.

type: long
=======
Total number of times internal flush buffers are written to a file due to flush timeout
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: integer

>>>>>>> upstream/master
--

*`envoyproxy.server.filesystem.reopen_failed`*::
+
--
<<<<<<< HEAD
Port of the source.
=======
Total number of times a file was failed to be opened


type: integer
>>>>>>> upstream/master

type: long

--

*`envoyproxy.server.filesystem.write_buffered`*::
+
--
<<<<<<< HEAD
User email address.
=======
Total number of times file data is moved to Envoys internal flush buffer


type: integer
>>>>>>> upstream/master

type: keyword

--

*`envoyproxy.server.filesystem.write_completed`*::
+
--
<<<<<<< HEAD
User's full name, if available.

type: keyword
=======
Total number of times a file was written
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: integer

>>>>>>> upstream/master
--

*`envoyproxy.server.filesystem.write_total_buffered`*::
+
--
<<<<<<< HEAD
Unique identifier for the group on the system/platform.
=======
Current total size of internal flush buffer in bytes


type: integer
>>>>>>> upstream/master

type: keyword

--


*`envoyproxy.server.runtime.load_error`*::
+
--
<<<<<<< HEAD
Name of the group.
=======
Total number of load attempts that resulted in an error


type: integer
>>>>>>> upstream/master

type: keyword

--

*`envoyproxy.server.runtime.load_success`*::
+
--
<<<<<<< HEAD
Unique user hash to correlate information for a user in anonymized form.
Useful if `user.id` or `user.name` contain confidential information and cannot be used.
=======
Total number of load attempts that were successful


type: integer
>>>>>>> upstream/master

type: keyword

--

*`envoyproxy.server.runtime.num_keys`*::
+
--
<<<<<<< HEAD
One or multiple unique identifiers of the user.
=======
Number of keys currently loaded


type: integer
>>>>>>> upstream/master

type: keyword

--

*`envoyproxy.server.runtime.override_dir_exists`*::
+
--
<<<<<<< HEAD
Short name or login of the user.

type: keyword
=======
Total number of loads that did use an override directory
>>>>>>> upstream/master


<<<<<<< HEAD
--

[float]
=== url

URL fields provide support for complete or partial URLs, and supports the breaking down into scheme, domain, path, and so on.


*`url.domain`*::
+
--
Domain of the url, such as "www.elastic.co".
In some cases a URL may refer to an IP and/or port directly, without a domain name. In this case, the IP address would go to the `domain` field.

type: keyword
=======
type: integer

--

*`envoyproxy.server.runtime.override_dir_not_exists`*::
+
--
Total number of loads that did not use an override directory
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: integer

>>>>>>> upstream/master
--

*`envoyproxy.server.runtime.admin_overrides_active`*::
+
--
<<<<<<< HEAD
Portion of the url after the `#`, such as "top".
The `#` is not part of the fragment.
=======
type: integer
>>>>>>> upstream/master

type: keyword

--


*`envoyproxy.server.listener_manager.listener_added`*::
+
--
<<<<<<< HEAD
If full URLs are important to your use case, they should be stored in `url.full`, whether this field is reconstructed or present in the event source.

type: keyword
=======
Total listeners added (either via static config or LDS)
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: integer

>>>>>>> upstream/master
--

*`envoyproxy.server.listener_manager.listener_create_failure`*::
+
--
<<<<<<< HEAD
Unmodified original url as seen in the event source.
Note that in network monitoring, the observed URL may be a full URL, whereas in access logs, the URL is often just represented as a path.
This field is meant to represent the URL as it was observed, complete or not.
=======
Total failed listener object additions to workers


type: integer
>>>>>>> upstream/master

type: keyword

example: https://www.elastic.co:443/search?q=elasticsearch#top or /search?q=elasticsearch

--

*`envoyproxy.server.listener_manager.listener_create_success`*::
+
--
<<<<<<< HEAD
Password of the request.
=======
Total listener objects successfully added to workers


type: integer
>>>>>>> upstream/master

type: keyword

--

*`envoyproxy.server.listener_manager.listener_modified`*::
+
--
<<<<<<< HEAD
Path of the request, such as "/search".
=======
Total listeners modified (via LDS)


type: integer
>>>>>>> upstream/master

type: keyword

--

*`envoyproxy.server.listener_manager.listener_removed`*::
+
--
<<<<<<< HEAD
Port of the request, such as 443.

type: long
=======
Total listeners removed (via LDS)
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: integer

>>>>>>> upstream/master
--

*`envoyproxy.server.listener_manager.total_listeners_active`*::
+
--
<<<<<<< HEAD
The query field describes the query string of the request, such as "q=elasticsearch".
The `?` is excluded from the query string. If a URL contains no `?`, there is no query field. If there is a `?` but no query, the query field exists with an empty string. The `exists` query can be used to differentiate between the two cases.
=======
Number of currently active listeners


type: integer
>>>>>>> upstream/master

type: keyword

--

*`envoyproxy.server.listener_manager.total_listeners_draining`*::
+
--
<<<<<<< HEAD
Scheme of the request, such as "https".
Note: The `:` is not part of the scheme.

type: keyword
=======
Number of currently draining listeners
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: integer

>>>>>>> upstream/master
--

*`envoyproxy.server.listener_manager.total_listeners_warming`*::
+
--
<<<<<<< HEAD
Username of the request.

type: keyword

--

[float]
=== user
=======
Number of currently warming listeners


type: integer
>>>>>>> upstream/master

--


*`envoyproxy.server.stats.overflow`*::
+
--
<<<<<<< HEAD
User email address.
=======
Total number of times Envoy cannot allocate a statistic due to a shortage of shared memory


type: integer
>>>>>>> upstream/master

type: keyword

--


*`envoyproxy.server.server.days_until_first_cert_expiring`*::
+
--
<<<<<<< HEAD
User's full name, if available.

type: keyword
=======
Number of days until the next certificate being managed will expire
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: integer

>>>>>>> upstream/master
--

*`envoyproxy.server.server.live`*::
+
--
<<<<<<< HEAD
Unique identifier for the group on the system/platform.
=======
1 if the server is not currently draining, 0 otherwise


type: integer
>>>>>>> upstream/master

type: keyword

--

*`envoyproxy.server.server.memory_allocated`*::
+
--
<<<<<<< HEAD
Name of the group.
=======
Current amount of allocated memory in bytes


type: integer
>>>>>>> upstream/master

type: keyword

--

*`envoyproxy.server.server.memory_heap_size`*::
+
--
<<<<<<< HEAD
Unique user hash to correlate information for a user in anonymized form.
Useful if `user.id` or `user.name` contain confidential information and cannot be used.
=======
Current reserved heap size in bytes


type: integer
>>>>>>> upstream/master

type: keyword

--

*`envoyproxy.server.server.parent_connections`*::
+
--
<<<<<<< HEAD
One or multiple unique identifiers of the user.
=======
Total connections of the old Envoy process on hot restart


type: integer
>>>>>>> upstream/master

type: keyword

--

*`envoyproxy.server.server.total_connections`*::
+
--
<<<<<<< HEAD
Short name or login of the user.

type: keyword
=======
Total connections of both new and old Envoy processes
>>>>>>> upstream/master


<<<<<<< HEAD
--

[float]
=== user_agent
=======
type: integer

--

*`envoyproxy.server.server.uptime`*::
+
--
Current server uptime in seconds
>>>>>>> upstream/master


type: integer

--

*`envoyproxy.server.server.version`*::
+
--
<<<<<<< HEAD
Name of the device.

type: keyword
=======
Integer represented version number based on SCM revision
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: integer

>>>>>>> upstream/master
--

*`envoyproxy.server.server.watchdog_mega_miss`*::
+
--
<<<<<<< HEAD
Name of the user agent.

type: keyword
=======
type: integer
>>>>>>> upstream/master

--

<<<<<<< HEAD
=======
*`envoyproxy.server.server.watchdog_miss`*::
+
--
type: integer

>>>>>>> upstream/master
--

*`envoyproxy.server.server.hot_restart_epoch`*::
+
--
<<<<<<< HEAD
Unparsed version of the user_agent.

type: keyword
=======
Current hot restart epoch
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: integer

>>>>>>> upstream/master
--


*`envoyproxy.server.http2.header_overflow`*::
+
--
<<<<<<< HEAD
OS family (such as redhat, debian, freebsd, windows).

type: keyword
=======
Total number of connections reset due to the headers being larger than Envoy::Http::Http2::ConnectionImpl::StreamImpl::MAX_HEADER_SIZE (63k)
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: integer

>>>>>>> upstream/master
--

*`envoyproxy.server.http2.headers_cb_no_stream`*::
+
--
<<<<<<< HEAD
Operating system name, including the version or code name.

type: keyword
=======
Total number of errors where a header callback is called without an associated stream. This tracks an unexpected occurrence due to an as yet undiagnosed bug
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: integer

>>>>>>> upstream/master
--

*`envoyproxy.server.http2.rx_messaging_error`*::
+
--
<<<<<<< HEAD
Operating system kernel version as a raw string.

type: keyword
=======
Total number of invalid received frames that violated section 8 of the HTTP/2 spec. This will result in a tx_reset
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: integer

>>>>>>> upstream/master
--

*`envoyproxy.server.http2.rx_reset`*::
+
--
<<<<<<< HEAD
Operating system name, without the version.

type: keyword
=======
Total number of reset stream frames received by Envoy
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: integer

>>>>>>> upstream/master
--

*`envoyproxy.server.http2.too_many_header_frames`*::
+
--
<<<<<<< HEAD
Operating system platform (such centos, ubuntu, windows).

type: keyword
=======
Total number of times an HTTP2 connection is reset due to receiving too many headers frames. Envoy currently supports proxying at most one header frame for 100-Continue one non-100 response code header frame and one frame with trailers
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: integer

>>>>>>> upstream/master
--

*`envoyproxy.server.http2.trailers`*::
+
--
<<<<<<< HEAD
Operating system version as a raw string.

type: keyword
=======
Total number of trailers seen on requests coming from downstream
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: integer

>>>>>>> upstream/master
--

*`envoyproxy.server.http2.tx_reset`*::
+
--
<<<<<<< HEAD
Version of the user agent.

type: keyword
=======
Total number of reset stream frames transmitted by Envoy
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: integer

>>>>>>> upstream/master
--

[[exported-fields-etcd]]
== Etcd fields

etcd Module



[float]
<<<<<<< HEAD
=== elasticsearch
=======
=== etcd
>>>>>>> upstream/master

`etcd` contains statistics that were read from Etcd



*`etcd.api_version`*::
+
--
<<<<<<< HEAD
Elasticsearch cluster name.
=======
Etcd API version for metrics retrieval

>>>>>>> upstream/master

type: keyword

type: keyword

--

<<<<<<< HEAD
*`elasticsearch.cluster.id`*::
+
--
Elasticsearch cluster id.


type: keyword

--

*`elasticsearch.cluster.state.id`*::
+
--
Elasticsearch state id.


type: keyword

--
=======
[float]
=== leader

Contains etcd leader statistics.



[float]
=== followers.counts

The number of failed and successful Raft RPC requests.


>>>>>>> upstream/master

*`etcd.leader.followers.counts.followers.counts.success`*::
+
--
<<<<<<< HEAD
Node ID
=======
successful Raft RPC requests
>>>>>>> upstream/master

type: integer

type: keyword

--

*`etcd.leader.followers.counts.followers.counts.fail`*::
+
--
<<<<<<< HEAD
Node name.
=======
failed Raft RPC requests
>>>>>>> upstream/master

type: integer

type: keyword

--

[float]
<<<<<<< HEAD
=== ccr

Cross-cluster replication stats
=======
=== followers.latency
>>>>>>> upstream/master

latency to each peer in the cluster



*`etcd.leader.followers.latency.followers.latency.average`*::
+
--
<<<<<<< HEAD
Name of leader index
=======
type: scaled_float

--
>>>>>>> upstream/master

*`etcd.leader.followers.latency.followers.latency.current`*::
+
--
type: scaled_float

type: keyword

--

*`etcd.leader.followers.latency.followers.latency.maximum`*::
+
--
<<<<<<< HEAD
Maximum sequence number of operation on the leader shard
=======
type: scaled_float

--
>>>>>>> upstream/master

*`etcd.leader.followers.latency.followers.latency.minimum`*::
+
--
type: integer

type: long

--

*`etcd.leader.followers.latency.follower.latency.standardDeviation`*::
+
--
type: scaled_float

--

*`etcd.leader.leader`*::
+
--
<<<<<<< HEAD
Name of follower index
=======
ID of actual leader

type: keyword

--
>>>>>>> upstream/master

[float]
=== server

<<<<<<< HEAD
type: keyword

--
=======
Server metrics from the Etcd V3 /metrics endpoint
>>>>>>> upstream/master



*`etcd.server.has_leader`*::
+
--
<<<<<<< HEAD
Number of the shard within the index
=======
Whether a leader exists in the cluster

>>>>>>> upstream/master

type: byte

type: long

--

*`etcd.server.leader_changes.count`*::
+
--
<<<<<<< HEAD
Number of operations indexed (replicated) into the follower shard from the leader shard
=======
Number of leader changes seen at the cluster

>>>>>>> upstream/master

type: long

type: long

--

*`etcd.server.proposals_committed.count`*::
+
--
<<<<<<< HEAD
Time, in ms, since the follower last fetched from the leader
=======
Number of consensus proposals commited

>>>>>>> upstream/master

type: long

type: long

--

*`etcd.server.proposals_pending.count`*::
+
--
<<<<<<< HEAD
Global checkpoint value on follower shard
=======
Number of consensus proposals pending


type: long

--

*`etcd.server.proposals_failed.count`*::
+
--
Number of consensus proposals failed

>>>>>>> upstream/master

type: long

type: long

--

<<<<<<< HEAD
[float]
=== cluster.stats
=======
*`etcd.server.grpc_started.count`*::
+
--
Number of sent gRPC requests
>>>>>>> upstream/master


type: long

--

*`etcd.server.grpc_handled.count`*::
+
--
<<<<<<< HEAD
Cluster status (green, yellow, red).
=======
Number of received gRPC requests

>>>>>>> upstream/master

type: long

type: keyword

--

[float]
<<<<<<< HEAD
=== nodes
=======
=== disk
>>>>>>> upstream/master

Disk metrics from the Etcd V3 /metrics endpoint



*`etcd.disk.mvcc_db_total_size.bytes`*::
+
--
<<<<<<< HEAD
Total number of nodes in cluster.
=======
Size of stored data at MVCC

>>>>>>> upstream/master

type: long

format: bytes

type: long

--

*`etcd.disk.wal_fsync_duration.ns.bucket.*`*::
+
--
<<<<<<< HEAD
Number of master-eligible nodes in cluster.
=======
Latency for writing ahead logs to disk

>>>>>>> upstream/master

type: object

type: long

--

*`etcd.disk.wal_fsync_duration.ns.count`*::
+
--
<<<<<<< HEAD
Number of data nodes in cluster.
=======
Write ahead logs count

>>>>>>> upstream/master

type: long

type: long

--

<<<<<<< HEAD
[float]
=== indices

Indices statistics.



*`elasticsearch.cluster.stats.indices.count`*::
+
--
Total number of indices in cluster.
=======
*`etcd.disk.wal_fsync_duration.ns.sum`*::
+
--
Write ahead logs latency sum

>>>>>>> upstream/master

type: long

type: long

--

<<<<<<< HEAD
[float]
=== shards

Shard statistics.



*`elasticsearch.cluster.stats.indices.shards.count`*::
+
--
Total number of shards in cluster.
=======
*`etcd.disk.backend_commit_duration.ns.bucket.*`*::
+
--
Latency for writing backend changes to disk

>>>>>>> upstream/master

type: object

type: long

--

*`etcd.disk.backend_commit_duration.ns.count`*::
+
--
<<<<<<< HEAD
Total number of primary shards in cluster.
=======
Backend commits count

>>>>>>> upstream/master

type: long

type: long

--

*`etcd.disk.backend_commit_duration.ns.sum`*::
+
--
<<<<<<< HEAD
Memory used for fielddata.
=======
Backend commits latency sum

>>>>>>> upstream/master

type: long

type: long

--

[float]
<<<<<<< HEAD
=== index
=======
=== memory
>>>>>>> upstream/master

Memory metrics from the Etcd V3 /metrics endpoint



*`etcd.memory.go_memstats_alloc.bytes`*::
+
--
<<<<<<< HEAD
Index name.
=======
Memory allocated bytes as of MemStats Go


type: long

format: bytes

--

[float]
=== network
>>>>>>> upstream/master

Network metrics from the Etcd V3 /metrics endpoint

<<<<<<< HEAD
type: keyword

--
=======
>>>>>>> upstream/master


*`etcd.network.client_grpc_sent.bytes`*::
+
--
<<<<<<< HEAD
Total number of documents in the index.
=======
gRPC sent bytes total

>>>>>>> upstream/master

type: long

format: bytes

type: long

--

*`etcd.network.client_grpc_received.bytes`*::
+
--
<<<<<<< HEAD
Total number of deleted documents in the index.
=======
gRPC received bytes total

>>>>>>> upstream/master

type: long

<<<<<<< HEAD
type: long

--
=======
format: bytes
>>>>>>> upstream/master

--
<<<<<<< HEAD
Total size of the index in bytes.


type: long
=======

[float]
=== self

Contains etcd self statistics.
>>>>>>> upstream/master

format: bytes


*`etcd.self.id`*::
+
--
<<<<<<< HEAD
Total number of index segments.
=======
the unique identifier for the member

>>>>>>> upstream/master

type: keyword

type: long

--

*`etcd.self.leaderinfo.leader`*::
+
--
<<<<<<< HEAD
Total number of memory used by the segments in bytes.


type: long

format: bytes

--

[float]
=== index.recovery
=======
id of the current leader member


type: keyword

--

*`etcd.self.leaderinfo.starttime`*::
+
--
the time when this node was started
>>>>>>> upstream/master


type: keyword

--

*`etcd.self.leaderinfo.uptime`*::
+
--
<<<<<<< HEAD
Shard recovery id.
=======
amount of time the leader has been leader

>>>>>>> upstream/master

type: keyword

type: long

--

*`etcd.self.name`*::
+
--
<<<<<<< HEAD
Shard recovery type.
=======
this member's name

>>>>>>> upstream/master

type: keyword

type: keyword

--

*`etcd.self.recv.appendrequest.count`*::
+
--
<<<<<<< HEAD
True if primary shard.
=======
number of append requests this node has processed

>>>>>>> upstream/master

type: integer

type: boolean

--

*`etcd.self.recv.bandwidthrate`*::
+
--
<<<<<<< HEAD
Recovery stage.
=======
number of bytes per second this node is receiving (follower only)

>>>>>>> upstream/master

type: scaled_float

type: keyword

--

*`etcd.self.recv.pkgrate`*::
+
--
<<<<<<< HEAD
Target node id.
=======
number of requests per second this node is receiving (follower only)

>>>>>>> upstream/master

type: scaled_float

type: keyword

--

*`etcd.self.send.appendrequest.count`*::
+
--
<<<<<<< HEAD
Target node host address (could be IP address or hostname).
=======
number of requests that this node has sent

>>>>>>> upstream/master

type: integer

type: keyword

--

*`etcd.self.send.bandwidthrate`*::
+
--
<<<<<<< HEAD
Target node name.
=======
number of bytes per second this node is sending (leader only). This value is undefined on single member clusters.

>>>>>>> upstream/master

type: scaled_float

type: keyword

--

*`etcd.self.send.pkgrate`*::
+
--
<<<<<<< HEAD
Source node id.
=======
number of requests per second this node is sending (leader only). This value is undefined on single member clusters.

>>>>>>> upstream/master

type: scaled_float

type: keyword

--

*`etcd.self.starttime`*::
+
--
<<<<<<< HEAD
Source node host address (could be IP address or hostname).
=======
the time when this node was started

>>>>>>> upstream/master

type: keyword

type: keyword

--

*`etcd.self.state`*::
+
--
<<<<<<< HEAD
Source node name.
=======
either leader or follower

>>>>>>> upstream/master

type: keyword

type: keyword

--

[float]
<<<<<<< HEAD
=== index.summary

index
=======
=== store
>>>>>>> upstream/master

The store statistics include information about the operations that this node has handled.



*`etcd.store.gets.success`*::
+
--
<<<<<<< HEAD
Total number of documents in the index.

=======
type: integer
>>>>>>> upstream/master

type: long

--

*`etcd.store.gets.fail`*::
+
--
<<<<<<< HEAD
Total number of deleted documents in the index.

=======
type: integer
>>>>>>> upstream/master

type: long

--

*`etcd.store.sets.success`*::
+
--
<<<<<<< HEAD
Total size of the index in bytes.


type: long

format: bytes
=======
type: integer
>>>>>>> upstream/master

--

*`etcd.store.sets.fail`*::
+
--
<<<<<<< HEAD
Total number of index segments.

=======
type: integer
>>>>>>> upstream/master

type: long

--

*`etcd.store.delete.success`*::
+
--
<<<<<<< HEAD
Total number of memory used by the segments in bytes.


type: long

format: bytes
=======
type: integer

--

*`etcd.store.delete.fail`*::
+
--
type: integer

--
>>>>>>> upstream/master

*`etcd.store.update.success`*::
+
--
type: integer

--

*`etcd.store.update.fail`*::
+
--
<<<<<<< HEAD
Total number of documents in the index.
=======
type: integer

--
>>>>>>> upstream/master

*`etcd.store.create.success`*::
+
--
type: integer

type: long

--

*`etcd.store.create.fail`*::
+
--
<<<<<<< HEAD
Total number of deleted documents in the index.
=======
type: integer

--
>>>>>>> upstream/master

*`etcd.store.compareandswap.success`*::
+
--
type: integer

type: long

--

*`etcd.store.compareandswap.fail`*::
+
--
<<<<<<< HEAD
Total size of the index in bytes.


type: long

format: bytes
=======
type: integer

--

*`etcd.store.compareanddelete.success`*::
+
--
type: integer
>>>>>>> upstream/master

--

*`etcd.store.compareanddelete.fail`*::
+
--
<<<<<<< HEAD
Total number of index segments.
=======
type: integer

--
>>>>>>> upstream/master

*`etcd.store.expire.count`*::
+
--
type: integer

type: long

--

*`etcd.store.watchers`*::
+
--
<<<<<<< HEAD
Total number of memory used by the segments in bytes.


type: long
=======
type: integer

--

[[exported-fields-golang]]
== Golang fields

Golang module
>>>>>>> upstream/master

format: bytes


[float]
<<<<<<< HEAD
=== ml.job
=======
=== golang
>>>>>>> upstream/master




<<<<<<< HEAD
*`elasticsearch.ml.job.id`*::
+
--
Unique ml job id.


type: keyword

--
=======
[float]
=== expvar

expvar


>>>>>>> upstream/master

*`golang.expvar.cmdline`*::
+
--
<<<<<<< HEAD
Job state.
=======
The cmdline of this Go program start with.

>>>>>>> upstream/master

type: keyword

type: keyword

--

<<<<<<< HEAD
*`elasticsearch.ml.job.data_counts.processed_record_count`*::
+
--
Processed data events.


type: long

--
=======
[float]
=== heap

The Go program heap information exposed by expvar.


>>>>>>> upstream/master

*`golang.heap.cmdline`*::
+
--
<<<<<<< HEAD
The number of records with either a missing date field or a date that could not be parsed.
=======
The cmdline of this Go program start with.

>>>>>>> upstream/master

type: keyword

type: long

--

[float]
<<<<<<< HEAD
=== node

node



*`elasticsearch.node.version`*::
+
--
Node version.


type: keyword

--

[float]
=== jvm
=======
=== gc

Garbage collector summary.



[float]
=== total_pause
>>>>>>> upstream/master

Total GC pause duration over lifetime of process.



*`golang.heap.gc.total_pause.ns`*::
+
--
<<<<<<< HEAD
JVM version.
=======
Duration in Ns.

>>>>>>> upstream/master

type: long

type: keyword

--

*`golang.heap.gc.total_count`*::
+
--
<<<<<<< HEAD
Heap init used by the JVM in bytes.


type: long

format: bytes
=======
Total number of GC was happened.


type: long
>>>>>>> upstream/master

--

*`golang.heap.gc.next_gc_limit`*::
+
--
<<<<<<< HEAD
Heap max used by the JVM in bytes.
=======
Next collection will happen when HeapAlloc > this amount.
>>>>>>> upstream/master


type: long

format: bytes

--

*`golang.heap.gc.cpu_fraction`*::
+
--
<<<<<<< HEAD
Non-Heap init used by the JVM in bytes.


type: long
=======
Fraction of CPU time used by GC.
>>>>>>> upstream/master

format: bytes

type: float

--
<<<<<<< HEAD
Non-Heap max used by the JVM in bytes.


type: long
=======

[float]
=== pause

Last GC pause durations during the monitoring period.
>>>>>>> upstream/master

format: bytes


*`golang.heap.gc.pause.count`*::
+
--
<<<<<<< HEAD
If process locked in memory.
=======
Count of GC pause duration during this collect period.

>>>>>>> upstream/master

type: long

type: boolean

--

[float]
<<<<<<< HEAD
=== node.stats

node_stats



[float]
=== indices
=======
=== sum
>>>>>>> upstream/master

Total GC pause duration during this collect period.



*`golang.heap.gc.pause.sum.ns`*::
+
--
<<<<<<< HEAD
Total number of existing documents.
=======
Duration in Ns.

>>>>>>> upstream/master

type: long

type: long

--

<<<<<<< HEAD
*`elasticsearch.node.stats.indices.docs.deleted`*::
+
--
Total number of deleted documents.


type: long

--
=======
[float]
=== max

Max GC pause duration during this collect period.


>>>>>>> upstream/master

*`golang.heap.gc.pause.max.ns`*::
+
--
<<<<<<< HEAD
Total number of segments.


type: long

--
=======
Duration in Ns.


type: long
>>>>>>> upstream/master

--
<<<<<<< HEAD
Total size of segments in bytes.


type: long
=======

[float]
=== avg

Average GC pause duration during this collect period.
>>>>>>> upstream/master

format: bytes


*`golang.heap.gc.pause.avg.ns`*::
+
--
<<<<<<< HEAD
Total size of the store in bytes.
=======
Duration in Ns.

>>>>>>> upstream/master

type: long

type: long

--

[float]
<<<<<<< HEAD
=== jvm.mem.pools

JVM memory pool stats



[float]
=== old
=======
=== system
>>>>>>> upstream/master

Heap summary,which bytes was obtained from system.



*`golang.heap.system.total`*::
+
--
<<<<<<< HEAD
Max bytes.
=======
Total bytes obtained from system (sum of XxxSys below).

>>>>>>> upstream/master

type: long

format: bytes

--

*`golang.heap.system.obtained`*::
+
--
<<<<<<< HEAD
Peak bytes.
=======
Via HeapSys, bytes obtained from system. heap_sys = heap_idle + heap_inuse.

>>>>>>> upstream/master

type: long

format: bytes

--

*`golang.heap.system.stack`*::
+
--
<<<<<<< HEAD
Peak max bytes.
=======
Bytes used by stack allocator, and these bytes was obtained from system.

>>>>>>> upstream/master

type: long

format: bytes

--

*`golang.heap.system.released`*::
+
--
<<<<<<< HEAD
Used bytes.
=======
Bytes released to the OS.

>>>>>>> upstream/master

type: long

format: bytes

--

[float]
<<<<<<< HEAD
=== young
=======
=== allocations
>>>>>>> upstream/master

Heap allocations summary.



*`golang.heap.allocations.mallocs`*::
+
--
<<<<<<< HEAD
Max bytes.

type: long
=======
Number of mallocs.
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: long

>>>>>>> upstream/master
--

*`golang.heap.allocations.frees`*::
+
--
<<<<<<< HEAD
Peak bytes.

type: long
=======
Number of frees.
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: long

>>>>>>> upstream/master
--

*`golang.heap.allocations.objects`*::
+
--
<<<<<<< HEAD
Peak max bytes.

type: long
=======
Total number of allocated objects.
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: long

>>>>>>> upstream/master
--

*`golang.heap.allocations.total`*::
+
--
<<<<<<< HEAD
Used bytes.
=======
Bytes allocated (even if freed) throughout the lifetime.

>>>>>>> upstream/master

type: long

format: bytes

--

<<<<<<< HEAD
[float]
=== survivor

Survivor memory pool stats.



*`elasticsearch.node.stats.jvm.mem.pools.survivor.max.bytes`*::
+
--
Max bytes.
=======
*`golang.heap.allocations.allocated`*::
+
--
Bytes allocated and not yet freed (same as Alloc above).

>>>>>>> upstream/master

type: long

format: bytes

--

*`golang.heap.allocations.idle`*::
+
--
<<<<<<< HEAD
Peak bytes.
=======
Bytes in idle spans.

>>>>>>> upstream/master

type: long

format: bytes

--

*`golang.heap.allocations.active`*::
+
--
<<<<<<< HEAD
Peak max bytes.
=======
Bytes in non-idle span.

>>>>>>> upstream/master

type: long

format: bytes

--

<<<<<<< HEAD
*`elasticsearch.node.stats.jvm.mem.pools.survivor.used.bytes`*::
+
--
Used bytes.

type: long
=======
[[exported-fields-graphite]]
== Graphite fields
>>>>>>> upstream/master

graphite Module

<<<<<<< HEAD
--

[float]
=== jvm.gc.collectors
=======


[float]
=== graphite
>>>>>>> upstream/master




[float]
<<<<<<< HEAD
=== old.collection
=======
=== server
>>>>>>> upstream/master

server



*`graphite.server.example`*::
+
--
<<<<<<< HEAD


type: long

--

*`elasticsearch.node.stats.jvm.gc.collectors.old.collection.ms`*::
+
--
=======
Example field


type: keyword

--

[[exported-fields-haproxy]]
== HAProxy fields
>>>>>>> upstream/master

HAProxy Module

type: long


[float]
<<<<<<< HEAD
=== young.collection
=======
=== haproxy
>>>>>>> upstream/master

HAProxy metrics.



<<<<<<< HEAD
*`elasticsearch.node.stats.jvm.gc.collectors.young.collection.count`*::
+
--
=======
[float]
=== info
>>>>>>> upstream/master

General information about HAProxy processes.

type: long


*`haproxy.info.processes`*::
+
--
<<<<<<< HEAD
=======
Number of processes.
>>>>>>> upstream/master


type: long

--

<<<<<<< HEAD
[float]
=== fs.summary

File system summary



*`elasticsearch.node.stats.fs.summary.total.bytes`*::
+
--

=======
*`haproxy.info.process_num`*::
+
--
Process number.
>>>>>>> upstream/master

type: long

<<<<<<< HEAD
format: bytes
=======
type: long
>>>>>>> upstream/master

--

*`haproxy.info.pid`*::
+
--
<<<<<<< HEAD


type: long

format: bytes
=======
Process ID.


type: alias

alias to: process.pid
>>>>>>> upstream/master

--

*`haproxy.info.run_queue`*::
+
--
<<<<<<< HEAD


type: long

format: bytes

--

[float]
=== cluster.pending_task

`cluster.pending_task` contains a pending task description.
=======

>>>>>>> upstream/master

type: long

--

*`haproxy.info.tasks`*::
+
--
<<<<<<< HEAD
Insert order
=======

>>>>>>> upstream/master

type: long

type: long

--

*`haproxy.info.uptime.sec`*::
+
--
<<<<<<< HEAD
Priority
=======
Current uptime in seconds.

>>>>>>> upstream/master

type: long

type: long

--

*`haproxy.info.memory.max.bytes`*::
+
--
<<<<<<< HEAD
Source. For example: put-mapping
=======
Maximum amount of memory usage in bytes (the 'Memmax_MB' value converted to bytes).

>>>>>>> upstream/master

type: long

format: bytes

type: keyword

--

*`haproxy.info.ulimit_n`*::
+
--
<<<<<<< HEAD
Time in queue
=======
Maximum number of open files for the process.

>>>>>>> upstream/master

type: long

type: long

--

[float]
<<<<<<< HEAD
=== shard
=======
=== compress
>>>>>>> upstream/master




<<<<<<< HEAD
*`elasticsearch.shard.primary`*::
+
--
True if this is the primary shard.


type: boolean

--
=======
[float]
=== bps



>>>>>>> upstream/master

*`haproxy.info.compress.bps.in`*::
+
--
<<<<<<< HEAD
The number of this shard.
=======

>>>>>>> upstream/master

type: long

type: long

--

*`haproxy.info.compress.bps.out`*::
+
--
<<<<<<< HEAD
The state of this shard.
=======

>>>>>>> upstream/master

type: long

type: keyword

--

*`haproxy.info.compress.bps.rate_limit`*::
+
--
<<<<<<< HEAD
The node the shard was relocated from.
=======

>>>>>>> upstream/master

type: long

type: keyword

--

[float]
<<<<<<< HEAD
=== envoyproxy
=======
=== connection
>>>>>>> upstream/master




[float]
<<<<<<< HEAD
=== server

Contains envoy proxy server stats
=======
=== rate
>>>>>>> upstream/master




*`haproxy.info.connection.rate.value`*::
+
--
<<<<<<< HEAD
Number of currently active (warmed) clusters
=======

>>>>>>> upstream/master

type: long

type: integer

--

*`haproxy.info.connection.rate.limit`*::
+
--
<<<<<<< HEAD
Total clusters added (either via static config or CDS)
=======

>>>>>>> upstream/master

type: long

type: integer

--

*`haproxy.info.connection.rate.max`*::
+
--
<<<<<<< HEAD
Total clusters modified (via CDS)
=======

>>>>>>> upstream/master

type: long

type: integer

--

*`haproxy.info.connection.current`*::
+
--
<<<<<<< HEAD
Total clusters removed (via CDS)
=======
Current connections.

>>>>>>> upstream/master

type: long

type: integer

--

*`haproxy.info.connection.total`*::
+
--
<<<<<<< HEAD
Number of currently warming (not active) clusters
=======
Total connections.

>>>>>>> upstream/master

type: long

type: integer

--

*`haproxy.info.connection.ssl.current`*::
+
--
<<<<<<< HEAD
Total number of times internal flush buffers are written to a file due to flush timeout
=======
Current SSL connections.

>>>>>>> upstream/master

type: long

type: integer

--

*`haproxy.info.connection.ssl.total`*::
+
--
<<<<<<< HEAD
Total number of times a file was failed to be opened
=======
Total SSL connections.

>>>>>>> upstream/master

type: long

type: integer

--

*`haproxy.info.connection.ssl.max`*::
+
--
<<<<<<< HEAD
Total number of times file data is moved to Envoys internal flush buffer
=======
Maximum SSL connections.

>>>>>>> upstream/master

type: long

type: integer

--

*`haproxy.info.connection.max`*::
+
--
<<<<<<< HEAD
Total number of times a file was written
=======
Maximum connections.

>>>>>>> upstream/master

type: long

type: integer

--

*`haproxy.info.connection.hard_max`*::
+
--
<<<<<<< HEAD
Current total size of internal flush buffer in bytes
=======

>>>>>>> upstream/master

type: long

type: integer

--

*`haproxy.info.requests.total`*::
+
--
<<<<<<< HEAD
Total number of load attempts that resulted in an error
=======

>>>>>>> upstream/master

type: long

type: integer

--

*`haproxy.info.sockets.max`*::
+
--
<<<<<<< HEAD
Total number of load attempts that were successful
=======

>>>>>>> upstream/master

type: long

type: integer

--

*`haproxy.info.requests.max`*::
+
--
<<<<<<< HEAD
Number of keys currently loaded
=======

>>>>>>> upstream/master

type: long

type: integer

--

<<<<<<< HEAD
*`envoyproxy.server.runtime.override_dir_exists`*::
+
--
Total number of loads that did use an override directory


type: integer

--
=======
[float]
=== pipes



>>>>>>> upstream/master

*`haproxy.info.pipes.used`*::
+
--
<<<<<<< HEAD
Total number of loads that did not use an override directory
=======

>>>>>>> upstream/master

type: integer

type: integer

--

*`haproxy.info.pipes.free`*::
+
--


type: integer

--

*`haproxy.info.pipes.max`*::
+
--
<<<<<<< HEAD
Total listeners added (either via static config or LDS)


type: integer

--
=======


type: integer
>>>>>>> upstream/master

--
<<<<<<< HEAD
Total failed listener object additions to workers
=======

[float]
=== session
>>>>>>> upstream/master

None

<<<<<<< HEAD
type: integer

--
=======
>>>>>>> upstream/master

*`haproxy.info.session.rate.value`*::
+
--
<<<<<<< HEAD
Total listener objects successfully added to workers
=======

>>>>>>> upstream/master

type: integer

type: integer

--

*`haproxy.info.session.rate.limit`*::
+
--
<<<<<<< HEAD
Total listeners modified (via LDS)
=======

>>>>>>> upstream/master

type: integer

type: integer

--

*`haproxy.info.session.rate.max`*::
+
--
<<<<<<< HEAD
Total listeners removed (via LDS)


type: integer

--
=======


type: integer
>>>>>>> upstream/master

--
<<<<<<< HEAD
Number of currently active listeners
=======

[float]
=== ssl
>>>>>>> upstream/master

None

<<<<<<< HEAD
type: integer

--
=======
>>>>>>> upstream/master

*`haproxy.info.ssl.rate.value`*::
+
--
<<<<<<< HEAD
Number of currently draining listeners
=======
None
>>>>>>> upstream/master

type: integer

type: integer

--

*`haproxy.info.ssl.rate.limit`*::
+
--
<<<<<<< HEAD
Number of currently warming listeners
=======
None
>>>>>>> upstream/master

type: integer

type: integer

--

*`haproxy.info.ssl.rate.max`*::
+
--
<<<<<<< HEAD
Total number of times Envoy cannot allocate a statistic due to a shortage of shared memory
=======
None

type: integer

--
>>>>>>> upstream/master

[float]
=== frontend

<<<<<<< HEAD
type: integer

--
=======
None
>>>>>>> upstream/master


*`haproxy.info.ssl.frontend.key_rate.value`*::
+
--
<<<<<<< HEAD
Number of days until the next certificate being managed will expire
=======
None
>>>>>>> upstream/master

type: integer

type: integer

--

*`haproxy.info.ssl.frontend.key_rate.max`*::
+
--
<<<<<<< HEAD
1 if the server is not currently draining, 0 otherwise
=======
None
>>>>>>> upstream/master

type: integer

type: integer

--

*`haproxy.info.ssl.frontend.session_reuse.pct`*::
+
--
<<<<<<< HEAD
Current amount of allocated memory in bytes
=======
None

type: scaled_float
>>>>>>> upstream/master

format: percent

type: integer

--

[float]
=== backend

None


*`haproxy.info.ssl.backend.key_rate.value`*::
+
--
<<<<<<< HEAD
Current reserved heap size in bytes
=======
None
>>>>>>> upstream/master

type: integer

type: integer

--

*`haproxy.info.ssl.backend.key_rate.max`*::
+
--
<<<<<<< HEAD
Total connections of the old Envoy process on hot restart
=======
MaxConnRate
>>>>>>> upstream/master

type: integer

type: integer

--

*`haproxy.info.ssl.cached_lookups`*::
+
--
<<<<<<< HEAD
Total connections of both new and old Envoy processes
=======
None
>>>>>>> upstream/master

type: long

type: integer

--

*`haproxy.info.ssl.cache_misses`*::
+
--
<<<<<<< HEAD
Current server uptime in seconds
=======
None
>>>>>>> upstream/master

type: long

type: integer

--

<<<<<<< HEAD
*`envoyproxy.server.server.version`*::
+
--
Integer represented version number based on SCM revision


type: integer

--
=======
[float]
=== zlib_mem_usage



>>>>>>> upstream/master

*`haproxy.info.zlib_mem_usage.value`*::
+
--


type: integer

--

*`haproxy.info.zlib_mem_usage.max`*::
+
--


type: integer

--

*`haproxy.info.idle.pct`*::
+
--
<<<<<<< HEAD
Current hot restart epoch
=======

>>>>>>> upstream/master

type: scaled_float

format: percent

type: integer

--

[float]
=== stat

Stats collected from HAProxy processes.



*`haproxy.stat.status`*::
+
--
<<<<<<< HEAD
Total number of connections reset due to the headers being larger than Envoy::Http::Http2::ConnectionImpl::StreamImpl::MAX_HEADER_SIZE (63k)
=======
Status (UP, DOWN, NOLB, MAINT, or MAINT(via)...).

>>>>>>> upstream/master

type: keyword

type: integer

--

*`haproxy.stat.weight`*::
+
--
<<<<<<< HEAD
Total number of errors where a header callback is called without an associated stream. This tracks an unexpected occurrence due to an as yet undiagnosed bug
=======
Total weight (for backends), or server weight (for servers).

>>>>>>> upstream/master

type: long

type: integer

--

*`haproxy.stat.downtime`*::
+
--
<<<<<<< HEAD
Total number of invalid received frames that violated section 8 of the HTTP/2 spec. This will result in a tx_reset
=======
Total downtime (in seconds). For backends, this value is the downtime for the whole backend, not the sum of the downtime for the servers.

>>>>>>> upstream/master

type: long

type: integer

--

*`haproxy.stat.component_type`*::
+
--
<<<<<<< HEAD
Total number of reset stream frames received by Envoy
=======
Component type (0=frontend, 1=backend, 2=server, or 3=socket/listener).

>>>>>>> upstream/master

type: integer

type: integer

--

*`haproxy.stat.process_id`*::
+
--
<<<<<<< HEAD
Total number of times an HTTP2 connection is reset due to receiving too many headers frames. Envoy currently supports proxying at most one header frame for 100-Continue one non-100 response code header frame and one frame with trailers
=======
Process ID (0 for first instance, 1 for second, and so on).

>>>>>>> upstream/master

type: alias

alias to: process.pid

type: integer

--

*`haproxy.stat.service_name`*::
+
--
<<<<<<< HEAD
Total number of trailers seen on requests coming from downstream
=======
Service name (FRONTEND for frontend, BACKEND for backend, or any name for server/listener).

>>>>>>> upstream/master

type: keyword

type: integer

--

*`haproxy.stat.in.bytes`*::
+
--
<<<<<<< HEAD
Total number of reset stream frames transmitted by Envoy


type: integer

--
=======
Bytes in.

>>>>>>> upstream/master

type: long

format: bytes

--

*`haproxy.stat.out.bytes`*::
+
--
Bytes out.

<<<<<<< HEAD
[float]
=== etcd
=======
>>>>>>> upstream/master

type: long

format: bytes

--

*`haproxy.stat.last_change`*::
+
--
<<<<<<< HEAD
Etcd API version for metrics retrieval
=======
Number of seconds since the last UP->DOWN or DOWN->UP transition.

>>>>>>> upstream/master

type: integer

type: keyword

--

<<<<<<< HEAD
[float]
=== leader

Contains etcd leader statistics.



[float]
=== followers.counts
=======
*`haproxy.stat.throttle.pct`*::
+
--
Current throttle percentage for the server when slowstart is active, or no value if slowstart is inactive.

>>>>>>> upstream/master

type: scaled_float

format: percent

--

*`haproxy.stat.selected.total`*::
+
--
<<<<<<< HEAD
successful Raft RPC requests

type: integer

--
=======
Total number of times a server was selected, either for new sessions, or when re-dispatching. For servers, this field reports the the number of times the server was selected.


type: long
>>>>>>> upstream/master

--
<<<<<<< HEAD
failed Raft RPC requests

type: integer

=======

*`haproxy.stat.tracked.id`*::
+
>>>>>>> upstream/master
--
ID of the proxy/server if tracking is enabled.

<<<<<<< HEAD
[float]
=== followers.latency
=======
>>>>>>> upstream/master

type: long

--


*`haproxy.stat.connection.total`*::
+
--
Cumulative number of connections.


type: long

--

*`haproxy.stat.connection.retried`*::
+
--
Number of times a connection to a server was retried.


type: long

--

*`haproxy.stat.connection.time.avg`*::
+
--
Average connect time in ms over the last 1024 requests.


type: long

--
<<<<<<< HEAD
ID of actual leader

type: keyword

=======


*`haproxy.stat.request.denied`*::
+
>>>>>>> upstream/master
--
Requests denied because of security concerns.

<<<<<<< HEAD
[float]
=== server
=======
  * For TCP this is because of a matched tcp-request content rule.
  * For HTTP this is because of a matched http-request or tarpit rule.
>>>>>>> upstream/master


type: long

--

*`haproxy.stat.request.queued.current`*::
+
--
<<<<<<< HEAD
Whether a leader exists in the cluster
=======
Current queued requests. For backends, this field reports the number of requests queued without a server assigned.

>>>>>>> upstream/master

type: long

type: byte

--

*`haproxy.stat.request.queued.max`*::
+
--
<<<<<<< HEAD
Number of leader changes seen at the cluster
=======
Maximum value of queued.current.

>>>>>>> upstream/master

type: long

type: long

--

*`haproxy.stat.request.errors`*::
+
--
<<<<<<< HEAD
Number of consensus proposals commited
=======
Request errors. Some of the possible causes are:

  * early termination from the client, before the request has been sent
  * read error from the client
  * client timeout
  * client closed connection
  * various bad requests from the client.
  * request was tarpitted.

>>>>>>> upstream/master

type: long

type: long

--

*`haproxy.stat.request.redispatched`*::
+
--
<<<<<<< HEAD
Number of consensus proposals pending
=======
Number of times a request was redispatched to another server. For servers, this field reports the number of times the server was switched away from.

>>>>>>> upstream/master

type: long

type: long

--

*`haproxy.stat.request.connection.errors`*::
+
--
<<<<<<< HEAD
Number of consensus proposals failed
=======
Number of requests that encountered an error trying to connect to a server. For backends, this field reports the sum of the stat for all backend servers, plus any connection errors not associated with a particular server (such as the backend having no active servers).

>>>>>>> upstream/master

type: long

type: long

--

[float]
=== rate




*`haproxy.stat.request.rate.value`*::
+
--
<<<<<<< HEAD
Number of sent gRPC requests
=======
Number of HTTP requests per second over the last elapsed second.

>>>>>>> upstream/master

type: long

type: long

--

*`haproxy.stat.request.rate.max`*::
+
--
<<<<<<< HEAD
Number of received gRPC requests
=======
Maximum number of HTTP requests per second.

>>>>>>> upstream/master

type: long

type: long

--

<<<<<<< HEAD
[float]
=== disk
=======
*`haproxy.stat.request.total`*::
+
--
Total number of HTTP requests received.
>>>>>>> upstream/master


type: long

--


*`haproxy.stat.response.errors`*::
+
--
<<<<<<< HEAD
Size of stored data at MVCC


type: long

format: bytes
=======
Number of response errors. This value includes the number of data transfers aborted by the server (haproxy.stat.server.aborted). Some other errors are:
* write errors on the client socket (won't be counted for the server stat) * failure applying filters to the response


type: long
>>>>>>> upstream/master

--

*`haproxy.stat.response.time.avg`*::
+
--
<<<<<<< HEAD
Latency for writing ahead logs to disk
=======
Average response time in ms over the last 1024 requests (0 for TCP).

>>>>>>> upstream/master

type: long

type: object

--

*`haproxy.stat.response.denied`*::
+
--
<<<<<<< HEAD
Write ahead logs count
=======
Responses denied because of security concerns. For HTTP this is because of a matched http-request rule, or "option checkcache".

>>>>>>> upstream/master

type: integer

type: long

--

<<<<<<< HEAD
*`etcd.disk.wal_fsync_duration.ns.sum`*::
+
--
Write ahead logs latency sum


type: long

--
=======
[float]
=== http



>>>>>>> upstream/master

*`haproxy.stat.response.http.1xx`*::
+
--
<<<<<<< HEAD
Latency for writing backend changes to disk
=======
HTTP responses with 1xx code.

>>>>>>> upstream/master

type: long

type: object

--

*`haproxy.stat.response.http.2xx`*::
+
--
<<<<<<< HEAD
Backend commits count
=======
HTTP responses with 2xx code.

>>>>>>> upstream/master

type: long

type: long

--

*`haproxy.stat.response.http.3xx`*::
+
--
<<<<<<< HEAD
Backend commits latency sum
=======
HTTP responses with 3xx code.

>>>>>>> upstream/master

type: long

type: long

--

<<<<<<< HEAD
[float]
=== memory
=======
*`haproxy.stat.response.http.4xx`*::
+
--
HTTP responses with 4xx code.
>>>>>>> upstream/master


type: long

--

*`haproxy.stat.response.http.5xx`*::
+
--
<<<<<<< HEAD
Memory allocated bytes as of MemStats Go
=======
HTTP responses with 5xx code.
>>>>>>> upstream/master


type: long

<<<<<<< HEAD
format: bytes
=======
--
>>>>>>> upstream/master

*`haproxy.stat.response.http.other`*::
+
--
HTTP responses with other codes (protocol error).

<<<<<<< HEAD
[float]
=== network
=======
>>>>>>> upstream/master

type: long

--


*`haproxy.stat.session.current`*::
+
--
<<<<<<< HEAD
gRPC sent bytes total


type: long

format: bytes
=======
Number of current sessions.


type: long
>>>>>>> upstream/master

--

*`haproxy.stat.session.max`*::
+
--
<<<<<<< HEAD
gRPC received bytes total
=======
Maximum number of sessions.
>>>>>>> upstream/master


type: long

<<<<<<< HEAD
format: bytes
=======
--
>>>>>>> upstream/master

*`haproxy.stat.session.limit`*::
+
--
Configured session limit.

<<<<<<< HEAD
[float]
=== self
=======
>>>>>>> upstream/master

type: long

--


*`haproxy.stat.session.rate.value`*::
+
--
<<<<<<< HEAD
the unique identifier for the member
=======
Number of sessions per second over the last elapsed second.

>>>>>>> upstream/master

type: integer

type: keyword

--

*`haproxy.stat.session.rate.limit`*::
+
--
<<<<<<< HEAD
id of the current leader member
=======
Configured limit on new sessions per second.

>>>>>>> upstream/master

type: integer

type: keyword

--

*`haproxy.stat.session.rate.max`*::
+
--
<<<<<<< HEAD
the time when this node was started
=======
Maximum number of new sessions per second.

>>>>>>> upstream/master

type: integer

type: keyword

--

<<<<<<< HEAD
*`etcd.self.leaderinfo.uptime`*::
+
--
amount of time the leader has been leader


type: keyword

--
=======
[float]
=== check



>>>>>>> upstream/master

*`haproxy.stat.check.status`*::
+
--
<<<<<<< HEAD
this member's name
=======
Status of the last health check. One of:

  UNK     -> unknown
  INI     -> initializing
  SOCKERR -> socket error
  L4OK    -> check passed on layer 4, no upper layers testing enabled
  L4TOUT  -> layer 1-4 timeout
  L4CON   -> layer 1-4 connection problem, for example
            "Connection refused" (tcp rst) or "No route to host" (icmp)
  L6OK    -> check passed on layer 6
  L6TOUT  -> layer 6 (SSL) timeout
  L6RSP   -> layer 6 invalid response - protocol error
  L7OK    -> check passed on layer 7
  L7OKC   -> check conditionally passed on layer 7, for example 404 with
            disable-on-404
  L7TOUT  -> layer 7 (HTTP/SMTP) timeout
  L7RSP   -> layer 7 invalid response - protocol error
  L7STS   -> layer 7 response error, for example HTTP 5xx

>>>>>>> upstream/master

type: keyword

type: keyword

--

*`haproxy.stat.check.code`*::
+
--
<<<<<<< HEAD
number of append requests this node has processed
=======
Layer 5-7 code, if available.

>>>>>>> upstream/master

type: long

type: integer

--

*`haproxy.stat.check.duration`*::
+
--
<<<<<<< HEAD
number of bytes per second this node is receiving (follower only)
=======
Time in ms that it took to finish the last health check.

>>>>>>> upstream/master

type: long

type: scaled_float

--

*`haproxy.stat.check.health.last`*::
+
--
<<<<<<< HEAD
number of requests per second this node is receiving (follower only)
=======
The result of the last health check.

>>>>>>> upstream/master

type: keyword

type: scaled_float

--

*`haproxy.stat.check.health.fail`*::
+
--
<<<<<<< HEAD
number of requests that this node has sent
=======
Number of failed checks.

>>>>>>> upstream/master

type: long

type: integer

--

*`haproxy.stat.check.agent.last`*::
+
--
<<<<<<< HEAD
number of bytes per second this node is sending (leader only). This value is undefined on single member clusters.
=======

>>>>>>> upstream/master

type: integer

type: scaled_float

--

*`haproxy.stat.check.failed`*::
+
--
<<<<<<< HEAD
number of requests per second this node is sending (leader only). This value is undefined on single member clusters.
=======
Number of checks that failed while the server was up.

>>>>>>> upstream/master

type: long

type: scaled_float

--

*`haproxy.stat.check.down`*::
+
--
<<<<<<< HEAD
the time when this node was started
=======
Number of UP->DOWN transitions. For backends, this value is the number of transitions to the whole backend being down, rather than the sum of the transitions for each server.

>>>>>>> upstream/master

type: long

type: keyword

--

*`haproxy.stat.client.aborted`*::
+
--
<<<<<<< HEAD
either leader or follower
=======
Number of data transfers aborted by the client.

>>>>>>> upstream/master

type: integer

type: keyword

--

[float]
<<<<<<< HEAD
=== store
=======
=== server
>>>>>>> upstream/master




*`haproxy.stat.server.id`*::
+
--
Server ID (unique inside a proxy).


type: integer

--

*`haproxy.stat.server.aborted`*::
+
--
Number of data transfers aborted by the server. This value is included in haproxy.stat.response.errors.


type: integer

--

*`haproxy.stat.server.active`*::
+
--
Number of backend servers that are active, meaning that they are healthy and can receive requests from the load balancer.


type: integer

--

*`haproxy.stat.server.backup`*::
+
--
Number of backend servers that are backup servers.


type: integer

--

[float]
=== compressor




*`haproxy.stat.compressor.in.bytes`*::
+
--
Number of HTTP response bytes fed to the compressor.


type: long

format: bytes

--

*`haproxy.stat.compressor.out.bytes`*::
+
--
Number of HTTP response bytes emitted by the compressor.


type: integer

format: bytes

--

*`haproxy.stat.compressor.bypassed.bytes`*::
+
--
Number of bytes that bypassed the HTTP compressor (CPU/BW limit).


type: long

format: bytes

--

*`haproxy.stat.compressor.response.bytes`*::
+
--
Number of HTTP responses that were compressed.


type: long

format: bytes

--

[float]
<<<<<<< HEAD
=== golang
=======
=== proxy
>>>>>>> upstream/master




<<<<<<< HEAD
[float]
=== expvar
=======
*`haproxy.stat.proxy.id`*::
+
--
Unique proxy ID.
>>>>>>> upstream/master


type: integer

--

*`haproxy.stat.proxy.name`*::
+
--
<<<<<<< HEAD
The cmdline of this Go program start with.
=======
Proxy name.

>>>>>>> upstream/master

type: keyword

type: keyword

--

[float]
<<<<<<< HEAD
=== heap
=======
=== queue
>>>>>>> upstream/master




*`haproxy.stat.queue.limit`*::
+
--
<<<<<<< HEAD
The cmdline of this Go program start with.
=======
Configured queue limit (maxqueue) for the server, or nothing if the value of maxqueue is 0 (meaning no limit).

>>>>>>> upstream/master

type: integer

type: keyword

--

<<<<<<< HEAD
[float]
=== gc
=======
*`haproxy.stat.queue.time.avg`*::
+
--
The average queue time in ms over the last 1024 requests.
>>>>>>> upstream/master


type: integer

--

<<<<<<< HEAD
[float]
=== total_pause
=======
[[exported-fields-host-processor]]
== Host fields
>>>>>>> upstream/master

Info collected for the host machine.




*`host.containerized`*::
+
--
<<<<<<< HEAD
Duration in Ns.
=======
If the host is a container.

>>>>>>> upstream/master

type: boolean

type: long

--

*`host.os.build`*::
+
--
<<<<<<< HEAD
Total number of GC was happened.
=======
OS build information.

>>>>>>> upstream/master

type: keyword

example: 18D109

type: long

--

*`host.os.codename`*::
+
--
<<<<<<< HEAD
Next collection will happen when HeapAlloc > this amount.


type: long

format: bytes

--

*`golang.heap.gc.cpu_fraction`*::
+
--
Fraction of CPU time used by GC.


type: float

--

[float]
=== pause
=======
OS codename, if any.


type: keyword

example: stretch

--

[[exported-fields-http]]
== HTTP fields

HTTP module



[float]
=== http
>>>>>>> upstream/master




[float]
=== request

HTTP request information



*`http.request.headers`*::
+
--
<<<<<<< HEAD
Count of GC pause duration during this collect period.
=======
The HTTP headers sent

>>>>>>> upstream/master

type: object

type: long

--

[float]
<<<<<<< HEAD
=== sum
=======
=== response
>>>>>>> upstream/master

HTTP response information



*`http.response.headers`*::
+
--
<<<<<<< HEAD
Duration in Ns.
=======
The HTTP headers received

>>>>>>> upstream/master

type: object

type: long

--

<<<<<<< HEAD
[float]
=== max
=======
*`http.response.code`*::
+
--
The HTTP status code
>>>>>>> upstream/master


type: keyword

example: 404

--

*`http.response.phrase`*::
+
--
<<<<<<< HEAD
Duration in Ns.
=======
The HTTP status phrase

>>>>>>> upstream/master

type: keyword

example: Not found

type: long

--

[float]
<<<<<<< HEAD
=== avg
=======
=== json
>>>>>>> upstream/master

json metricset


[float]
=== server

<<<<<<< HEAD
*`golang.heap.gc.pause.avg.ns`*::
+
--
Duration in Ns.
=======
server

>>>>>>> upstream/master

[[exported-fields-jolokia]]
== Jolokia fields

<<<<<<< HEAD
type: long

--

[float]
=== system
=======
Jolokia module

>>>>>>> upstream/master


[float]
=== jolokia

jolokia contains metrics exposed via jolokia agent

<<<<<<< HEAD
*`golang.heap.system.total`*::
+
--
Total bytes obtained from system (sum of XxxSys below).


type: long

format: bytes
=======


[[exported-fields-jolokia-autodiscover]]
== Jolokia Discovery autodiscover provider fields

Metadata from Jolokia Discovery added by the jolokia provider.
>>>>>>> upstream/master



*`jolokia.agent.version`*::
+
--
<<<<<<< HEAD
Via HeapSys, bytes obtained from system. heap_sys = heap_idle + heap_inuse.


type: long

format: bytes
=======
Version number of jolokia agent.


type: keyword
>>>>>>> upstream/master

--

*`jolokia.agent.id`*::
+
--
<<<<<<< HEAD
Bytes used by stack allocator, and these bytes was obtained from system.


type: long

format: bytes
=======
Each agent has a unique id which can be either provided during startup of the agent in form of a configuration parameter or being autodetected. If autodected, the id has several parts: The IP, the process id, hashcode of the agent and its type.


type: keyword
>>>>>>> upstream/master

--

*`jolokia.server.product`*::
+
--
<<<<<<< HEAD
Bytes released to the OS.


type: long

format: bytes

--

[float]
=== allocations
=======
The container product if detected.


type: keyword

--

*`jolokia.server.version`*::
+
--
The container's version (if detected).
>>>>>>> upstream/master


type: keyword

--

*`jolokia.server.vendor`*::
+
--
<<<<<<< HEAD
Number of mallocs.
=======
The vendor of the container the agent is running in.

>>>>>>> upstream/master

type: keyword

type: long

--

*`jolokia.url`*::
+
--
<<<<<<< HEAD
Number of frees.
=======
The URL how this agent can be contacted.

>>>>>>> upstream/master

type: keyword

type: long

--

*`jolokia.secured`*::
+
--
<<<<<<< HEAD
Total number of allocated objects.
=======
Whether the agent was configured for authentication or not.

>>>>>>> upstream/master

type: boolean

type: long

--

<<<<<<< HEAD
*`golang.heap.allocations.total`*::
+
--
Bytes allocated (even if freed) throughout the lifetime.


type: long
=======
[[exported-fields-kafka]]
== Kafka fields

Kafka module

>>>>>>> upstream/master

format: bytes

[float]
=== kafka

<<<<<<< HEAD
*`golang.heap.allocations.allocated`*::
+
--
Bytes allocated and not yet freed (same as Alloc above).


type: long

format: bytes
=======



[float]
=== broker
>>>>>>> upstream/master

Broker Consumer Group Information have been read from (Broker handling the consumer group).



*`kafka.broker.id`*::
+
--
<<<<<<< HEAD
Bytes in idle spans.


type: long

format: bytes
=======
Broker id


type: long
>>>>>>> upstream/master

--

*`kafka.broker.address`*::
+
--
<<<<<<< HEAD
Bytes in non-idle span.


type: long

format: bytes
=======
Broker advertised address


type: keyword
>>>>>>> upstream/master

--

*`kafka.topic.name`*::
+
--
Topic name


type: keyword

--

<<<<<<< HEAD
[float]
=== graphite
=======
*`kafka.topic.error.code`*::
+
--
Topic error code.
>>>>>>> upstream/master


type: long

--

<<<<<<< HEAD
[float]
=== server
=======
*`kafka.partition.id`*::
+
--
Partition id.
>>>>>>> upstream/master


type: long

--

*`kafka.partition.topic_id`*::
+
--
<<<<<<< HEAD
Example field
=======
Unique id of the partition in the topic.
>>>>>>> upstream/master

type: keyword

type: keyword

--

*`kafka.partition.topic_broker_id`*::
+
--
Unique id of the partition in the topic and the broker.

type: keyword

--

[float]
<<<<<<< HEAD
=== haproxy
=======
=== consumergroup
>>>>>>> upstream/master

consumergroup



[float]
<<<<<<< HEAD
=== info
=======
=== broker
>>>>>>> upstream/master

Broker Consumer Group Information have been read from (Broker handling the consumer group).



*`kafka.consumergroup.broker.id`*::
+
--
<<<<<<< HEAD
Number of processes.
=======
Broker id

>>>>>>> upstream/master

type: long

type: long

--

*`kafka.consumergroup.broker.address`*::
+
--
<<<<<<< HEAD
Process number.
=======
Broker address

>>>>>>> upstream/master

type: keyword

type: long

--

*`kafka.consumergroup.id`*::
+
--
<<<<<<< HEAD
Process ID.


type: alias

alias to: process.pid
=======
Consumer Group ID

type: keyword
>>>>>>> upstream/master

--

*`kafka.consumergroup.topic`*::
+
--

deprecated[6.5]

Topic name

<<<<<<< HEAD
type: long
=======
type: keyword
>>>>>>> upstream/master

--

*`kafka.consumergroup.partition`*::
+
--

deprecated[6.5]

Partition ID

type: long

--

*`kafka.consumergroup.offset`*::
+
--
<<<<<<< HEAD
Current uptime in seconds.
=======
consumer offset into partition being read
>>>>>>> upstream/master

type: long

type: long

--

*`kafka.consumergroup.meta`*::
+
--
<<<<<<< HEAD
Maximum amount of memory usage in bytes (the 'Memmax_MB' value converted to bytes).


type: long

format: bytes
=======
custom consumer meta data string

type: keyword
>>>>>>> upstream/master

--

*`kafka.consumergroup.error.code`*::
+
--
<<<<<<< HEAD
Maximum number of open files for the process.
=======
kafka consumer/partition error code.

>>>>>>> upstream/master

type: long

type: long

--

[float]
<<<<<<< HEAD
=== compress




[float]
=== bps
=======
=== client
>>>>>>> upstream/master

Assigned client reading events from partition



*`kafka.consumergroup.client.id`*::
+
--
<<<<<<< HEAD


type: long
=======
Client ID (kafka setting client.id)

type: keyword
>>>>>>> upstream/master

--

*`kafka.consumergroup.client.host`*::
+
--
<<<<<<< HEAD


type: long
=======
Client host

type: keyword
>>>>>>> upstream/master

--

*`kafka.consumergroup.client.member_id`*::
+
--
<<<<<<< HEAD


type: long
=======
internal consumer group member ID

type: keyword
>>>>>>> upstream/master

--

[float]
<<<<<<< HEAD
=== connection
=======
=== partition
>>>>>>> upstream/master

partition



[float]
<<<<<<< HEAD
=== rate
=======
=== offset
>>>>>>> upstream/master

Available offsets of the given partition.



*`kafka.partition.offset.newest`*::
+
--
<<<<<<< HEAD
=======
Newest offset of the partition.
>>>>>>> upstream/master


type: long

--

*`kafka.partition.offset.oldest`*::
+
--
<<<<<<< HEAD
=======
Oldest offset of the partition.
>>>>>>> upstream/master


type: long

--

<<<<<<< HEAD
*`haproxy.info.connection.rate.max`*::
+
--
=======
[float]
=== partition
>>>>>>> upstream/master

Partition data.

type: long


*`kafka.partition.partition.id`*::
+
--
<<<<<<< HEAD
Current connections.
=======

deprecated[6.5]

Partition id.

>>>>>>> upstream/master

type: long

type: long

--

*`kafka.partition.partition.leader`*::
+
--
<<<<<<< HEAD
Total connections.
=======
Leader id (broker).

>>>>>>> upstream/master

type: long

type: long

--

*`kafka.partition.partition.isr`*::
+
--
<<<<<<< HEAD
Current SSL connections.
=======
List of isr ids.

>>>>>>> upstream/master

type: keyword

type: long

--

*`kafka.partition.partition.replica`*::
+
--
<<<<<<< HEAD
Total SSL connections.
=======
Replica id (broker).

>>>>>>> upstream/master

type: long

type: long

--

*`kafka.partition.partition.insync_replica`*::
+
--
<<<<<<< HEAD
Maximum SSL connections.
=======
Indicates if replica is included in the in-sync replicate set (ISR).

>>>>>>> upstream/master

type: boolean

type: long

--

*`kafka.partition.partition.is_leader`*::
+
--
<<<<<<< HEAD
Maximum connections.
=======
Indicates if replica is the leader

>>>>>>> upstream/master

type: boolean

type: long

--

*`kafka.partition.partition.error.code`*::
+
--
<<<<<<< HEAD
=======
Error code from fetching partition.
>>>>>>> upstream/master


type: long

--

*`kafka.partition.topic.error.code`*::
+
--
<<<<<<< HEAD
=======

deprecated[6.5]

topic error code.
>>>>>>> upstream/master


type: long

--

*`kafka.partition.topic.name`*::
+
--
<<<<<<< HEAD


type: long
=======

deprecated[6.5]

Topic name


type: keyword
>>>>>>> upstream/master

--

*`kafka.partition.broker.id`*::
+
--
<<<<<<< HEAD


type: long

--

[float]
=== pipes
=======

deprecated[6.5]

Broker id
>>>>>>> upstream/master


type: long

--

*`kafka.partition.broker.address`*::
+
--

deprecated[6.5]

Broker address

type: integer

type: keyword

--

[[exported-fields-kibana]]
== Kibana fields

Kibana module

type: integer


<<<<<<< HEAD
*`haproxy.info.pipes.max`*::
+
--
=======
[float]
=== kibana
>>>>>>> upstream/master


type: integer


[float]
<<<<<<< HEAD
=== session
=======
=== stats
>>>>>>> upstream/master

Kibana stats and run-time metrics.



*`kibana.stats.uuid`*::
+
--
<<<<<<< HEAD


type: integer
=======
Kibana instance UUID


type: alias

alias to: service.id
>>>>>>> upstream/master

--

*`kibana.stats.name`*::
+
--
<<<<<<< HEAD


type: integer
=======
Kibana instance name


type: keyword
>>>>>>> upstream/master

--

*`kibana.stats.index`*::
+
--
<<<<<<< HEAD


type: integer

--

[float]
=== ssl

None


*`haproxy.info.ssl.rate.value`*::
+
--
None
=======
Name of Kibana's internal index


type: keyword

--

*`kibana.stats.host.name`*::
+
--
Kibana instance hostname


type: keyword
>>>>>>> upstream/master

type: integer

--

*`kibana.stats.transport_address`*::
+
--
<<<<<<< HEAD
None
=======
Kibana server's hostname and port


type: alias

alias to: service.address
>>>>>>> upstream/master

type: integer

--

*`kibana.stats.version`*::
+
--
<<<<<<< HEAD
None

type: integer

--

[float]
=== frontend
=======
Kibana version


type: alias
>>>>>>> upstream/master

alias to: service.version

--

*`kibana.stats.snapshot`*::
+
--
<<<<<<< HEAD
None
=======
Whether the Kibana build is a snapshot build


type: boolean
>>>>>>> upstream/master

type: integer

--

*`kibana.stats.status`*::
+
--
<<<<<<< HEAD
None
=======
Kibana instance's health status


type: keyword
>>>>>>> upstream/master

type: integer

--

*`kibana.stats.concurrent_connections`*::
+
--
<<<<<<< HEAD
None

type: scaled_float
=======
Number of client connections made to the server. Note that browsers can send multiple simultaneous connections to request multiple server assets at once, and they can re-use established connections.
>>>>>>> upstream/master


<<<<<<< HEAD
--

[float]
=== backend

None


*`haproxy.info.ssl.backend.key_rate.value`*::
+
--
None

type: integer

--
=======
type: long

--

[float]
=== process

Process metrics


>>>>>>> upstream/master

*`kibana.stats.process.event_loop_delay.ms`*::
+
--
<<<<<<< HEAD
MaxConnRate

type: integer

--
=======
Event loop delay in milliseconds


type: scaled_float
>>>>>>> upstream/master

--
<<<<<<< HEAD
None

type: long

--

*`haproxy.info.ssl.cache_misses`*::
+
--
None

type: long

=======

[float]
=== memory.heap

Process heap metrics



*`kibana.stats.process.memory.heap.total.bytes`*::
+
>>>>>>> upstream/master
--
Total heap allocated to process in bytes

<<<<<<< HEAD
[float]
=== zlib_mem_usage
=======
>>>>>>> upstream/master

type: long

format: bytes

--

*`kibana.stats.process.memory.heap.used.bytes`*::
+
--
<<<<<<< HEAD
=======
Heap used by process in bytes

>>>>>>> upstream/master

type: long

<<<<<<< HEAD
type: integer
=======
format: bytes
>>>>>>> upstream/master

--

*`kibana.stats.process.memory.heap.size_limit.bytes`*::
+
--
<<<<<<< HEAD


type: integer
=======
Max. old space size allocated to Node.js process, in bytes


type: long

format: bytes
>>>>>>> upstream/master

--

*`kibana.stats.process.memory.heap.uptime.ms`*::
+
--
<<<<<<< HEAD

=======
Uptime of process in milliseconds
>>>>>>> upstream/master

type: scaled_float

<<<<<<< HEAD
format: percent
=======
type: long
>>>>>>> upstream/master

--

[float]
<<<<<<< HEAD
=== stat
=======
=== request
>>>>>>> upstream/master

Request count metrics



*`kibana.stats.request.disconnects`*::
+
--
<<<<<<< HEAD
Status (UP, DOWN, NOLB, MAINT, or MAINT(via)...).
=======
Number of requests that were disconnected

>>>>>>> upstream/master

type: long

type: keyword

--

*`kibana.stats.request.total`*::
+
--
<<<<<<< HEAD
Total weight (for backends), or server weight (for servers).
=======
Total number of requests

>>>>>>> upstream/master

type: long

type: long

--

<<<<<<< HEAD
*`haproxy.stat.downtime`*::
+
--
Total downtime (in seconds). For backends, this value is the downtime for the whole backend, not the sum of the downtime for the servers.


type: long

--
=======
[float]
=== response_time

Response times metrics


>>>>>>> upstream/master

*`kibana.stats.response_time.avg.ms`*::
+
--
<<<<<<< HEAD
Component type (0=frontend, 1=backend, 2=server, or 3=socket/listener).
=======
Average response time in milliseconds

>>>>>>> upstream/master

type: long

type: integer

--

*`kibana.stats.response_time.max.ms`*::
+
--
<<<<<<< HEAD
Process ID (0 for first instance, 1 for second, and so on).


type: alias

alias to: process.pid

--

*`haproxy.stat.service_name`*::
+
--
Service name (FRONTEND for frontend, BACKEND for backend, or any name for server/listener).


type: keyword

--
=======
Maximum response time in milliseconds


type: long

--

[float]
=== status

Status fields


>>>>>>> upstream/master

*`kibana.status.name`*::
+
--
<<<<<<< HEAD
Bytes in.


type: long

format: bytes
=======
Kibana instance name.


type: keyword
>>>>>>> upstream/master

--

*`kibana.status.uuid`*::
+
--
<<<<<<< HEAD
Bytes out.


type: long

format: bytes
=======
Kibana instance uuid.


type: alias

alias to: service.id
>>>>>>> upstream/master

--

*`kibana.status.version.number`*::
+
--
<<<<<<< HEAD
Number of seconds since the last UP->DOWN or DOWN->UP transition.
=======
Kibana version number.

>>>>>>> upstream/master

type: alias

alias to: service.version

type: integer

--

*`kibana.status.status.overall.state`*::
+
--
<<<<<<< HEAD
Current throttle percentage for the server when slowstart is active, or no value if slowstart is inactive.


type: scaled_float

format: percentage

--

*`haproxy.stat.selected.total`*::
+
--
Total number of times a server was selected, either for new sessions, or when re-dispatching. For servers, this field reports the the number of times the server was selected.


type: long

--
=======
Kibana overall state.


type: keyword

--

[float]
=== metrics

Metrics fields


>>>>>>> upstream/master

*`kibana.status.metrics.concurrent_connections`*::
+
--
<<<<<<< HEAD
ID of the proxy/server if tracking is enabled.
=======
Current concurrent connections.

>>>>>>> upstream/master

type: long

type: long

--

[float]
=== requests

<<<<<<< HEAD
*`haproxy.stat.connection.total`*::
+
--
Cumulative number of connections.


type: long

--
=======
Request statistics.


>>>>>>> upstream/master

*`kibana.status.metrics.requests.disconnects`*::
+
--
<<<<<<< HEAD
Number of times a connection to a server was retried.
=======
Total number of disconnected connections.

>>>>>>> upstream/master

type: long

type: long

--

*`kibana.status.metrics.requests.total`*::
+
--
<<<<<<< HEAD
Average connect time in ms over the last 1024 requests.
=======
Total number of connections.

>>>>>>> upstream/master

type: long

type: long

--

[[exported-fields-kubernetes-processor]]
== Kubernetes fields

<<<<<<< HEAD
*`haproxy.stat.request.denied`*::
+
--
Requests denied because of security concerns.
=======
Kubernetes metadata added by the kubernetes processor
>>>>>>> upstream/master



<<<<<<< HEAD
type: long

--
=======
>>>>>>> upstream/master

*`kubernetes.pod.name`*::
+
--
<<<<<<< HEAD
Current queued requests. For backends, this field reports the number of requests queued without a server assigned.
=======
Kubernetes pod name

>>>>>>> upstream/master

type: keyword

type: long

--

*`kubernetes.pod.uid`*::
+
--
<<<<<<< HEAD
Maximum value of queued.current.
=======
Kubernetes Pod UID

>>>>>>> upstream/master

type: keyword

type: long

--

*`kubernetes.namespace`*::
+
--
<<<<<<< HEAD
Request errors. Some of the possible causes are:
=======
Kubernetes namespace
>>>>>>> upstream/master


type: keyword

type: long

--

*`kubernetes.node.name`*::
+
--
<<<<<<< HEAD
Number of times a request was redispatched to another server. For servers, this field reports the number of times the server was switched away from.
=======
Kubernetes node name

>>>>>>> upstream/master

type: keyword

type: long

--

*`kubernetes.labels.*`*::
+
--
<<<<<<< HEAD
Number of requests that encountered an error trying to connect to a server. For backends, this field reports the sum of the stat for all backend servers, plus any connection errors not associated with a particular server (such as the backend having no active servers).
=======
Kubernetes labels map

>>>>>>> upstream/master

type: object

type: long

--

<<<<<<< HEAD
[float]
=== rate
=======
*`kubernetes.annotations.*`*::
+
--
Kubernetes annotations map
>>>>>>> upstream/master


type: object

--

*`kubernetes.replicaset.name`*::
+
--
<<<<<<< HEAD
Number of HTTP requests per second over the last elapsed second.
=======
Kubernetes replicaset name

>>>>>>> upstream/master

type: keyword

type: long

--

*`kubernetes.deployment.name`*::
+
--
<<<<<<< HEAD
Maximum number of HTTP requests per second.
=======
Kubernetes deployment name

>>>>>>> upstream/master

type: keyword

type: long

--

*`kubernetes.statefulset.name`*::
+
--
<<<<<<< HEAD
Total number of HTTP requests received.
=======
Kubernetes statefulset name

>>>>>>> upstream/master

type: keyword

type: long

--

*`kubernetes.container.name`*::
+
--
<<<<<<< HEAD
Number of response errors. This value includes the number of data transfers aborted by the server (haproxy.stat.server.aborted). Some other errors are:
* write errors on the client socket (won't be counted for the server stat) * failure applying filters to the response
=======
Kubernetes container name

>>>>>>> upstream/master

type: keyword

type: long

--

*`kubernetes.container.image`*::
+
--
<<<<<<< HEAD
Average response time in ms over the last 1024 requests (0 for TCP).
=======
Kubernetes container image

>>>>>>> upstream/master

type: keyword

type: long

--

<<<<<<< HEAD
*`haproxy.stat.response.denied`*::
+
--
Responses denied because of security concerns. For HTTP this is because of a matched http-request rule, or "option checkcache".


type: integer

--

[float]
=== http
=======
[[exported-fields-kubernetes]]
== Kubernetes fields

Kubernetes metrics



[float]
=== kubernetes
>>>>>>> upstream/master

Information and statistics of pods managed by kubernetes.



<<<<<<< HEAD
*`haproxy.stat.response.http.1xx`*::
+
--
HTTP responses with 1xx code.


type: long

--
=======
[float]
=== apiserver

Kubernetes API server metrics


>>>>>>> upstream/master

*`kubernetes.apiserver.request.client`*::
+
--
<<<<<<< HEAD
HTTP responses with 2xx code.
=======
Client executing requests

>>>>>>> upstream/master

type: keyword

type: long

--

*`kubernetes.apiserver.request.resource`*::
+
--
<<<<<<< HEAD
HTTP responses with 3xx code.
=======
Requested resource

>>>>>>> upstream/master

type: keyword

type: long

--

*`kubernetes.apiserver.request.subresource`*::
+
--
<<<<<<< HEAD
HTTP responses with 4xx code.
=======
Requested subresource

>>>>>>> upstream/master

type: keyword

type: long

--

*`kubernetes.apiserver.request.scope`*::
+
--
<<<<<<< HEAD
HTTP responses with 5xx code.
=======
Request scope (cluster, namespace, resource)

>>>>>>> upstream/master

type: keyword

type: long

--

*`kubernetes.apiserver.request.verb`*::
+
--
<<<<<<< HEAD
HTTP responses with other codes (protocol error).
=======
HTTP verb

>>>>>>> upstream/master

type: keyword

type: long

--

*`kubernetes.apiserver.request.code`*::
+
--
<<<<<<< HEAD
Number of current sessions.
=======
HTTP code

>>>>>>> upstream/master

type: keyword

type: long

--

*`kubernetes.apiserver.request.content_type`*::
+
--
<<<<<<< HEAD
Maximum number of sessions.
=======
Request HTTP content type

>>>>>>> upstream/master

type: keyword

type: long

--

*`kubernetes.apiserver.request.dry_run`*::
+
--
<<<<<<< HEAD
Configured session limit.
=======
Wether the request uses dry run

>>>>>>> upstream/master

type: keyword

type: long

--

*`kubernetes.apiserver.request.kind`*::
+
--
<<<<<<< HEAD
Number of sessions per second over the last elapsed second.
=======
Kind of request

>>>>>>> upstream/master

type: keyword

type: integer

--

*`kubernetes.apiserver.request.component`*::
+
--
<<<<<<< HEAD
Configured limit on new sessions per second.
=======
Component handling the request

>>>>>>> upstream/master

type: keyword

type: integer

--

*`kubernetes.apiserver.request.group`*::
+
--
<<<<<<< HEAD
Maximum number of new sessions per second.
=======
API group for the resource

>>>>>>> upstream/master

type: keyword

type: integer

--

<<<<<<< HEAD
[float]
=== check




*`haproxy.stat.check.status`*::
+
--
Status of the last health check. One of:
=======
*`kubernetes.apiserver.request.version`*::
+
--
version for the group
>>>>>>> upstream/master


type: keyword

type: keyword

--

*`kubernetes.apiserver.request.handler`*::
+
--
<<<<<<< HEAD
Layer 5-7 code, if available.
=======
Request handler

>>>>>>> upstream/master

type: keyword

type: long

--

*`kubernetes.apiserver.request.method`*::
+
--
<<<<<<< HEAD
Time in ms that it took to finish the last health check.
=======
HTTP method

>>>>>>> upstream/master

type: keyword

type: long

--

*`kubernetes.apiserver.request.host`*::
+
--
<<<<<<< HEAD
The result of the last health check.
=======
Request host

>>>>>>> upstream/master

type: keyword

type: keyword

--


*`kubernetes.apiserver.process.cpu.sec`*::
+
--
<<<<<<< HEAD
Number of failed checks.
=======
CPU seconds
>>>>>>> upstream/master

type: double

type: long

--

*`kubernetes.apiserver.process.memory.resident.bytes`*::
+
--
<<<<<<< HEAD
=======
Bytes in resident memory
>>>>>>> upstream/master

type: long

<<<<<<< HEAD
type: integer
=======
format: bytes
>>>>>>> upstream/master

--

*`kubernetes.apiserver.process.memory.virtual.bytes`*::
+
--
<<<<<<< HEAD
Number of checks that failed while the server was up.
=======
Bytes in virtual memory

type: long
>>>>>>> upstream/master

format: bytes

type: long

--

*`kubernetes.apiserver.process.fds.open.count`*::
+
--
<<<<<<< HEAD
Number of UP->DOWN transitions. For backends, this value is the number of transitions to the whole backend being down, rather than the sum of the transitions for each server.
=======
Number of open file descriptors
>>>>>>> upstream/master

type: long

type: long

--

*`kubernetes.apiserver.process.started.sec`*::
+
--
<<<<<<< HEAD
Number of data transfers aborted by the client.
=======
Seconds since the process started
>>>>>>> upstream/master

type: double

type: integer

--

<<<<<<< HEAD
[float]
=== server


=======
>>>>>>> upstream/master

*`kubernetes.apiserver.http.request.duration.us.percentile.*`*::
+
--
<<<<<<< HEAD
Server ID (unique inside a proxy).
=======
Request duration microseconds percentiles
>>>>>>> upstream/master

type: object

type: integer

--

*`kubernetes.apiserver.http.request.duration.us.sum`*::
+
--
<<<<<<< HEAD
Number of data transfers aborted by the server. This value is included in haproxy.stat.response.errors.
=======
Request duration microseconds cumulative sum
>>>>>>> upstream/master

type: double

type: integer

--

*`kubernetes.apiserver.http.request.duration.us.count`*::
+
--
<<<<<<< HEAD
Number of backend servers that are active, meaning that they are healthy and can receive requests from the load balancer.
=======
Request count for duration
>>>>>>> upstream/master

type: long

type: integer

--

*`kubernetes.apiserver.http.request.size.bytes.percentile.*`*::
+
--
<<<<<<< HEAD
Number of backend servers that are backup servers.
=======
Request size percentiles
>>>>>>> upstream/master

type: object

type: integer

--

<<<<<<< HEAD
[float]
=== compressor




*`haproxy.stat.compressor.in.bytes`*::
+
--
Number of HTTP response bytes fed to the compressor.
=======
*`kubernetes.apiserver.http.request.size.bytes.sum`*::
+
--
Request size cumulative sum

type: long
>>>>>>> upstream/master


<<<<<<< HEAD
type: long

format: bytes

=======
>>>>>>> upstream/master
--

*`kubernetes.apiserver.http.request.size.bytes.count`*::
+
--
<<<<<<< HEAD
Number of HTTP response bytes emitted by the compressor.


type: integer

format: bytes
=======
Request count for size

type: long

--

*`kubernetes.apiserver.http.response.size.bytes.percentile.*`*::
+
--
Response size percentiles

type: object
>>>>>>> upstream/master

--

*`kubernetes.apiserver.http.response.size.bytes.sum`*::
+
--
<<<<<<< HEAD
Number of bytes that bypassed the HTTP compressor (CPU/BW limit).
=======
Response size cumulative sum

type: long
>>>>>>> upstream/master


<<<<<<< HEAD
type: long

format: bytes

=======
>>>>>>> upstream/master
--

*`kubernetes.apiserver.http.response.size.bytes.count`*::
+
--
<<<<<<< HEAD
Number of HTTP responses that were compressed.


type: long

format: bytes

--

[float]
=== proxy
=======
Response count

type: long

--

*`kubernetes.apiserver.http.request.count`*::
+
--
Request count for response

type: long

--

*`kubernetes.apiserver.client.request.count`*::
+
--
Number of requests as client
>>>>>>> upstream/master

type: long

--


*`kubernetes.apiserver.request.count`*::
+
--
<<<<<<< HEAD
Unique proxy ID.
=======
Number of requests
>>>>>>> upstream/master

type: long

type: integer

--

*`kubernetes.apiserver.request.latency.sum`*::
+
--
<<<<<<< HEAD
Proxy name.
=======
Requests latency, sum of latencies in microseconds
>>>>>>> upstream/master

type: long

type: keyword

--

<<<<<<< HEAD
[float]
=== queue

=======
*`kubernetes.apiserver.request.latency.count`*::
+
--
Request latency, number of requests
>>>>>>> upstream/master

type: long

--

*`kubernetes.apiserver.request.latency.bucket.*`*::
+
--
<<<<<<< HEAD
Configured queue limit (maxqueue) for the server, or nothing if the value of maxqueue is 0 (meaning no limit).
=======
Request latency histogram buckets
>>>>>>> upstream/master

type: object

type: integer

--

*`kubernetes.apiserver.request.duration.us.sum`*::
+
--
<<<<<<< HEAD
The average queue time in ms over the last 1024 requests.
=======
Request duration, sum in microseconds

type: long
>>>>>>> upstream/master

--

<<<<<<< HEAD
type: integer

=======
*`kubernetes.apiserver.request.duration.us.count`*::
+
>>>>>>> upstream/master
--
Request duration, number of operations

type: long

--

*`kubernetes.apiserver.request.duration.us.bucket.*`*::
+
--
Request duration, histogram buckets

type: object

--

*`kubernetes.apiserver.request.current.count`*::
+
--
<<<<<<< HEAD
If the host is a container.
=======
Inflight requests
>>>>>>> upstream/master

type: long

type: boolean

--

*`kubernetes.apiserver.request.longrunning.count`*::
+
--
<<<<<<< HEAD
OS build information.


type: keyword

example: 18D109

--

*`host.os.codename`*::
+
--
OS codename, if any.


type: keyword

example: stretch
=======
Number of requests active long running requests

type: long

--
>>>>>>> upstream/master

*`kubernetes.apiserver.etcd.object.count`*::
+
--
Number of kubernetes objects at etcd

type: long

--

*`kubernetes.apiserver.audit.event.count`*::
+
--
Number of audit events

type: long

<<<<<<< HEAD
[float]
=== http
=======
--
>>>>>>> upstream/master

*`kubernetes.apiserver.audit.rejected.count`*::
+
--
Number of audit rejected events

type: long

--

[float]
<<<<<<< HEAD
=== request
=======
=== container
>>>>>>> upstream/master

kubernetes container metrics



*`kubernetes.container.start_time`*::
+
--
<<<<<<< HEAD
The HTTP headers sent
=======
Start time

>>>>>>> upstream/master

type: date

type: object

--

[float]
<<<<<<< HEAD
=== response
=======
=== cpu
>>>>>>> upstream/master

CPU usage metrics





*`kubernetes.container.cpu.usage.core.ns`*::
+
--
<<<<<<< HEAD
The HTTP headers received
=======
Container CPU Core usage nanoseconds

>>>>>>> upstream/master

type: long

type: object

--

*`kubernetes.container.cpu.usage.nanocores`*::
+
--
<<<<<<< HEAD
The HTTP status code


type: keyword

example: 404
=======
CPU used nanocores


type: long
>>>>>>> upstream/master

--

*`kubernetes.container.cpu.usage.node.pct`*::
+
--
<<<<<<< HEAD
The HTTP status phrase


type: keyword

example: Not found

--

[float]
=== json
=======
CPU usage as a percentage of the total node allocatable CPU


type: scaled_float

format: percent

--

*`kubernetes.container.cpu.usage.limit.pct`*::
+
--
CPU usage as a percentage of the defined limit for the container (or total node allocatable CPU if unlimited)
>>>>>>> upstream/master


type: scaled_float

format: percent

--

[float]
<<<<<<< HEAD
=== server
=======
=== logs
>>>>>>> upstream/master

Logs info




*`kubernetes.container.logs.available.bytes`*::
+
--
Logs available capacity in bytes


<<<<<<< HEAD
[float]
=== jolokia
=======
type: long
>>>>>>> upstream/master

format: bytes

--


*`kubernetes.container.logs.capacity.bytes`*::
+
--
Logs total capacity in bytes


type: long

format: bytes

--


*`kubernetes.container.logs.used.bytes`*::
+
--
<<<<<<< HEAD
Version number of jolokia agent.
=======
Logs used capacity in bytes

>>>>>>> upstream/master

type: long

format: bytes

type: keyword

--


*`kubernetes.container.logs.inodes.count`*::
+
--
<<<<<<< HEAD
Each agent has a unique id which can be either provided during startup of the agent in form of a configuration parameter or being autodetected. If autodected, the id has several parts: The IP, the process id, hashcode of the agent and its type.
=======
Total available inodes

>>>>>>> upstream/master

type: long

type: keyword

--

*`kubernetes.container.logs.inodes.free`*::
+
--
<<<<<<< HEAD
The container product if detected.
=======
Total free inodes

>>>>>>> upstream/master

type: long

type: keyword

--

*`kubernetes.container.logs.inodes.used`*::
+
--
<<<<<<< HEAD
The container's version (if detected).
=======
Total used inodes

>>>>>>> upstream/master

type: long

type: keyword

--



*`kubernetes.container.memory.available.bytes`*::
+
--
<<<<<<< HEAD
The vendor of the container the agent is running in.
=======
Total available memory

>>>>>>> upstream/master

type: long

format: bytes

type: keyword

--


*`kubernetes.container.memory.usage.bytes`*::
+
--
<<<<<<< HEAD
The URL how this agent can be contacted.
=======
Total memory usage

>>>>>>> upstream/master

type: long

format: bytes

type: keyword

--

*`kubernetes.container.memory.usage.node.pct`*::
+
--
<<<<<<< HEAD
Whether the agent was configured for authentication or not.
=======
Memory usage as a percentage of the total node allocatable memory

>>>>>>> upstream/master

type: scaled_float

format: percent

type: boolean

--

*`kubernetes.container.memory.usage.limit.pct`*::
+
--
Memory usage as a percentage of the defined limit for the container (or total node allocatable memory if unlimited)


type: scaled_float

format: percent

<<<<<<< HEAD
[float]
=== kafka
=======
--
>>>>>>> upstream/master


*`kubernetes.container.memory.rss.bytes`*::
+
--
RSS memory usage


<<<<<<< HEAD
[float]
=== broker
=======
type: long
>>>>>>> upstream/master

format: bytes

--


*`kubernetes.container.memory.workingset.bytes`*::
+
--
<<<<<<< HEAD
Broker id
=======
Working set memory usage

>>>>>>> upstream/master

type: long

format: bytes

type: long

--

*`kubernetes.container.memory.pagefaults`*::
+
--
<<<<<<< HEAD
Broker advertised address
=======
Number of page faults

>>>>>>> upstream/master

type: long

type: keyword

--

*`kubernetes.container.memory.majorpagefaults`*::
+
--
<<<<<<< HEAD
Topic name
=======
Number of major page faults

>>>>>>> upstream/master

type: long

type: keyword

--



*`kubernetes.container.rootfs.capacity.bytes`*::
+
--
<<<<<<< HEAD
Topic error code.
=======
Root filesystem total capacity in bytes

>>>>>>> upstream/master

type: long

format: bytes

type: long

--


*`kubernetes.container.rootfs.available.bytes`*::
+
--
<<<<<<< HEAD
Partition id.
=======
Root filesystem total available in bytes

>>>>>>> upstream/master

type: long

format: bytes

type: long

--


*`kubernetes.container.rootfs.used.bytes`*::
+
--
<<<<<<< HEAD
Unique id of the partition in the topic.
=======
Root filesystem total used in bytes


type: long

format: bytes
>>>>>>> upstream/master

type: keyword

--


*`kubernetes.container.rootfs.inodes.used`*::
+
--
<<<<<<< HEAD
Unique id of the partition in the topic and the broker.
=======
Used inodes


type: long
>>>>>>> upstream/master

type: keyword

--

[float]
<<<<<<< HEAD
=== consumergroup
=======
=== controllermanager
>>>>>>> upstream/master

Controller manager metrics



<<<<<<< HEAD
[float]
=== broker
=======
*`kubernetes.controllermanager.handler`*::
+
--
Request handler
>>>>>>> upstream/master


type: keyword

--

*`kubernetes.controllermanager.code`*::
+
--
<<<<<<< HEAD
Broker id
=======
HTTP code

>>>>>>> upstream/master

type: keyword

type: long

--

*`kubernetes.controllermanager.method`*::
+
--
<<<<<<< HEAD
Broker address
=======
HTTP method

>>>>>>> upstream/master

type: keyword

type: keyword

--

*`kubernetes.controllermanager.host`*::
+
--
<<<<<<< HEAD
Consumer Group ID

type: keyword

=======
Request host


type: keyword

--

*`kubernetes.controllermanager.name`*::
+
>>>>>>> upstream/master
--
Name for the resource


type: keyword

--

*`kubernetes.controllermanager.zone`*::
+
--
Infrastructure zone


<<<<<<< HEAD
Topic name

=======
>>>>>>> upstream/master
type: keyword

--


*`kubernetes.controllermanager.process.cpu.sec`*::
+
--
CPU seconds

type: double

--

*`kubernetes.controllermanager.process.memory.resident.bytes`*::
+
--
Bytes in resident memory

<<<<<<< HEAD
Partition ID
=======
type: long

format: bytes
>>>>>>> upstream/master

type: long

--

*`kubernetes.controllermanager.process.memory.virtual.bytes`*::
+
--
<<<<<<< HEAD
consumer offset into partition being read
=======
Bytes in virtual memory

type: long

format: bytes
>>>>>>> upstream/master

type: long

--

*`kubernetes.controllermanager.process.fds.open.count`*::
+
--
<<<<<<< HEAD
custom consumer meta data string
=======
Number of open file descriptors

type: long
>>>>>>> upstream/master

type: keyword

--

*`kubernetes.controllermanager.process.started.sec`*::
+
--
<<<<<<< HEAD
kafka consumer/partition error code.
=======
Seconds since the process started
>>>>>>> upstream/master

type: double

type: long

--

<<<<<<< HEAD
[float]
=== client
=======
>>>>>>> upstream/master

*`kubernetes.controllermanager.http.request.duration.us.percentile.*`*::
+
--
Request duration microseconds percentiles

type: object

--

*`kubernetes.controllermanager.http.request.duration.us.sum`*::
+
--
<<<<<<< HEAD
Client ID (kafka setting client.id)
=======
Request duration microseconds cumulative sum

type: double
>>>>>>> upstream/master

type: keyword

--

*`kubernetes.controllermanager.http.request.duration.us.count`*::
+
--
<<<<<<< HEAD
Client host
=======
Request count for duration

type: long
>>>>>>> upstream/master

type: keyword

--

*`kubernetes.controllermanager.http.request.size.bytes.percentile.*`*::
+
--
<<<<<<< HEAD
internal consumer group member ID
=======
Request size percentiles

type: object
>>>>>>> upstream/master

type: keyword

--

<<<<<<< HEAD
[float]
=== partition

partition
=======
*`kubernetes.controllermanager.http.request.size.bytes.sum`*::
+
--
Request size cumulative sum
>>>>>>> upstream/master

type: long

format: bytes

<<<<<<< HEAD
[float]
=== offset
=======
--
>>>>>>> upstream/master

*`kubernetes.controllermanager.http.request.size.bytes.count`*::
+
--
Request count for size

type: long

--

*`kubernetes.controllermanager.http.response.size.bytes.percentile.*`*::
+
--
<<<<<<< HEAD
Newest offset of the partition.
=======
Response size percentiles
>>>>>>> upstream/master

type: object

type: long

--

*`kubernetes.controllermanager.http.response.size.bytes.sum`*::
+
--
<<<<<<< HEAD
Oldest offset of the partition.
=======
Response size cumulative sum

type: long
>>>>>>> upstream/master

format: bytes

type: long

--

<<<<<<< HEAD
[float]
=== partition

Partition data.
=======
*`kubernetes.controllermanager.http.response.size.bytes.count`*::
+
--
Response count
>>>>>>> upstream/master

type: long

--

*`kubernetes.controllermanager.http.request.count`*::
+
--
Request count for response

<<<<<<< HEAD
Partition id.


=======
>>>>>>> upstream/master
type: long

--

*`kubernetes.controllermanager.client.request.count`*::
+
--
<<<<<<< HEAD
Leader id (broker).
=======
Number of requests as client

>>>>>>> upstream/master

type: long

type: long

--


*`kubernetes.controllermanager.workqueue.longestrunning.sec`*::
+
--
<<<<<<< HEAD
List of isr ids.
=======
Longest running processors
>>>>>>> upstream/master

type: double

type: keyword

--

*`kubernetes.controllermanager.workqueue.unfinished.sec`*::
+
--
<<<<<<< HEAD
Replica id (broker).
=======
Unfinished processors
>>>>>>> upstream/master

type: double

type: long

--

*`kubernetes.controllermanager.workqueue.adds.count`*::
+
--
<<<<<<< HEAD
Indicates if replica is included in the in-sync replicate set (ISR).
=======
Workqueue add count
>>>>>>> upstream/master

type: long

type: boolean

--

*`kubernetes.controllermanager.workqueue.depth.count`*::
+
--
<<<<<<< HEAD
Indicates if replica is the leader
=======
Workqueue depth count
>>>>>>> upstream/master

type: long

type: boolean

--

*`kubernetes.controllermanager.workqueue.retries.count`*::
+
--
<<<<<<< HEAD
Error code from fetching partition.
=======
Workqueue number of retries
>>>>>>> upstream/master

type: long

type: long

--


*`kubernetes.controllermanager.node.collector.eviction.count`*::
+
--
Number of node evictions

<<<<<<< HEAD
topic error code.


=======
>>>>>>> upstream/master
type: long

--

*`kubernetes.controllermanager.node.collector.unhealthy.count`*::
+
--
Number of unhealthy nodes

type: long

<<<<<<< HEAD
Topic name
=======
--

*`kubernetes.controllermanager.node.collector.count`*::
+
--
Number of nodes
>>>>>>> upstream/master

type: long

type: keyword

--

*`kubernetes.controllermanager.node.collector.health.pct`*::
+
--
Percentage of healthy nodes

<<<<<<< HEAD
Broker id


=======
>>>>>>> upstream/master
type: long

--

*`kubernetes.controllermanager.leader.is_master`*::
+
--
Whether the node is master

<<<<<<< HEAD
deprecated[6.5]

Broker address
=======
>>>>>>> upstream/master

type: boolean

type: keyword

--

[float]
=== event

The Kubernetes events metricset collects events that are generated by objects running inside of Kubernetes



<<<<<<< HEAD
[float]
=== kibana
=======
*`kubernetes.event.count`*::
+
--
Count field records the number of times the particular event has occurred

>>>>>>> upstream/master

type: long

--


<<<<<<< HEAD
[float]
=== stats
=======
*`kubernetes.event.timestamp.first_occurrence`*::
+
--
Timestamp of first occurrence of event
>>>>>>> upstream/master


type: date

--

*`kubernetes.event.timestamp.last_occurrence`*::
+
--
<<<<<<< HEAD
Kibana instance UUID


type: alias

alias to: service.id
=======
Timestamp of last occurrence of event


type: date
>>>>>>> upstream/master

--

*`kubernetes.event.message`*::
+
--
<<<<<<< HEAD
Kibana instance name
=======
Message recorded for the given event

>>>>>>> upstream/master

type: keyword

type: keyword

--

*`kubernetes.event.reason`*::
+
--
<<<<<<< HEAD
Name of Kibana's internal index
=======
Reason recorded for the given event

>>>>>>> upstream/master

type: keyword

type: keyword

--

*`kubernetes.event.type`*::
+
--
<<<<<<< HEAD
Kibana instance hostname
=======
Type of the given event

>>>>>>> upstream/master

type: keyword

type: keyword

--

<<<<<<< HEAD
*`kibana.stats.transport_address`*::
+
--
Kibana server's hostname and port


type: alias
=======
[float]
=== metadata
>>>>>>> upstream/master

Metadata associated with the given event

<<<<<<< HEAD
--
=======


>>>>>>> upstream/master

*`kubernetes.event.metadata.timestamp.created`*::
+
--
<<<<<<< HEAD
Kibana version


type: alias

alias to: service.version
=======
Timestamp of creation of the given event


type: date
>>>>>>> upstream/master

--

*`kubernetes.event.metadata.name`*::
+
--
<<<<<<< HEAD
Whether the Kibana build is a snapshot build
=======
Name of the event

>>>>>>> upstream/master

type: keyword

type: boolean

--

*`kubernetes.event.metadata.namespace`*::
+
--
<<<<<<< HEAD
Kibana instance's health status
=======
Namespace in which event was generated

>>>>>>> upstream/master

type: keyword

type: keyword

--

*`kubernetes.event.metadata.resource_version`*::
+
--
<<<<<<< HEAD
Number of client connections made to the server. Note that browsers can send multiple simultaneous connections to request multiple server assets at once, and they can re-use established connections.
=======
Version of the event resource

>>>>>>> upstream/master

type: keyword

type: long

--

<<<<<<< HEAD
[float]
=== process
=======
*`kubernetes.event.metadata.uid`*::
+
--
Unique identifier to the event object
>>>>>>> upstream/master


type: keyword

--

*`kubernetes.event.metadata.self_link`*::
+
--
<<<<<<< HEAD
Event loop delay in milliseconds
=======
URL representing the event

>>>>>>> upstream/master

type: keyword

type: scaled_float

--

[float]
<<<<<<< HEAD
=== memory.heap
=======
=== involved_object
>>>>>>> upstream/master

Metadata associated with the given involved object



*`kubernetes.event.involved_object.api_version`*::
+
--
<<<<<<< HEAD
Total heap allocated to process in bytes


type: long

format: bytes
=======
API version of the object


type: keyword

--

*`kubernetes.event.involved_object.kind`*::
+
--
API kind of the object


type: keyword
>>>>>>> upstream/master

--

*`kubernetes.event.involved_object.name`*::
+
--
<<<<<<< HEAD
Heap used by process in bytes


type: long

format: bytes
=======
name of the object


type: keyword
>>>>>>> upstream/master

--

*`kubernetes.event.involved_object.resource_version`*::
+
--
<<<<<<< HEAD
Max. old space size allocated to Node.js process, in bytes


type: long

format: bytes
=======
resource version of the object


type: keyword
>>>>>>> upstream/master

--

*`kubernetes.event.involved_object.uid`*::
+
--
<<<<<<< HEAD
Uptime of process in milliseconds
=======
UUID version of the object

>>>>>>> upstream/master

type: keyword

type: long

--

[float]
<<<<<<< HEAD
=== request
=======
=== node
>>>>>>> upstream/master

kubernetes node metrics



*`kubernetes.node.start_time`*::
+
--
<<<<<<< HEAD
Number of requests that were disconnected


type: long

--
=======
Start time


type: date
>>>>>>> upstream/master

--
<<<<<<< HEAD
Total number of requests
=======
>>>>>>> upstream/master

[float]
=== cpu

<<<<<<< HEAD
type: long

--

[float]
=== response_time
=======
CPU usage metrics

>>>>>>> upstream/master




*`kubernetes.node.cpu.usage.core.ns`*::
+
--
<<<<<<< HEAD
Average response time in milliseconds
=======
Node CPU Core usage nanoseconds

>>>>>>> upstream/master

type: long

type: long

--

*`kubernetes.node.cpu.usage.nanocores`*::
+
--
<<<<<<< HEAD
Maximum response time in milliseconds


type: long

=======
CPU used nanocores


type: long

--



*`kubernetes.node.memory.available.bytes`*::
+
>>>>>>> upstream/master
--
Total available memory

<<<<<<< HEAD
[float]
=== status
=======
>>>>>>> upstream/master

type: long

format: bytes

--


*`kubernetes.node.memory.usage.bytes`*::
+
--
<<<<<<< HEAD
Kibana instance name.
=======
Total memory usage

>>>>>>> upstream/master

type: long

format: bytes

type: keyword

--


*`kubernetes.node.memory.rss.bytes`*::
+
--
<<<<<<< HEAD
Kibana instance uuid.


type: alias

alias to: service.id
=======
RSS memory usage


type: long

format: bytes
>>>>>>> upstream/master

--


*`kubernetes.node.memory.workingset.bytes`*::
+
--
<<<<<<< HEAD
Kibana version number.


type: alias

alias to: service.version
=======
Working set memory usage


type: long

format: bytes
>>>>>>> upstream/master

--

*`kubernetes.node.memory.pagefaults`*::
+
--
<<<<<<< HEAD
Kibana overall state.
=======
Number of page faults

>>>>>>> upstream/master

type: long

--

<<<<<<< HEAD
type: keyword

=======
*`kubernetes.node.memory.majorpagefaults`*::
+
>>>>>>> upstream/master
--
Number of major page faults

<<<<<<< HEAD
[float]
=== metrics
=======
>>>>>>> upstream/master

type: long

--



*`kubernetes.node.network.rx.bytes`*::
+
--
<<<<<<< HEAD
Current concurrent connections.
=======
Received bytes


type: long

format: bytes
>>>>>>> upstream/master

--

<<<<<<< HEAD
type: long

=======
*`kubernetes.node.network.rx.errors`*::
+
>>>>>>> upstream/master
--
Rx errors

<<<<<<< HEAD
[float]
=== requests
=======
>>>>>>> upstream/master

type: long

--


*`kubernetes.node.network.tx.bytes`*::
+
--
<<<<<<< HEAD
Total number of disconnected connections.
=======
Transmitted bytes

>>>>>>> upstream/master

type: long

format: bytes

type: long

--

*`kubernetes.node.network.tx.errors`*::
+
--
<<<<<<< HEAD
Total number of connections.


type: long

=======
Tx errors


type: long

--



*`kubernetes.node.fs.capacity.bytes`*::
+
>>>>>>> upstream/master
--
Filesystem total capacity in bytes


type: long

format: bytes

--


*`kubernetes.node.fs.available.bytes`*::
+
--
<<<<<<< HEAD
Kubernetes pod name
=======
Filesystem total available in bytes

>>>>>>> upstream/master

type: long

format: bytes

type: keyword

--


*`kubernetes.node.fs.used.bytes`*::
+
--
<<<<<<< HEAD
Kubernetes Pod UID
=======
Filesystem total used in bytes

>>>>>>> upstream/master

type: long

format: bytes

type: keyword

--


*`kubernetes.node.fs.inodes.used`*::
+
--
<<<<<<< HEAD
Kubernetes namespace
=======
Number of used inodes

>>>>>>> upstream/master

type: long

type: keyword

--

*`kubernetes.node.fs.inodes.count`*::
+
--
<<<<<<< HEAD
Kubernetes node name
=======
Number of inodes

>>>>>>> upstream/master

type: long

type: keyword

--

*`kubernetes.node.fs.inodes.free`*::
+
--
<<<<<<< HEAD
Kubernetes labels map
=======
Number of free inodes

>>>>>>> upstream/master

type: long

type: object

--




*`kubernetes.node.runtime.imagefs.capacity.bytes`*::
+
--
<<<<<<< HEAD
Kubernetes annotations map
=======
Image filesystem total capacity in bytes

>>>>>>> upstream/master

type: long

format: bytes

type: object

--


*`kubernetes.node.runtime.imagefs.available.bytes`*::
+
--
<<<<<<< HEAD
Kubernetes replicaset name
=======
Image filesystem total available in bytes

>>>>>>> upstream/master

type: long

format: bytes

type: keyword

--


*`kubernetes.node.runtime.imagefs.used.bytes`*::
+
--
<<<<<<< HEAD
Kubernetes deployment name
=======
Image filesystem total used in bytes

>>>>>>> upstream/master

type: long

format: bytes

type: keyword

--

[float]
=== pod

kubernetes pod metrics



*`kubernetes.pod.start_time`*::
+
--
<<<<<<< HEAD
Kubernetes statefulset name
=======
Start time

>>>>>>> upstream/master

type: date

type: keyword

--



*`kubernetes.pod.network.rx.bytes`*::
+
--
<<<<<<< HEAD
Kubernetes container name
=======
Received bytes

>>>>>>> upstream/master

type: long

format: bytes

type: keyword

--

*`kubernetes.pod.network.rx.errors`*::
+
--
<<<<<<< HEAD
Kubernetes container image
=======
Rx errors

>>>>>>> upstream/master

type: long

type: keyword

--


*`kubernetes.pod.network.tx.bytes`*::
+
--
Transmitted bytes


type: long

<<<<<<< HEAD
[float]
=== kubernetes
=======
format: bytes
>>>>>>> upstream/master

--

*`kubernetes.pod.network.tx.errors`*::
+
--
Tx errors


type: long

--

[float]
<<<<<<< HEAD
=== apiserver
=======
=== cpu
>>>>>>> upstream/master

CPU usage metrics




*`kubernetes.pod.cpu.usage.nanocores`*::
+
--
<<<<<<< HEAD
Client doing the requests
=======
CPU used nanocores

>>>>>>> upstream/master

type: long

type: keyword

--

*`kubernetes.pod.cpu.usage.node.pct`*::
+
--
<<<<<<< HEAD
Requested resource
=======
CPU usage as a percentage of the total node CPU

>>>>>>> upstream/master

type: scaled_float

format: percent

type: keyword

--

*`kubernetes.pod.cpu.usage.limit.pct`*::
+
--
<<<<<<< HEAD
Requested subresource
=======
CPU usage as a percentage of the defined limit for the pod containers (or total node CPU if unlimited)

>>>>>>> upstream/master

type: scaled_float

format: percent

type: keyword

--



*`kubernetes.pod.memory.usage.bytes`*::
+
--
<<<<<<< HEAD
Request scope (cluster, namespace, resource)
=======
Total memory usage

>>>>>>> upstream/master

type: long

format: bytes

type: keyword

--

*`kubernetes.pod.memory.usage.node.pct`*::
+
--
<<<<<<< HEAD
Request HTTP verb
=======
Memory usage as a percentage of the total node allocatable memory


type: scaled_float
>>>>>>> upstream/master

format: percent

type: keyword

--

*`kubernetes.pod.memory.usage.limit.pct`*::
+
--
<<<<<<< HEAD
Total number of requests
=======
Memory usage as a percentage of the defined limit for the pod containers (or total node allocatable memory if unlimited)

>>>>>>> upstream/master

type: scaled_float

format: percent

type: long

--


*`kubernetes.pod.memory.available.bytes`*::
+
--
<<<<<<< HEAD
Requests latency, sum of latencies in microseconds
=======
Total memory available

>>>>>>> upstream/master

type: long

format: bytes

type: long

--


*`kubernetes.pod.memory.working_set.bytes`*::
+
--
<<<<<<< HEAD
Request latency, number of requests
=======
Total working set memory

>>>>>>> upstream/master

type: long

format: bytes

type: long

--


*`kubernetes.pod.memory.rss.bytes`*::
+
--
<<<<<<< HEAD
Request latency histogram buckets
=======
Total resident set size memory

>>>>>>> upstream/master

type: long

format: bytes

type: object

--

<<<<<<< HEAD
[float]
=== container
=======
*`kubernetes.pod.memory.page_faults`*::
+
--
Total page faults
>>>>>>> upstream/master


type: long

--

*`kubernetes.pod.memory.major_page_faults`*::
+
--
<<<<<<< HEAD
Start time
=======
Total major page faults

>>>>>>> upstream/master

type: long

type: date

--

[float]
<<<<<<< HEAD
=== cpu

CPU usage metrics

=======
=== proxy
>>>>>>> upstream/master

Kubernetes proxy server metrics



*`kubernetes.proxy.handler`*::
+
--
<<<<<<< HEAD
Container CPU Core usage nanoseconds
=======
Request handler

>>>>>>> upstream/master

type: keyword

type: long

--

*`kubernetes.proxy.code`*::
+
--
<<<<<<< HEAD
CPU used nanocores
=======
HTTP code

>>>>>>> upstream/master

type: keyword

type: long

--

*`kubernetes.proxy.method`*::
+
--
<<<<<<< HEAD
CPU usage as a percentage of the total node allocatable CPU


type: scaled_float

format: percentage
=======
HTTP method


type: keyword
>>>>>>> upstream/master

--

*`kubernetes.proxy.host`*::
+
--
<<<<<<< HEAD
CPU usage as a percentage of the defined limit for the container (or total node allocatable CPU if unlimited)


type: scaled_float

format: percentage

--

[float]
=== logs

Logs info
=======
Request host


type: keyword

--

>>>>>>> upstream/master

*`kubernetes.proxy.process.cpu.sec`*::
+
--
CPU seconds

type: double

--

*`kubernetes.proxy.process.memory.resident.bytes`*::
+
--
<<<<<<< HEAD
Logs available capacity in bytes
=======
Bytes in resident memory

type: long
>>>>>>> upstream/master


<<<<<<< HEAD
type: long

format: bytes

=======
>>>>>>> upstream/master
--

*`kubernetes.proxy.process.memory.virtual.bytes`*::
+
--
<<<<<<< HEAD
Logs total capacity in bytes
=======
Bytes in virtual memory

type: long
>>>>>>> upstream/master


<<<<<<< HEAD
type: long

format: bytes

=======
>>>>>>> upstream/master
--

*`kubernetes.proxy.process.fds.open.count`*::
+
--
<<<<<<< HEAD
Logs used capacity in bytes


type: long

format: bytes
=======
Number of open file descriptors

type: long

--

*`kubernetes.proxy.process.started.sec`*::
+
--
Seconds since the process started

type: double
>>>>>>> upstream/master

--


*`kubernetes.proxy.http.request.duration.us.percentile.*`*::
+
--
<<<<<<< HEAD
Total available inodes
=======
Request duration microseconds percentiles
>>>>>>> upstream/master

type: object

type: long

--

*`kubernetes.proxy.http.request.duration.us.sum`*::
+
--
<<<<<<< HEAD
Total free inodes
=======
Request duration microseconds cumulative sum
>>>>>>> upstream/master

type: double

type: long

--

*`kubernetes.proxy.http.request.duration.us.count`*::
+
--
<<<<<<< HEAD
Total used inodes
=======
Request count for duration

type: long
>>>>>>> upstream/master

--

<<<<<<< HEAD
type: long

=======
*`kubernetes.proxy.http.request.size.bytes.percentile.*`*::
+
>>>>>>> upstream/master
--
Request size percentiles

type: object

--

*`kubernetes.proxy.http.request.size.bytes.sum`*::
+
--
<<<<<<< HEAD
Total available memory
=======
Request size cumulative sum

type: long
>>>>>>> upstream/master


<<<<<<< HEAD
type: long

format: bytes

=======
>>>>>>> upstream/master
--

*`kubernetes.proxy.http.request.size.bytes.count`*::
+
--
<<<<<<< HEAD
Total memory usage


type: long

format: bytes
=======
Request count for size

type: long

--

*`kubernetes.proxy.http.response.size.bytes.percentile.*`*::
+
--
Response size percentiles

type: object
>>>>>>> upstream/master

--

*`kubernetes.proxy.http.response.size.bytes.sum`*::
+
--
<<<<<<< HEAD
Memory usage as a percentage of the total node allocatable memory


type: scaled_float

format: percentage
=======
Response size cumulative sum

type: long

format: bytes
>>>>>>> upstream/master

--

*`kubernetes.proxy.http.response.size.bytes.count`*::
+
--
<<<<<<< HEAD
Memory usage as a percentage of the defined limit for the container (or total node allocatable memory if unlimited)


type: scaled_float

format: percentage
=======
Response count

type: long

--
>>>>>>> upstream/master

*`kubernetes.proxy.http.request.count`*::
+
--
Request count

type: long

--

*`kubernetes.proxy.client.request.count`*::
+
--
<<<<<<< HEAD
RSS memory usage
=======
Number of requests as client
>>>>>>> upstream/master


type: long

--

<<<<<<< HEAD
--
=======
[float]
=== sync

kubeproxy proxy sync metrics

>>>>>>> upstream/master


*`kubernetes.proxy.sync.rules.duration.us.sum`*::
+
--
<<<<<<< HEAD
Working set memory usage


type: long

format: bytes
=======
SyncProxyRules duration, sum of durations in microseconds

type: long

--

*`kubernetes.proxy.sync.rules.duration.us.count`*::
+
--
SyncProxyRules duration, number of operations

type: long
>>>>>>> upstream/master

--

*`kubernetes.proxy.sync.rules.duration.us.bucket.*`*::
+
--
<<<<<<< HEAD
Number of page faults
=======
SyncProxyRules duration, histogram buckets
>>>>>>> upstream/master

type: object

type: long

--

*`kubernetes.proxy.sync.networkprogramming.duration.us.sum`*::
+
--
<<<<<<< HEAD
Number of major page faults
=======
Network programming duration, sum in microseconds

type: long
>>>>>>> upstream/master

--

<<<<<<< HEAD
type: long

=======
*`kubernetes.proxy.sync.networkprogramming.duration.us.count`*::
+
>>>>>>> upstream/master
--
Network programming duration, number of operations

type: long

--

*`kubernetes.proxy.sync.networkprogramming.duration.us.bucket.*`*::
+
--
<<<<<<< HEAD
Root filesystem total capacity in bytes


type: long

format: bytes
=======
Network programming duration, histogram buckets

type: object

--

[float]
=== scheduler
>>>>>>> upstream/master

Kubernetes scheduler metrics



*`kubernetes.scheduler.handler`*::
+
--
<<<<<<< HEAD
Root filesystem total available in bytes


type: long

format: bytes
=======
Request handler


type: keyword
>>>>>>> upstream/master

--

*`kubernetes.scheduler.code`*::
+
--
<<<<<<< HEAD
Root filesystem total used in bytes


type: long

format: bytes
=======
HTTP code


type: keyword

--
>>>>>>> upstream/master

*`kubernetes.scheduler.method`*::
+
--
HTTP method


type: keyword

--

*`kubernetes.scheduler.host`*::
+
--
<<<<<<< HEAD
Used inodes
=======
Request host

>>>>>>> upstream/master

type: keyword

type: long

--

<<<<<<< HEAD
[float]
=== event
=======
*`kubernetes.scheduler.name`*::
+
--
Name for the resource
>>>>>>> upstream/master


type: keyword

--

*`kubernetes.scheduler.result`*::
+
--
<<<<<<< HEAD
Count field records the number of times the particular event has occurred
=======
Schedule attempt result

>>>>>>> upstream/master

type: keyword

type: long

--

*`kubernetes.scheduler.operation`*::
+
--
<<<<<<< HEAD
Timestamp of first occurrence of event
=======
Scheduling operation

>>>>>>> upstream/master

type: keyword

type: date

--


*`kubernetes.scheduler.process.cpu.sec`*::
+
--
<<<<<<< HEAD
Timestamp of last occurrence of event
=======
CPU seconds
>>>>>>> upstream/master

type: double

type: date

--

*`kubernetes.scheduler.process.memory.resident.bytes`*::
+
--
<<<<<<< HEAD
Message recorded for the given event
=======
Bytes in resident memory

type: long
>>>>>>> upstream/master

format: bytes

type: keyword

--

*`kubernetes.scheduler.process.memory.virtual.bytes`*::
+
--
<<<<<<< HEAD
Reason recorded for the given event
=======
Bytes in virtual memory

type: long
>>>>>>> upstream/master

format: bytes

type: keyword

--

*`kubernetes.scheduler.process.fds.open.count`*::
+
--
<<<<<<< HEAD
Type of the given event
=======
Number of open file descriptors
>>>>>>> upstream/master

type: long

type: keyword

--

<<<<<<< HEAD
[float]
=== metadata

Metadata associated with the given event
=======
*`kubernetes.scheduler.process.started.sec`*::
+
--
Seconds since the process started
>>>>>>> upstream/master

type: double

--


*`kubernetes.scheduler.http.request.duration.us.percentile.*`*::
+
--
<<<<<<< HEAD
Timestamp of creation of the given event
=======
Request duration microseconds percentiles
>>>>>>> upstream/master

type: object

type: date

--

*`kubernetes.scheduler.http.request.duration.us.sum`*::
+
--
<<<<<<< HEAD
Name of the event
=======
Request duration microseconds cumulative sum
>>>>>>> upstream/master

type: double

type: keyword

--

*`kubernetes.scheduler.http.request.duration.us.count`*::
+
--
<<<<<<< HEAD
Namespace in which event was generated
=======
Request count for duration
>>>>>>> upstream/master

type: long

type: keyword

--

*`kubernetes.scheduler.http.request.size.bytes.percentile.*`*::
+
--
<<<<<<< HEAD
Version of the event resource
=======
Request size percentiles
>>>>>>> upstream/master

type: object

type: keyword

--

*`kubernetes.scheduler.http.request.size.bytes.sum`*::
+
--
<<<<<<< HEAD
Unique identifier to the event object
=======
Request size cumulative sum

type: long
>>>>>>> upstream/master

format: bytes

type: keyword

--

*`kubernetes.scheduler.http.request.size.bytes.count`*::
+
--
<<<<<<< HEAD
URL representing the event
=======
Request count for size
>>>>>>> upstream/master

type: long

type: keyword

--

<<<<<<< HEAD
[float]
=== involved_object

Metadata associated with the given involved object
=======
*`kubernetes.scheduler.http.response.size.bytes.percentile.*`*::
+
--
Response size percentiles
>>>>>>> upstream/master

type: object

--

*`kubernetes.scheduler.http.response.size.bytes.sum`*::
+
--
<<<<<<< HEAD
API version of the object
=======
Response size cumulative sum

type: long
>>>>>>> upstream/master

format: bytes

type: keyword

--

*`kubernetes.scheduler.http.response.size.bytes.count`*::
+
--
<<<<<<< HEAD
API kind of the object
=======
Response count
>>>>>>> upstream/master

type: long

type: keyword

--

*`kubernetes.scheduler.http.request.count`*::
+
--
<<<<<<< HEAD
name of the object
=======
Request count
>>>>>>> upstream/master

type: long

type: keyword

--

*`kubernetes.scheduler.client.request.count`*::
+
--
<<<<<<< HEAD
resource version of the object
=======
Number of requests as client

>>>>>>> upstream/master

type: long

type: keyword

--

*`kubernetes.scheduler.leader.is_master`*::
+
--
<<<<<<< HEAD
UUID version of the object
=======
Whether the node is master

>>>>>>> upstream/master

type: boolean

type: keyword

--

<<<<<<< HEAD
[float]
=== node
=======
>>>>>>> upstream/master

*`kubernetes.scheduler.scheduling.e2e.duration.us.bucket.*`*::
+
--
End to end scheduling duration microseconds

type: object

--

*`kubernetes.scheduler.scheduling.e2e.duration.us.sum`*::
+
--
<<<<<<< HEAD
Start time
=======
End to end scheduling duration microseconds sum
>>>>>>> upstream/master

type: long

type: date

--

<<<<<<< HEAD
[float]
=== cpu
=======
*`kubernetes.scheduler.scheduling.e2e.duration.us.count`*::
+
--
End to end scheduling count
>>>>>>> upstream/master

type: long

--

*`kubernetes.scheduler.scheduling.pod.preemption.victims.count`*::
+
--
Pod preemption victims

type: long

--

*`kubernetes.scheduler.scheduling.pod.attempts.count`*::
+
--
<<<<<<< HEAD
Node CPU Core usage nanoseconds
=======
Pod attempts count
>>>>>>> upstream/master

type: long

type: long

--

*`kubernetes.scheduler.scheduling.duration.seconds.percentile.*`*::
+
--
<<<<<<< HEAD
CPU used nanocores
=======
Scheduling duration percentiles

type: object
>>>>>>> upstream/master

--

<<<<<<< HEAD
type: long

=======
*`kubernetes.scheduler.scheduling.duration.seconds.sum`*::
+
>>>>>>> upstream/master
--
Scheduling duration cumulative sum

type: double

--

*`kubernetes.scheduler.scheduling.duration.seconds.count`*::
+
--
<<<<<<< HEAD
Total available memory


type: long

format: bytes
=======
Scheduling count

type: long

--

[float]
=== container

kubernetes container metrics
>>>>>>> upstream/master



*`kubernetes.container.id`*::
+
--
<<<<<<< HEAD
Total memory usage


type: long

format: bytes
=======
Container id

type: keyword
>>>>>>> upstream/master

--


*`kubernetes.container.status.phase`*::
+
--
<<<<<<< HEAD
RSS memory usage


type: long

format: bytes
=======
Container phase (running, waiting, terminated)


type: keyword
>>>>>>> upstream/master

--

*`kubernetes.container.status.ready`*::
+
--
<<<<<<< HEAD
Working set memory usage


type: long

format: bytes
=======
Container ready status


type: boolean
>>>>>>> upstream/master

--

*`kubernetes.container.status.restarts`*::
+
--
<<<<<<< HEAD
Number of page faults
=======
Container restarts count

>>>>>>> upstream/master

type: integer

type: long

--

*`kubernetes.container.status.reason`*::
+
--
<<<<<<< HEAD
Number of major page faults
=======
Waiting (ContainerCreating, CrashLoopBackoff, ErrImagePull, ImagePullBackoff) or termination (Completed, ContainerCannotRun, Error, OOMKilled) reason.

>>>>>>> upstream/master

type: keyword

type: long

--


*`kubernetes.container.cpu.limit.cores`*::
+
--
<<<<<<< HEAD
Received bytes


type: long

format: bytes
=======
Container CPU cores limit


type: float
>>>>>>> upstream/master

--

*`kubernetes.container.cpu.request.cores`*::
+
--
<<<<<<< HEAD
Rx errors
=======
Container CPU requested cores

>>>>>>> upstream/master

type: float

type: long

--

*`kubernetes.container.cpu.limit.nanocores`*::
+
--
<<<<<<< HEAD
Transmitted bytes


type: long

format: bytes
=======

deprecated[6.4]

Container CPU nanocores limit


type: long
>>>>>>> upstream/master

--

*`kubernetes.container.cpu.request.nanocores`*::
+
--
<<<<<<< HEAD
Tx errors
=======

deprecated[6.4]
>>>>>>> upstream/master

Container CPU requested nanocores

<<<<<<< HEAD
type: long

--
=======
>>>>>>> upstream/master

type: long

--


*`kubernetes.container.memory.limit.bytes`*::
+
--
<<<<<<< HEAD
Filesystem total capacity in bytes
=======
Container memory limit in bytes
>>>>>>> upstream/master


type: long

format: bytes

--

*`kubernetes.container.memory.request.bytes`*::
+
--
<<<<<<< HEAD
Filesystem total available in bytes
=======
Container requested memory in bytes


type: long
>>>>>>> upstream/master


<<<<<<< HEAD
type: long

format: bytes
=======
--

[float]
=== cronjob
>>>>>>> upstream/master

kubernetes cronjob metrics



*`kubernetes.cronjob.name`*::
+
--
<<<<<<< HEAD
Filesystem total used in bytes


type: long

format: bytes
=======
Cronjob name

type: keyword
>>>>>>> upstream/master

--

*`kubernetes.cronjob.schedule`*::
+
--
<<<<<<< HEAD
Number of used inodes
=======
Cronjob schedule
>>>>>>> upstream/master

type: keyword

type: long

--

*`kubernetes.cronjob.concurrency`*::
+
--
<<<<<<< HEAD
Number of inodes
=======
Concurrency policy
>>>>>>> upstream/master

type: keyword

type: long

--

*`kubernetes.cronjob.active.count`*::
+
--
<<<<<<< HEAD
Number of free inodes
=======
Number of active pods for the cronjob

type: long

--

*`kubernetes.cronjob.is_suspended`*::
+
--
Whether the cronjob is suspended
>>>>>>> upstream/master

type: boolean

type: long

--

*`kubernetes.cronjob.created.sec`*::
+
--
Epoch seconds since the cronjob was created

type: double

--

*`kubernetes.cronjob.last_schedule.sec`*::
+
--
<<<<<<< HEAD
Image filesystem total capacity in bytes


type: long

format: bytes
=======
Epoch seconds for last cronjob run

type: double
>>>>>>> upstream/master

--

*`kubernetes.cronjob.next_schedule.sec`*::
+
--
<<<<<<< HEAD
Image filesystem total available in bytes


type: long

format: bytes
=======
Epoch seconds for next cronjob run

type: double
>>>>>>> upstream/master

--

*`kubernetes.cronjob.deadline.sec`*::
+
--
<<<<<<< HEAD
Image filesystem total used in bytes


type: long

format: bytes
=======
Deadline seconds after schedule for considering failed

type: long
>>>>>>> upstream/master

--

[float]
<<<<<<< HEAD
=== pod
=======
=== deployment
>>>>>>> upstream/master

kubernetes deployment metrics



*`kubernetes.deployment.paused`*::
+
--
<<<<<<< HEAD
Start time
=======
Kubernetes deployment paused status

>>>>>>> upstream/master

type: boolean

type: date

--

[float]
=== replicas

Kubernetes deployment replicas info



*`kubernetes.deployment.replicas.desired`*::
+
--
<<<<<<< HEAD
Received bytes


type: long

format: bytes
=======
Deployment number of desired replicas (spec)


type: integer
>>>>>>> upstream/master

--

*`kubernetes.deployment.replicas.available`*::
+
--
<<<<<<< HEAD
Rx errors
=======
Deployment available replicas

>>>>>>> upstream/master

type: integer

type: long

--

*`kubernetes.deployment.replicas.unavailable`*::
+
--
<<<<<<< HEAD
Transmitted bytes


type: long

format: bytes
=======
Deployment unavailable replicas


type: integer
>>>>>>> upstream/master

--

*`kubernetes.deployment.replicas.updated`*::
+
--
<<<<<<< HEAD
Tx errors
=======
Deployment updated replicas

>>>>>>> upstream/master

type: integer

type: long

--

[float]
<<<<<<< HEAD
=== cpu
=======
=== node
>>>>>>> upstream/master

kubernetes node metrics




*`kubernetes.node.status.ready`*::
+
--
<<<<<<< HEAD
CPU used nanocores
=======
Node ready status (true, false or unknown)

>>>>>>> upstream/master

type: keyword

type: long

--

*`kubernetes.node.status.unschedulable`*::
+
--
<<<<<<< HEAD
CPU usage as a percentage of the total node CPU


type: scaled_float

format: percentage
=======
Node unschedulable status


type: boolean
>>>>>>> upstream/master

--


*`kubernetes.node.cpu.allocatable.cores`*::
+
--
<<<<<<< HEAD
CPU usage as a percentage of the defined limit for the pod containers (or total node CPU if unlimited)


type: scaled_float

format: percentage

=======
Node CPU allocatable cores


type: float

>>>>>>> upstream/master
--

*`kubernetes.node.cpu.capacity.cores`*::
+
--
<<<<<<< HEAD
Total memory usage


type: long

format: bytes
=======
Node CPU capacity cores


type: long
>>>>>>> upstream/master

--


*`kubernetes.node.memory.allocatable.bytes`*::
+
--
<<<<<<< HEAD
Memory usage as a percentage of the total node allocatable memory


type: scaled_float

format: percentage
=======
Node allocatable memory in bytes


type: long

format: bytes
>>>>>>> upstream/master

--

*`kubernetes.node.memory.capacity.bytes`*::
+
--
<<<<<<< HEAD
Memory usage as a percentage of the defined limit for the pod containers (or total node allocatable memory if unlimited)


type: scaled_float

format: percentage
=======
Node memory capacity in bytes


type: long

format: bytes
>>>>>>> upstream/master

--


*`kubernetes.node.pod.allocatable.total`*::
+
--
<<<<<<< HEAD
Total memory available


type: long

format: bytes
=======
Node allocatable pods


type: long
>>>>>>> upstream/master

--

*`kubernetes.node.pod.capacity.total`*::
+
--
<<<<<<< HEAD
Total working set memory


type: long

format: bytes
=======
Node pod capacity
>>>>>>> upstream/master


type: long

--
<<<<<<< HEAD
Total resident set size memory


type: long
=======

[float]
=== pod

kubernetes pod metrics
>>>>>>> upstream/master

format: bytes


*`kubernetes.pod.ip`*::
+
--
<<<<<<< HEAD
Total page faults
=======
Kubernetes pod IP

>>>>>>> upstream/master

type: ip

type: long

--

*`kubernetes.pod.host_ip`*::
+
--
<<<<<<< HEAD
Total major page faults
=======
Kubernetes pod host IP

>>>>>>> upstream/master

type: ip

type: long

--

[float]
<<<<<<< HEAD
=== container
=======
=== status
>>>>>>> upstream/master

Kubernetes pod status metrics



*`kubernetes.pod.status.phase`*::
+
--
<<<<<<< HEAD
Container id

type: keyword

--
=======
Kubernetes pod phase (Running, Pending...)


type: keyword
>>>>>>> upstream/master

--

*`kubernetes.pod.status.ready`*::
+
--
<<<<<<< HEAD
Container phase (running, waiting, terminated)
=======
Kubernetes pod ready status (true, false or unknown)

>>>>>>> upstream/master

type: keyword

type: keyword

--

*`kubernetes.pod.status.scheduled`*::
+
--
<<<<<<< HEAD
Container ready status
=======
Kubernetes pod scheduled status (true, false, unknown)

>>>>>>> upstream/master

type: keyword

type: boolean

--

<<<<<<< HEAD
*`kubernetes.container.status.restarts`*::
+
--
Container restarts count


type: integer

--
=======
[float]
=== replicaset

kubernetes replica set metrics


>>>>>>> upstream/master

[float]
=== replicas

Kubernetes replica set paused status



*`kubernetes.replicaset.replicas.available`*::
+
--
<<<<<<< HEAD
Waiting (ContainerCreating, CrashLoopBackoff, ErrImagePull, ImagePullBackoff) or termination (Completed, ContainerCannotRun, Error, OOMKilled) reason.
=======
The number of replicas per ReplicaSet

>>>>>>> upstream/master

type: long

type: keyword

--

*`kubernetes.replicaset.replicas.desired`*::
+
--
<<<<<<< HEAD
Container CPU cores limit
=======
The number of replicas per ReplicaSet

>>>>>>> upstream/master

type: long

type: float

--

*`kubernetes.replicaset.replicas.ready`*::
+
--
<<<<<<< HEAD
Container CPU requested cores
=======
The number of ready replicas per ReplicaSet

>>>>>>> upstream/master

type: long

type: float

--

*`kubernetes.replicaset.replicas.observed`*::
+
--
The generation observed by the ReplicaSet controller


<<<<<<< HEAD
Container CPU nanocores limit


=======
>>>>>>> upstream/master
type: long

--

*`kubernetes.replicaset.replicas.labeled`*::
+
--
The number of fully labeled replicas per ReplicaSet


<<<<<<< HEAD
Container CPU requested nanocores
=======
type: long

--
>>>>>>> upstream/master

[float]
=== statefulset

<<<<<<< HEAD
type: long

--
=======
kubernetes stateful set metrics
>>>>>>> upstream/master



*`kubernetes.statefulset.created`*::
+
--
<<<<<<< HEAD
Container memory limit in bytes


type: long

format: bytes

--

*`kubernetes.container.memory.request.bytes`*::
+
--
Container requested memory in bytes


type: long
=======
The creation timestamp (epoch) for StatefulSet


type: long

--

[float]
=== replicas

Kubernetes stateful set replicas status

>>>>>>> upstream/master

format: bytes

*`kubernetes.statefulset.replicas.observed`*::
+
--
The number of observed replicas per StatefulSet

<<<<<<< HEAD
[float]
=== deployment

kubernetes deployment metrics
=======
>>>>>>> upstream/master

type: long

--

*`kubernetes.statefulset.replicas.desired`*::
+
--
<<<<<<< HEAD
Kubernetes deployment paused status
=======
The number of desired replicas per StatefulSet

>>>>>>> upstream/master

type: long

type: boolean

--

[float]
<<<<<<< HEAD
=== replicas
=======
=== generation
>>>>>>> upstream/master

Kubernetes stateful set generation information



*`kubernetes.statefulset.generation.observed`*::
+
--
<<<<<<< HEAD
Deployment number of desired replicas (spec)
=======
The observed generation per StatefulSet

>>>>>>> upstream/master

type: long

type: integer

--

*`kubernetes.statefulset.generation.desired`*::
+
--
<<<<<<< HEAD
Deployment available replicas
=======
The desired generation per StatefulSet

>>>>>>> upstream/master

type: long

type: integer

--

[float]
=== system

kubernetes system containers metrics



*`kubernetes.system.container`*::
+
--
<<<<<<< HEAD
Deployment unavailable replicas
=======
Container name

>>>>>>> upstream/master

type: keyword

type: integer

--

*`kubernetes.system.start_time`*::
+
--
<<<<<<< HEAD
Deployment updated replicas
=======
Start time

>>>>>>> upstream/master

type: date

type: integer

--

[float]
<<<<<<< HEAD
=== node
=======
=== cpu
>>>>>>> upstream/master

CPU usage metrics





*`kubernetes.system.cpu.usage.core.ns`*::
+
--
<<<<<<< HEAD
Node ready status (true, false or unknown)
=======
CPU Core usage nanoseconds

>>>>>>> upstream/master

type: long

type: keyword

--

*`kubernetes.system.cpu.usage.nanocores`*::
+
--
<<<<<<< HEAD
Node unschedulable status
=======
CPU used nanocores

>>>>>>> upstream/master

type: long

type: boolean

--



*`kubernetes.system.memory.usage.bytes`*::
+
--
<<<<<<< HEAD
Node CPU allocatable cores
=======
Total memory usage

>>>>>>> upstream/master

type: long

format: bytes

type: float

--


*`kubernetes.system.memory.rss.bytes`*::
+
--
<<<<<<< HEAD
Node CPU capacity cores
=======
RSS memory usage

>>>>>>> upstream/master

type: long

format: bytes

type: long

--


*`kubernetes.system.memory.workingset.bytes`*::
+
--
<<<<<<< HEAD
Node allocatable memory in bytes
=======
Working set memory usage
>>>>>>> upstream/master


type: long

format: bytes

--

*`kubernetes.system.memory.pagefaults`*::
+
--
<<<<<<< HEAD
Node memory capacity in bytes


type: long

format: bytes
=======
Number of page faults


type: long
>>>>>>> upstream/master

--

*`kubernetes.system.memory.majorpagefaults`*::
+
--
<<<<<<< HEAD
Node allocatable pods
=======
Number of major page faults

>>>>>>> upstream/master

type: long

type: long

--

<<<<<<< HEAD
*`kubernetes.node.pod.capacity.total`*::
+
--
Node pod capacity


type: long

=======
[float]
=== volume

kubernetes volume metrics



*`kubernetes.volume.name`*::
+
>>>>>>> upstream/master
--
Volume name

<<<<<<< HEAD
[float]
=== pod
=======
>>>>>>> upstream/master

type: keyword

--



*`kubernetes.volume.fs.capacity.bytes`*::
+
--
<<<<<<< HEAD
Kubernetes pod IP
=======
Filesystem total capacity in bytes

>>>>>>> upstream/master

type: long

format: bytes

type: ip

--


*`kubernetes.volume.fs.available.bytes`*::
+
--
<<<<<<< HEAD
Kubernetes pod host IP
=======
Filesystem total available in bytes

>>>>>>> upstream/master

type: long

format: bytes

type: ip

--

<<<<<<< HEAD
[float]
=== status
=======
>>>>>>> upstream/master

*`kubernetes.volume.fs.used.bytes`*::
+
--
Filesystem total used in bytes


type: long

format: bytes

--


*`kubernetes.volume.fs.inodes.used`*::
+
--
<<<<<<< HEAD
Kubernetes pod phase (Running, Pending...)
=======
Used inodes

>>>>>>> upstream/master

type: long

type: keyword

--

*`kubernetes.volume.fs.inodes.free`*::
+
--
<<<<<<< HEAD
Kubernetes pod ready status (true, false or unknown)
=======
Free inodes

>>>>>>> upstream/master

type: long

type: keyword

--

*`kubernetes.volume.fs.inodes.count`*::
+
--
<<<<<<< HEAD
Kubernetes pod scheduled status (true, false, unknown)
=======
Total inodes

>>>>>>> upstream/master

type: long

type: keyword

--

[[exported-fields-kvm]]
== kvm fields

kvm module



[float]
<<<<<<< HEAD
=== replicaset
=======
=== kvm
>>>>>>> upstream/master




[float]
<<<<<<< HEAD
=== replicas
=======
=== dommemstat
>>>>>>> upstream/master

dommemstat



<<<<<<< HEAD
*`kubernetes.replicaset.replicas.available`*::
+
--
The number of replicas per ReplicaSet


type: long

--
=======
[float]
=== stat

Memory stat


>>>>>>> upstream/master

*`kvm.dommemstat.stat.name`*::
+
--
<<<<<<< HEAD
The number of replicas per ReplicaSet
=======
Memory stat name

>>>>>>> upstream/master

type: keyword

type: long

--

*`kvm.dommemstat.stat.value`*::
+
--
<<<<<<< HEAD
The number of ready replicas per ReplicaSet
=======
Memory stat value

>>>>>>> upstream/master

type: long

type: long

--

*`kvm.dommemstat.id`*::
+
--
<<<<<<< HEAD
The generation observed by the ReplicaSet controller
=======
Domain id

>>>>>>> upstream/master

type: long

type: long

--

*`kvm.dommemstat.name`*::
+
--
<<<<<<< HEAD
The number of fully labeled replicas per ReplicaSet
=======
Domain name

>>>>>>> upstream/master

type: keyword

type: long

--

<<<<<<< HEAD
[float]
=== statefulset
=======
[[exported-fields-logstash]]
== Logstash fields
>>>>>>> upstream/master

Logstash module



<<<<<<< HEAD
*`kubernetes.statefulset.created`*::
+
--
The creation timestamp (epoch) for StatefulSet


type: long

--

[float]
=== replicas
=======
[float]
=== logstash




[float]
=== node
>>>>>>> upstream/master

node



*`logstash.node.host`*::
+
--
<<<<<<< HEAD
The number of observed replicas per StatefulSet
=======
Host name

>>>>>>> upstream/master

type: alias

alias to: host.hostname

type: long

--

*`logstash.node.version`*::
+
--
<<<<<<< HEAD
The number of desired replicas per StatefulSet
=======
Logstash Version

>>>>>>> upstream/master

type: alias

alias to: service.version

type: long

--

[float]
<<<<<<< HEAD
=== generation
=======
=== jvm
>>>>>>> upstream/master

JVM Info



*`logstash.node.jvm.version`*::
+
--
<<<<<<< HEAD
The observed generation per StatefulSet
=======
Version

>>>>>>> upstream/master

type: keyword

type: long

--

*`logstash.node.jvm.pid`*::
+
--
<<<<<<< HEAD
The desired generation per StatefulSet
=======
Process ID

>>>>>>> upstream/master

type: alias

alias to: process.pid

type: long

--

[float]
<<<<<<< HEAD
=== system
=======
=== node.stats

node_stats metrics.



[float]
=== events

Events stats
>>>>>>> upstream/master



*`logstash.node.stats.events.in`*::
+
--
Incoming events counter.


type: long

--

*`logstash.node.stats.events.out`*::
+
--
<<<<<<< HEAD
Container name
=======
Outgoing events counter.

>>>>>>> upstream/master

type: long

type: keyword

--

*`logstash.node.stats.events.filtered`*::
+
--
<<<<<<< HEAD
Start time
=======
Filtered events counter.

>>>>>>> upstream/master

type: long

type: date

--

[[exported-fields-memcached]]
== Memcached fields

Memcached module



[float]
<<<<<<< HEAD
=== cpu
=======
=== memcached
>>>>>>> upstream/master




[float]
=== stats

stats



*`memcached.stats.pid`*::
+
--
<<<<<<< HEAD
CPU Core usage nanoseconds
=======
Current process ID of the Memcached task.

>>>>>>> upstream/master

type: long

type: long

--

*`memcached.stats.uptime.sec`*::
+
--
<<<<<<< HEAD
CPU used nanocores
=======
Memcached server uptime.

>>>>>>> upstream/master

type: long

type: long

--

*`memcached.stats.threads`*::
+
--
<<<<<<< HEAD
Total memory usage


type: long

format: bytes
=======
Number of threads used by the current Memcached server process.


type: long
>>>>>>> upstream/master

--

*`memcached.stats.connections.current`*::
+
--
<<<<<<< HEAD
RSS memory usage


type: long

format: bytes
=======
Number of open connections to this Memcached server, should be the same value on all servers during normal operation.


type: long
>>>>>>> upstream/master

--

*`memcached.stats.connections.total`*::
+
--
<<<<<<< HEAD
Working set memory usage


type: long

format: bytes
=======
Numer of successful connect attempts to this server since it has been started.


type: long
>>>>>>> upstream/master

--

*`memcached.stats.get.hits`*::
+
--
<<<<<<< HEAD
Number of page faults
=======
Number of successful "get" commands (cache hits) since startup, divide them by the "cmd_get" value to get the cache hitrate.

>>>>>>> upstream/master

type: long

type: long

--

*`memcached.stats.get.misses`*::
+
--
<<<<<<< HEAD
Number of major page faults
=======
Number of failed "get" requests because nothing was cached for this key or the cached value was too old.

>>>>>>> upstream/master

type: long

type: long

--

<<<<<<< HEAD
[float]
=== volume
=======
*`memcached.stats.cmd.get`*::
+
--
Number of "get" commands received since server startup not counting if they were successful or not.
>>>>>>> upstream/master


type: long

--

*`memcached.stats.cmd.set`*::
+
--
<<<<<<< HEAD
Volume name
=======
Number of "set" commands serviced since startup.

>>>>>>> upstream/master

type: long

type: keyword

--

*`memcached.stats.read.bytes`*::
+
--
<<<<<<< HEAD
Filesystem total capacity in bytes


type: long

format: bytes
=======
Total number of bytes received from the network by this server.


type: long
>>>>>>> upstream/master

--

*`memcached.stats.written.bytes`*::
+
--
<<<<<<< HEAD
Filesystem total available in bytes


type: long

format: bytes
=======
Total number of bytes send to the network by this server.


type: long
>>>>>>> upstream/master

--

*`memcached.stats.items.current`*::
+
--
<<<<<<< HEAD
Filesystem total used in bytes
=======
Number of items currently in this server's cache.
>>>>>>> upstream/master


type: long

<<<<<<< HEAD
format: bytes
=======
--
>>>>>>> upstream/master

*`memcached.stats.items.total`*::
+
--
Number of items stored ever stored on this server. This is no "maximum item count" value but a counted increased by every new item stored in the cache.


type: long

--

*`memcached.stats.evictions`*::
+
--
<<<<<<< HEAD
Used inodes
=======
Number of objects removed from the cache to free up memory for new items because Memcached reached it's maximum memory setting (limit_maxbytes).

>>>>>>> upstream/master

type: long

type: long

--

*`memcached.stats.bytes.current`*::
+
--
<<<<<<< HEAD
Free inodes
=======
Number of bytes currently used for caching items.

>>>>>>> upstream/master

type: long

type: long

--

*`memcached.stats.bytes.limit`*::
+
--
<<<<<<< HEAD
Total inodes
=======
Number of bytes this server is allowed to use for storage.

>>>>>>> upstream/master

type: long

type: long

--

[[exported-fields-mongodb]]
== MongoDB fields

Metrics collected from MongoDB servers.



[float]
<<<<<<< HEAD
=== kvm
=======
=== mongodb
>>>>>>> upstream/master

MongoDB metrics.



[float]
<<<<<<< HEAD
=== dommemstat
=======
=== collstats
>>>>>>> upstream/master

MongoDB collection statistics metrics.



<<<<<<< HEAD
[float]
=== stat
=======
*`mongodb.collstats.db`*::
+
--
Database name.
>>>>>>> upstream/master


type: keyword

--

*`mongodb.collstats.collection`*::
+
--
<<<<<<< HEAD
Memory stat name
=======
Collection name.

>>>>>>> upstream/master

type: keyword

type: keyword

--

*`mongodb.collstats.name`*::
+
--
<<<<<<< HEAD
Memory stat value
=======
Combination of database and collection name.

>>>>>>> upstream/master

type: keyword

type: long

--

*`mongodb.collstats.total.time.us`*::
+
--
<<<<<<< HEAD
Domain id
=======
Total waiting time for locks in microseconds.

>>>>>>> upstream/master

type: long

type: long

--

*`mongodb.collstats.total.count`*::
+
--
<<<<<<< HEAD
Domain name
=======
Total number of lock wait events.

>>>>>>> upstream/master

type: long

type: keyword

--


*`mongodb.collstats.lock.read.time.us`*::
+
--
Time waiting for read locks in microseconds.


type: long

<<<<<<< HEAD
[float]
=== logstash
=======
--
>>>>>>> upstream/master

*`mongodb.collstats.lock.read.count`*::
+
--
Number of read lock wait events.


type: long

<<<<<<< HEAD
[float]
=== node
=======
--
>>>>>>> upstream/master

*`mongodb.collstats.lock.write.time.us`*::
+
--
Time waiting for write locks in microseconds.


type: long

--
<<<<<<< HEAD
Host name


type: alias

alias to: host.hostname
=======

*`mongodb.collstats.lock.write.count`*::
+
--
Number of write lock wait events.


type: long
>>>>>>> upstream/master

--

*`mongodb.collstats.queries.time.us`*::
+
--
<<<<<<< HEAD
Logstash Version


type: alias

alias to: service.version

--

[float]
=== jvm
=======
Time running queries in microseconds.


type: long

--

*`mongodb.collstats.queries.count`*::
+
--
Number of queries executed.
>>>>>>> upstream/master


type: long

--

*`mongodb.collstats.getmore.time.us`*::
+
--
<<<<<<< HEAD
Version
=======
Time asking for more cursor rows in microseconds.

>>>>>>> upstream/master

type: long

type: keyword

--

*`mongodb.collstats.getmore.count`*::
+
--
<<<<<<< HEAD
Process ID


type: alias

alias to: process.pid

--

[float]
=== node.stats
=======
Number of times a cursor asked for more data.


type: long

--

*`mongodb.collstats.insert.time.us`*::
+
--
Time inserting new documents in microseconds.


type: long

--

*`mongodb.collstats.insert.count`*::
+
--
Number of document insert events.
>>>>>>> upstream/master


type: long

--

<<<<<<< HEAD
[float]
=== events
=======
*`mongodb.collstats.update.time.us`*::
+
--
Time updating documents in microseconds.
>>>>>>> upstream/master


type: long

--

*`mongodb.collstats.update.count`*::
+
--
<<<<<<< HEAD
Incoming events counter.
=======
Number of document update events.

>>>>>>> upstream/master

type: long

type: long

--

*`mongodb.collstats.remove.time.us`*::
+
--
<<<<<<< HEAD
Outgoing events counter.
=======
Time deleting documents in microseconds.

>>>>>>> upstream/master

type: long

type: long

--

*`mongodb.collstats.remove.count`*::
+
--
<<<<<<< HEAD
Filtered events counter.
=======
Number of document delete events.

>>>>>>> upstream/master

type: long

type: long

--

*`mongodb.collstats.commands.time.us`*::
+
--
Time executing database commands in microseconds.


type: long

--

<<<<<<< HEAD
[float]
=== memcached
=======
*`mongodb.collstats.commands.count`*::
+
--
Number of database commands executed.
>>>>>>> upstream/master


type: long

--

[float]
<<<<<<< HEAD
=== stats
=======
=== dbstats
>>>>>>> upstream/master

dbstats provides an overview of a particular mongo database. This document is most concerned with data volumes of a database.



*`mongodb.dbstats.avg_obj_size.bytes`*::
+
--
<<<<<<< HEAD
Current process ID of the Memcached task.

=======
type: long

format: bytes
>>>>>>> upstream/master

type: long

--

*`mongodb.dbstats.collections`*::
+
--
<<<<<<< HEAD
Memcached server uptime.

=======
type: integer
>>>>>>> upstream/master

type: long

--

*`mongodb.dbstats.data_size.bytes`*::
+
--
<<<<<<< HEAD
Number of threads used by the current Memcached server process.

=======
type: long

format: bytes
>>>>>>> upstream/master

type: long

--

*`mongodb.dbstats.db`*::
+
--
<<<<<<< HEAD
Number of open connections to this Memcached server, should be the same value on all servers during normal operation.

=======
type: keyword
>>>>>>> upstream/master

type: long

--

*`mongodb.dbstats.file_size.bytes`*::
+
--
<<<<<<< HEAD
Numer of successful connect attempts to this server since it has been started.

=======
type: long

format: bytes
>>>>>>> upstream/master

type: long

--

*`mongodb.dbstats.index_size.bytes`*::
+
--
<<<<<<< HEAD
Number of successful "get" commands (cache hits) since startup, divide them by the "cmd_get" value to get the cache hitrate.

=======
type: long

format: bytes
>>>>>>> upstream/master

type: long

--

*`mongodb.dbstats.indexes`*::
+
--
<<<<<<< HEAD
Number of failed "get" requests because nothing was cached for this key or the cached value was too old.


=======
>>>>>>> upstream/master
type: long

--

*`mongodb.dbstats.num_extents`*::
+
--
<<<<<<< HEAD
Number of "get" commands received since server startup not counting if they were successful or not.


=======
>>>>>>> upstream/master
type: long

--

*`mongodb.dbstats.objects`*::
+
--
<<<<<<< HEAD
Number of "set" commands serviced since startup.


=======
>>>>>>> upstream/master
type: long

--

*`mongodb.dbstats.storage_size.bytes`*::
+
--
<<<<<<< HEAD
Total number of bytes received from the network by this server.

=======
type: long

format: bytes
>>>>>>> upstream/master

type: long

--

*`mongodb.dbstats.ns_size_mb.mb`*::
+
--
<<<<<<< HEAD
Total number of bytes send to the network by this server.


=======
>>>>>>> upstream/master
type: long

--


*`mongodb.dbstats.data_file_version.major`*::
+
--
<<<<<<< HEAD
Number of items currently in this server's cache.


=======
>>>>>>> upstream/master
type: long

--

*`mongodb.dbstats.data_file_version.minor`*::
+
--
<<<<<<< HEAD
Number of items stored ever stored on this server. This is no "maximum item count" value but a counted increased by every new item stored in the cache.


=======
>>>>>>> upstream/master
type: long

--


*`mongodb.dbstats.extent_free_list.num`*::
+
--
<<<<<<< HEAD
Number of objects removed from the cache to free up memory for new items because Memcached reached it's maximum memory setting (limit_maxbytes).


=======
>>>>>>> upstream/master
type: long

--

*`mongodb.dbstats.extent_free_list.size.bytes`*::
+
--
<<<<<<< HEAD
Number of bytes currently used for caching items.

=======
type: long

format: bytes
>>>>>>> upstream/master

type: long

--

[float]
=== metrics

Statistics that reflect the current use and state of a running `mongod` instance for more information, take a look at https://docs.mongodb.com/manual/reference/command/serverStatus/#serverstatus.metrics



[float]
=== commands

Reports on the use of database commands. The fields in metrics.commands are the names of database commands and each value is a document that reports the total number of commands executed as well as the number of failed executions.
metrics.commands.<command>.failed shows the number of times <command> failed on this mongod. metrics.commands.<command>.total shows the number of times <command> executed on this mongod.




*`mongodb.metrics.commands.is_self.failed`*::
+
--
<<<<<<< HEAD
Number of bytes this server is allowed to use for storage.


type: long

=======
type: long

--

*`mongodb.metrics.commands.is_self.total`*::
+
>>>>>>> upstream/master
--
type: long

--


*`mongodb.metrics.commands.aggregate.failed`*::
+
--
type: long

--

<<<<<<< HEAD
[float]
=== mongodb
=======
*`mongodb.metrics.commands.aggregate.total`*::
+
--
type: long
>>>>>>> upstream/master

--


*`mongodb.metrics.commands.build_info.failed`*::
+
--
type: long

<<<<<<< HEAD
[float]
=== collstats
=======
--
>>>>>>> upstream/master

*`mongodb.metrics.commands.build_info.total`*::
+
--
type: long

--


*`mongodb.metrics.commands.coll_stats.failed`*::
+
--
<<<<<<< HEAD
Database name.

=======
type: long
>>>>>>> upstream/master

type: keyword

--

*`mongodb.metrics.commands.coll_stats.total`*::
+
--
<<<<<<< HEAD
Collection name.
=======
type: long

--

>>>>>>> upstream/master

*`mongodb.metrics.commands.connection_pool_stats.failed`*::
+
--
type: long

type: keyword

--

*`mongodb.metrics.commands.connection_pool_stats.total`*::
+
--
<<<<<<< HEAD
Combination of database and collection name.


type: keyword

=======
type: long

--


*`mongodb.metrics.commands.count.failed`*::
+
>>>>>>> upstream/master
--
type: long

--

*`mongodb.metrics.commands.count.total`*::
+
--
<<<<<<< HEAD
Total waiting time for locks in microseconds.
=======
type: long

--

>>>>>>> upstream/master

*`mongodb.metrics.commands.db_stats.failed`*::
+
--
type: long

type: long

--

*`mongodb.metrics.commands.db_stats.total`*::
+
--
<<<<<<< HEAD
Total number of lock wait events.


type: long

=======
type: long

--


*`mongodb.metrics.commands.distinct.failed`*::
+
>>>>>>> upstream/master
--
type: long

--

*`mongodb.metrics.commands.distinct.total`*::
+
--
<<<<<<< HEAD
Time waiting for read locks in microseconds.


=======
type: long

--


*`mongodb.metrics.commands.find.failed`*::
+
--
>>>>>>> upstream/master
type: long

--

*`mongodb.metrics.commands.find.total`*::
+
--
<<<<<<< HEAD
Number of read lock wait events.


type: long

=======
type: long

--


*`mongodb.metrics.commands.get_cmd_line_opts.failed`*::
+
>>>>>>> upstream/master
--
type: long

--

*`mongodb.metrics.commands.get_cmd_line_opts.total`*::
+
--
<<<<<<< HEAD
Time waiting for write locks in microseconds.


=======
type: long

--


*`mongodb.metrics.commands.get_last_error.failed`*::
+
--
>>>>>>> upstream/master
type: long

--

*`mongodb.metrics.commands.get_last_error.total`*::
+
--
<<<<<<< HEAD
Number of write lock wait events.


=======
>>>>>>> upstream/master
type: long

--


*`mongodb.metrics.commands.get_log.failed`*::
+
--
<<<<<<< HEAD
Time running queries in microseconds.


=======
>>>>>>> upstream/master
type: long

--

*`mongodb.metrics.commands.get_log.total`*::
+
--
<<<<<<< HEAD
Number of queries executed.


=======
>>>>>>> upstream/master
type: long

--


*`mongodb.metrics.commands.get_more.failed`*::
+
--
<<<<<<< HEAD
Time asking for more cursor rows in microseconds.


=======
>>>>>>> upstream/master
type: long

--

*`mongodb.metrics.commands.get_more.total`*::
+
--
<<<<<<< HEAD
Number of times a cursor asked for more data.


=======
>>>>>>> upstream/master
type: long

--


*`mongodb.metrics.commands.get_parameter.failed`*::
+
--
<<<<<<< HEAD
Time inserting new documents in microseconds.


=======
>>>>>>> upstream/master
type: long

--

*`mongodb.metrics.commands.get_parameter.total`*::
+
--
<<<<<<< HEAD
Number of document insert events.


=======
>>>>>>> upstream/master
type: long

--


*`mongodb.metrics.commands.host_info.failed`*::
+
--
<<<<<<< HEAD
Time updating documents in microseconds.


=======
>>>>>>> upstream/master
type: long

--

*`mongodb.metrics.commands.host_info.total`*::
+
--
<<<<<<< HEAD
Number of document update events.


=======
>>>>>>> upstream/master
type: long

--


*`mongodb.metrics.commands.insert.failed`*::
+
--
<<<<<<< HEAD
Time deleting documents in microseconds.


=======
>>>>>>> upstream/master
type: long

--

*`mongodb.metrics.commands.insert.total`*::
+
--
<<<<<<< HEAD
Number of document delete events.


=======
>>>>>>> upstream/master
type: long

--


*`mongodb.metrics.commands.is_master.failed`*::
+
--
<<<<<<< HEAD
Time executing database commands in microseconds.


=======
>>>>>>> upstream/master
type: long

--

*`mongodb.metrics.commands.is_master.total`*::
+
--
<<<<<<< HEAD
Number of database commands executed.


=======
>>>>>>> upstream/master
type: long

--

<<<<<<< HEAD
[float]
=== dbstats

dbstats provides an overview of a particular mongo database. This document is most concerned with data volumes of a database.
=======
>>>>>>> upstream/master

*`mongodb.metrics.commands.last_collections.failed`*::
+
--
type: long

--

*`mongodb.metrics.commands.last_collections.total`*::
+
--
type: long

--


*`mongodb.metrics.commands.last_commands.failed`*::
+
--
type: long

--

*`mongodb.metrics.commands.last_commands.total`*::
+
--
type: long

--


*`mongodb.metrics.commands.list_databased.failed`*::
+
--
type: long

--

*`mongodb.metrics.commands.list_databased.total`*::
+
--
type: long

--


*`mongodb.metrics.commands.list_indexes.failed`*::
+
--
type: long

--

*`mongodb.metrics.commands.list_indexes.total`*::
+
--
type: long

--


*`mongodb.metrics.commands.ping.failed`*::
+
--
type: long

--

*`mongodb.metrics.commands.ping.total`*::
+
--
type: long

--


*`mongodb.metrics.commands.profile.failed`*::
+
--
type: long

--

*`mongodb.metrics.commands.profile.total`*::
+
--
type: long

--


*`mongodb.metrics.commands.replset_get_rbid.failed`*::
+
--
type: long

--

*`mongodb.metrics.commands.replset_get_rbid.total`*::
+
--
type: long

--


*`mongodb.metrics.commands.replset_get_status.failed`*::
+
--
type: long

--

*`mongodb.metrics.commands.replset_get_status.total`*::
+
--
type: long

--

<<<<<<< HEAD
[float]
=== metrics

Statistics that reflect the current use and state of a running `mongod` instance for more information, take a look at https://docs.mongodb.com/manual/reference/command/serverStatus/#serverstatus.metrics



[float]
=== commands

Reports on the use of database commands. The fields in metrics.commands are the names of database commands and each value is a document that reports the total number of commands executed as well as the number of failed executions.
metrics.commands.<command>.failed shows the number of times <command> failed on this mongod. metrics.commands.<command>.total shows the number of times <command> executed on this mongod.



=======
>>>>>>> upstream/master

*`mongodb.metrics.commands.replset_heartbeat.failed`*::
+
--
type: long

--

*`mongodb.metrics.commands.replset_heartbeat.total`*::
+
--
type: long

--


*`mongodb.metrics.commands.replset_update_position.failed`*::
+
--
type: long

--

*`mongodb.metrics.commands.replset_update_position.total`*::
+
--
type: long

--


*`mongodb.metrics.commands.server_status.failed`*::
+
--
type: long

--

*`mongodb.metrics.commands.server_status.total`*::
+
--
type: long

--


*`mongodb.metrics.commands.update.failed`*::
+
--
type: long

--

*`mongodb.metrics.commands.update.total`*::
+
--
type: long

--


*`mongodb.metrics.commands.whatsmyuri.failed`*::
+
--
type: long

--

*`mongodb.metrics.commands.whatsmyuri.total`*::
+
--
type: long

--

[float]
=== cursor

Contains data regarding cursor state and use.



*`mongodb.metrics.cursor.timed_out`*::
+
--
The total number of cursors that have timed out since the server process started.


type: long

--

[float]
=== open

Contains data regarding open cursors.



*`mongodb.metrics.cursor.open.no_timeout`*::
+
--
The number of open cursors with the option DBQuery.Option.noTimeout set to prevent timeout.


type: long

--

*`mongodb.metrics.cursor.open.pinned`*::
+
--
The number of `pinned` open cursors.


type: long

--

*`mongodb.metrics.cursor.open.total`*::
+
--
The number of cursors that MongoDB is maintaining for clients.


type: long

--

[float]
=== document

Reflects document access and modification patterns.



*`mongodb.metrics.document.deleted`*::
+
--
The total number of documents deleted.


type: long

--

*`mongodb.metrics.document.inserted`*::
+
--
The total number of documents inserted.


type: long

--

*`mongodb.metrics.document.returned`*::
+
--
The total number of documents returned by queries.


type: long

--

*`mongodb.metrics.document.updated`*::
+
--
The total number of documents updated.


type: long

--

[float]
=== get_last_error

Returns the error status of the preceding write operation on the current connection.



*`mongodb.metrics.get_last_error.write_wait.ms`*::
+
--
The total amount of time in milliseconds that the mongod has spent performing getLastError operations with write concern (i.e. w) greater than 1.


type: long

--

*`mongodb.metrics.get_last_error.write_wait.count`*::
+
--
The total number of getLastError operations with a specified write concern (i.e. w) greater than 1.


type: long

--

*`mongodb.metrics.get_last_error.write_timeouts`*::
+
--
The number of times that write concern operations have timed out as a result of the wtimeout threshold to getLastError.


type: long

--

[float]
=== operation

Holds counters for several types of update and query operations that MongoDB handles using special operation types.



*`mongodb.metrics.operation.scan_and_order`*::
+
--
The total number of queries that return sorted numbers that cannot perform the sort operation using an index.


type: long

--

*`mongodb.metrics.operation.write_conflicts`*::
+
--
The total number of queries that encountered write conflicts.


type: long

--

[float]
=== query_executor

Reports data from the query execution system.



*`mongodb.metrics.query_executor.scanned_indexes`*::
+
--
The total number of index items scanned during queries and query-plan evaluation.


type: long

--

*`mongodb.metrics.query_executor.scanned_documents`*::
+
--
The total number of documents scanned during queries and query-plan evaluation.


type: long

--

[float]
=== replication

Reports metrics related to the replication process. metrics.replication appears on all mongod instances, even those that aren't members of replica sets.



[float]
=== executor

Reports on various statistics for the replication executor.




*`mongodb.metrics.replication.executor.counters.event_created`*::
+
--
type: long

--

*`mongodb.metrics.replication.executor.counters.event_wait`*::
+
--
type: long

--

*`mongodb.metrics.replication.executor.counters.cancels`*::
+
--
type: long

--

*`mongodb.metrics.replication.executor.counters.waits`*::
+
--
type: long

--


*`mongodb.metrics.replication.executor.counters.scheduled.netcmd`*::
+
--
type: long

--

*`mongodb.metrics.replication.executor.counters.scheduled.dbwork`*::
+
--
type: long

--

*`mongodb.metrics.replication.executor.counters.scheduled.exclusive`*::
+
--
type: long

--

*`mongodb.metrics.replication.executor.counters.scheduled.work_at`*::
+
--
type: long

--

*`mongodb.metrics.replication.executor.counters.scheduled.work`*::
+
--
type: long

--

*`mongodb.metrics.replication.executor.counters.scheduled.failures`*::
+
--
type: long

--



*`mongodb.metrics.replication.executor.queues.in_progress.network`*::
+
--
type: long

--

*`mongodb.metrics.replication.executor.queues.in_progress.dbwork`*::
+
--
type: long

--

*`mongodb.metrics.replication.executor.queues.in_progress.exclusive`*::
+
--
type: long

--

*`mongodb.metrics.replication.executor.queues.sleepers`*::
+
--
type: long

--

*`mongodb.metrics.replication.executor.queues.ready`*::
+
--
type: long

--

*`mongodb.metrics.replication.executor.queues.free`*::
+
--
type: long

--

*`mongodb.metrics.replication.executor.unsignaled_events`*::
+
--
type: long

--

*`mongodb.metrics.replication.executor.event_waiters`*::
+
--
type: long

--

*`mongodb.metrics.replication.executor.shutting_down`*::
+
--
type: boolean

--

*`mongodb.metrics.replication.executor.network_interface`*::
+
--
type: keyword

--

[float]
=== apply

Reports on the application of operations from the replication oplog.



*`mongodb.metrics.replication.apply.attempts_to_become_secondary`*::
+
--
type: long

--

[float]
=== batches

Reports on the oplog application process on secondaries members of replica sets.



*`mongodb.metrics.replication.apply.batches.count`*::
+
--
The total number of batches applied across all databases.


type: long

--

*`mongodb.metrics.replication.apply.batches.time.ms`*::
+
--
The total amount of time in milliseconds the mongod has spent applying operations from the oplog.


type: long

--

*`mongodb.metrics.replication.apply.ops`*::
+
--
The total number of oplog operations applied.


type: long

--

[float]
=== buffer

MongoDB buffers oplog operations from the replication sync source buffer before applying oplog entries in a batch. metrics.replication.buffer provides a way to track the oplog buffer.



*`mongodb.metrics.replication.buffer.count`*::
+
--
The current number of operations in the oplog buffer.


type: long

--

*`mongodb.metrics.replication.buffer.max_size.bytes`*::
+
--
The maximum size of the buffer. This value is a constant setting in the mongod, and is not configurable.


type: long

--

*`mongodb.metrics.replication.buffer.size.bytes`*::
+
--
The current size of the contents of the oplog buffer.


type: long

--

[float]
=== initial_sync

Report initial sync status



*`mongodb.metrics.replication.initial_sync.completed`*::
+
--
type: long

--

*`mongodb.metrics.replication.initial_sync.failed_attempts`*::
+
--
type: long

--

*`mongodb.metrics.replication.initial_sync.failures`*::
+
--
type: long

--

[float]
<<<<<<< HEAD
=== cursor
=======
=== network
>>>>>>> upstream/master

Reports network use by the replication process.



*`mongodb.metrics.replication.network.bytes`*::
+
--
<<<<<<< HEAD
The total number of cursors that have timed out since the server process started.
=======
The total amount of data read from the replication sync source.

>>>>>>> upstream/master

type: long

type: long

--

[float]
<<<<<<< HEAD
=== open
=======
=== getmores
>>>>>>> upstream/master

Reports on the getmore operations, which are requests for additional results from the oplog cursor as part of the oplog replication process.



*`mongodb.metrics.replication.network.getmores.count`*::
+
--
<<<<<<< HEAD
The number of open cursors with the option DBQuery.Option.noTimeout set to prevent timeout.
=======
The total number of getmore operations

>>>>>>> upstream/master

type: long

type: long

--

*`mongodb.metrics.replication.network.getmores.time.ms`*::
+
--
<<<<<<< HEAD
The number of `pinned` open cursors.
=======
The total amount of time required to collect data from getmore operations.

>>>>>>> upstream/master

type: long

type: long

--

*`mongodb.metrics.replication.network.ops`*::
+
--
<<<<<<< HEAD
The number of cursors that MongoDB is maintaining for clients.
=======
The total number of operations read from the replication source.

>>>>>>> upstream/master

type: long

type: long

--

<<<<<<< HEAD
[float]
=== document

Reflects document access and modification patterns.
=======
*`mongodb.metrics.replication.network.reders_created`*::
+
--
The total number of oplog query processes created.
>>>>>>> upstream/master


type: long

--
<<<<<<< HEAD
The total number of documents deleted.
=======

[float]
=== preload
>>>>>>> upstream/master

Reports on the `pre-fetch` stage, where MongoDB loads documents and indexes into RAM to improve replication throughput.

<<<<<<< HEAD
type: long

--

*`mongodb.metrics.document.inserted`*::
+
--
The total number of documents inserted.
=======


[float]
=== docs
>>>>>>> upstream/master

Reports on the documents loaded into memory during the pre-fetch stage.

<<<<<<< HEAD
type: long

--
=======
>>>>>>> upstream/master


*`mongodb.metrics.replication.preload.docs.count`*::
+
--
<<<<<<< HEAD
The total number of documents returned by queries.
=======
The total number of documents loaded during the pre-fetch stage of replication.

>>>>>>> upstream/master

type: long

type: long

--

*`mongodb.metrics.replication.preload.docs.time.ms`*::
+
--
<<<<<<< HEAD
The total number of documents updated.


=======
>>>>>>> upstream/master
type: long

--

[float]
<<<<<<< HEAD
=== get_last_error
=======
=== indexes
>>>>>>> upstream/master

Reports on the index items loaded into memory during the pre-fetch stage of replication.



*`mongodb.metrics.replication.preload.indexes.count`*::
+
--
<<<<<<< HEAD
The total amount of time in milliseconds that the mongod has spent performing getLastError operations with write concern (i.e. w) greater than 1.
=======
The total number of index entries loaded by members before updating documents as part of the pre-fetch stage of replication.

>>>>>>> upstream/master

type: long

type: long

--

*`mongodb.metrics.replication.preload.indexes.time.ms`*::
+
--
<<<<<<< HEAD
The total number of getLastError operations with a specified write concern (i.e. w) greater than 1.
=======
The total amount of time, in milliseconds, spent loading index entries as part of the pre-fetch stage of replication.

>>>>>>> upstream/master

type: long

type: long

--


*`mongodb.metrics.storage.free_list.search.bucket_exhausted`*::
+
--
<<<<<<< HEAD
The number of times that write concern operations have timed out as a result of the wtimeout threshold to getLastError.
=======
The number of times that mongod has checked the free list without finding a suitably large record allocation.

>>>>>>> upstream/master

type: long

type: long

--

<<<<<<< HEAD
[float]
=== operation

Holds counters for several types of update and query operations that MongoDB handles using special operation types.



*`mongodb.metrics.operation.scan_and_order`*::
+
--
The total number of queries that return sorted numbers that cannot perform the sort operation using an index.
=======
*`mongodb.metrics.storage.free_list.search.requests`*::
+
--
The number of times mongod has searched for available record allocations.

>>>>>>> upstream/master

type: long

type: long

--

*`mongodb.metrics.storage.free_list.search.scanned`*::
+
--
<<<<<<< HEAD
The total number of queries that encountered write conflicts.
=======
The number of available record allocations mongod has searched.

>>>>>>> upstream/master

type: long

type: long

--

[float]
<<<<<<< HEAD
=== query_executor
=======
=== ttl
>>>>>>> upstream/master

Reports on the operation of the resource use of the ttl index process.



*`mongodb.metrics.ttl.deleted_documents`*::
+
--
<<<<<<< HEAD
The total number of index items scanned during queries and query-plan evaluation.
=======
The total number of documents deleted from collections with a ttl index.

>>>>>>> upstream/master

type: long

type: long

--

*`mongodb.metrics.ttl.passes`*::
+
--
<<<<<<< HEAD
The total number of documents scanned during queries and query-plan evaluation.
=======
The number of times the background process removes documents from collections with a ttl index.

>>>>>>> upstream/master

type: long

type: long

--

[float]
<<<<<<< HEAD
=== replication
=======
=== replstatus
>>>>>>> upstream/master

replstatus provides an overview of replica set status.



[float]
<<<<<<< HEAD
=== executor

Reports on various statistics for the replication executor.
=======
=== oplog
>>>>>>> upstream/master

oplog provides an overview of replication oplog status, which is retrieved from db.getReplicationInfo().



*`mongodb.replstatus.oplog.size.allocated`*::
+
--
The total amount of space used by the replstatus in bytes.


type: long

format: bytes

--

*`mongodb.replstatus.oplog.size.used`*::
+
--
total amount of space allocated to the replstatus in bytes.


type: long

format: bytes

--

*`mongodb.replstatus.oplog.first.timestamp`*::
+
--
Timestamp of the first (i.e. earliest) operation in the replstatus


type: long

--

*`mongodb.replstatus.oplog.last.timestamp`*::
+
--
Timestamp of the last (i.e. latest) operation in the replstatus


type: long

--

*`mongodb.replstatus.oplog.window`*::
+
--
The difference between the first and last operation in the replstatus.


type: long

--

*`mongodb.replstatus.set_name`*::
+
--
The name of the replica set.


type: keyword

--

*`mongodb.replstatus.server_date`*::
+
--
Reflects the current time according to the server that processed the replSetGetStatus command.


type: date

--


*`mongodb.replstatus.optimes.last_committed`*::
+
--
Information, from the viewpoint of this member, regarding the most recent operation that has been written to a majority of replica set members.


type: long

--

*`mongodb.replstatus.optimes.applied`*::
+
--
Information, from the viewpoint of this member, regarding the most recent operation that has been applied to this member of the replica set.


type: long

--

*`mongodb.replstatus.optimes.durable`*::
+
--
Information, from the viewpoint of this member, regarding the most recent operation that has been written to the journal of this member of the replica set.


type: long

--

[float]
=== lag

Delay between a write operation on the primary and its copy to a secondary



*`mongodb.replstatus.lag.max`*::
+
--
Difference between optime of primary and slowest secondary


type: long

format: duration

--

*`mongodb.replstatus.lag.min`*::
+
--
Difference between optime of primary and fastest secondary


type: long

format: duration

--

[float]
=== headroom

Difference between the primary's oplog window and the replication lag of the secondary



*`mongodb.replstatus.headroom.max`*::
+
--
Difference between primary's oplog window and the replication lag of the fastest secondary


type: long

format: duration

--

*`mongodb.replstatus.headroom.min`*::
+
--
Difference between primary's oplog window and the replication lag of the slowest secondary


type: long

format: duration

--

[float]
<<<<<<< HEAD
=== apply
=======
=== members
>>>>>>> upstream/master

Provides information about members of replica set grouped by their state



*`mongodb.replstatus.members.primary.host`*::
+
--
Host address of the primary


type: keyword

--

<<<<<<< HEAD
[float]
=== batches
=======
*`mongodb.replstatus.members.primary.optime`*::
+
--
Optime of primary
>>>>>>> upstream/master


type: keyword

--

*`mongodb.replstatus.members.secondary.hosts`*::
+
--
<<<<<<< HEAD
The total number of batches applied across all databases.
=======
List of secondary hosts

>>>>>>> upstream/master

type: keyword

type: long

--

*`mongodb.replstatus.members.secondary.optimes`*::
+
--
<<<<<<< HEAD
The total amount of time in milliseconds the mongod has spent applying operations from the oplog.
=======
Optimes of secondaries

>>>>>>> upstream/master

type: keyword

type: long

--

*`mongodb.replstatus.members.secondary.count`*::
+
--
<<<<<<< HEAD
The total number of oplog operations applied.


=======
>>>>>>> upstream/master
type: long

--

<<<<<<< HEAD
[float]
=== buffer
=======
*`mongodb.replstatus.members.recovering.hosts`*::
+
--
List of recovering members hosts
>>>>>>> upstream/master


type: keyword

--

*`mongodb.replstatus.members.recovering.count`*::
+
--
<<<<<<< HEAD
The current number of operations in the oplog buffer.
=======
Count of members in the `recovering` state

>>>>>>> upstream/master

type: long

type: long

--

*`mongodb.replstatus.members.unknown.hosts`*::
+
--
<<<<<<< HEAD
The maximum size of the buffer. This value is a constant setting in the mongod, and is not configurable.
=======
List of members' hosts in the `unknown` state

>>>>>>> upstream/master

type: keyword

type: long

--

*`mongodb.replstatus.members.unknown.count`*::
+
--
<<<<<<< HEAD
The current size of the contents of the oplog buffer.
=======
Count of members with `unknown` state

>>>>>>> upstream/master

type: long

type: long

--

<<<<<<< HEAD
[float]
=== initial_sync
=======
*`mongodb.replstatus.members.startup2.hosts`*::
+
--
List of initializing members hosts
>>>>>>> upstream/master


type: keyword

--

*`mongodb.replstatus.members.startup2.count`*::
+
--
Count of members in the `startup2` state


type: long

--

*`mongodb.replstatus.members.arbiter.hosts`*::
+
--
List of arbiters hosts


type: keyword

--

<<<<<<< HEAD
[float]
=== network
=======
*`mongodb.replstatus.members.arbiter.count`*::
+
--
Count of arbiters
>>>>>>> upstream/master


type: long

--

*`mongodb.replstatus.members.down.hosts`*::
+
--
<<<<<<< HEAD
The total amount of data read from the replication sync source.
=======
List of `down` members hosts

>>>>>>> upstream/master

type: keyword

type: long

--

<<<<<<< HEAD
[float]
=== getmores
=======
*`mongodb.replstatus.members.down.count`*::
+
--
Count of `down` members
>>>>>>> upstream/master


type: long

--

*`mongodb.replstatus.members.rollback.hosts`*::
+
--
<<<<<<< HEAD
The total number of getmore operations
=======
List of members in the `rollback` state

>>>>>>> upstream/master

type: keyword

type: long

--

*`mongodb.replstatus.members.rollback.count`*::
+
--
<<<<<<< HEAD
The total amount of time required to collect data from getmore operations.
=======
Count of members in the `rollback` state

>>>>>>> upstream/master

type: long

type: long

--

*`mongodb.replstatus.members.unhealthy.hosts`*::
+
--
<<<<<<< HEAD
The total number of operations read from the replication source.
=======
List of members' hosts with healthy = false

>>>>>>> upstream/master

type: keyword

type: long

--

*`mongodb.replstatus.members.unhealthy.count`*::
+
--
<<<<<<< HEAD
The total number of oplog query processes created.
=======
Count of unhealthy members

>>>>>>> upstream/master

type: long

type: long

--

[float]
<<<<<<< HEAD
=== preload
=======
=== status
>>>>>>> upstream/master

MongoDB server status metrics.



<<<<<<< HEAD
[float]
=== docs
=======
*`mongodb.status.version`*::
+
--
Instance version.
>>>>>>> upstream/master


type: alias

alias to: service.version

--

*`mongodb.status.process`*::
+
--
<<<<<<< HEAD
The total number of documents loaded during the pre-fetch stage of replication.
=======
The current MongoDB process. Possible values are mongos or mongod.

>>>>>>> upstream/master

type: alias

alias to: process.name

type: long

--

*`mongodb.status.uptime.ms`*::
+
--
Instance uptime in milliseconds.


type: long

--

<<<<<<< HEAD
[float]
=== indexes
=======
*`mongodb.status.local_time`*::
+
--
Local time as reported by the MongoDB instance.
>>>>>>> upstream/master


type: date

--

*`mongodb.status.asserts.regular`*::
+
--
<<<<<<< HEAD
The total number of index entries loaded by members before updating documents as part of the pre-fetch stage of replication.
=======
Number of regular assertions produced by the server.

>>>>>>> upstream/master

type: long

type: long

--

*`mongodb.status.asserts.warning`*::
+
--
<<<<<<< HEAD
The total amount of time, in milliseconds, spent loading index entries as part of the pre-fetch stage of replication.
=======
Number of warning assertions produced by the server.

>>>>>>> upstream/master

type: long

type: long

--

*`mongodb.status.asserts.msg`*::
+
--
<<<<<<< HEAD
The number of times that mongod has checked the free list without finding a suitably large record allocation.
=======
Number of msg assertions produced by the server.

>>>>>>> upstream/master

type: long

type: long

--

*`mongodb.status.asserts.user`*::
+
--
<<<<<<< HEAD
The number of times mongod has searched for available record allocations.
=======
Number of user assertions produced by the server.

>>>>>>> upstream/master

type: long

type: long

--

*`mongodb.status.asserts.rollovers`*::
+
--
<<<<<<< HEAD
The number of available record allocations mongod has searched.
=======
Number of rollovers assertions produced by the server.

>>>>>>> upstream/master

type: long

type: long

--

[float]
<<<<<<< HEAD
=== ttl
=======
=== connections
>>>>>>> upstream/master

Data regarding the current status of incoming connections and availability of the database server.



*`mongodb.status.connections.current`*::
+
--
<<<<<<< HEAD
The total number of documents deleted from collections with a ttl index.
=======
The number of connections to the database server from clients. This number includes the current shell session. Consider the value of `available` to add more context to this datum.

>>>>>>> upstream/master

type: long

type: long

--

*`mongodb.status.connections.available`*::
+
--
<<<<<<< HEAD
The number of times the background process removes documents from collections with a ttl index.
=======
The number of unused available incoming connections the database can provide.

>>>>>>> upstream/master

type: long

type: long

--

<<<<<<< HEAD
[float]
=== replstatus
=======
*`mongodb.status.connections.total_created`*::
+
--
A count of all incoming connections created to the server. This number includes connections that have since closed.
>>>>>>> upstream/master


type: long

--

[float]
<<<<<<< HEAD
=== oplog
=======
=== extra_info
>>>>>>> upstream/master

Platform specific data.



*`mongodb.status.extra_info.heap_usage.bytes`*::
+
--
<<<<<<< HEAD
The total amount of space used by the replstatus in bytes.
=======
The total size in bytes of heap space used by the database process. Only available on Unix/Linux.
>>>>>>> upstream/master


type: long

format: bytes

--

*`mongodb.status.extra_info.page_faults`*::
+
--
<<<<<<< HEAD
total amount of space allocated to the replstatus in bytes.


type: long

format: bytes
=======
The total number of page faults that require disk operations. Page faults refer to operations that require the database server to access data that isn't available in active memory.


type: long

--

[float]
=== global_lock

Reports on lock state of the database.
>>>>>>> upstream/master



*`mongodb.status.global_lock.total_time.us`*::
+
--
<<<<<<< HEAD
Timestamp of the first (i.e. earliest) operation in the replstatus
=======
The time, in microseconds, since the database last started and created the globalLock. This is roughly equivalent to total server uptime.

>>>>>>> upstream/master

type: long

type: long

--

<<<<<<< HEAD
*`mongodb.replstatus.oplog.last.timestamp`*::
+
--
Timestamp of the last (i.e. latest) operation in the replstatus


type: long

--
=======
[float]
=== current_queue

The number of operations queued because of a lock.


>>>>>>> upstream/master

*`mongodb.status.global_lock.current_queue.total`*::
+
--
<<<<<<< HEAD
The difference between the first and last operation in the replstatus.
=======
The total number of operations queued waiting for the lock (i.e., the sum of current_queue.readers and current_queue.writers).

>>>>>>> upstream/master

type: long

type: long

--

*`mongodb.status.global_lock.current_queue.readers`*::
+
--
<<<<<<< HEAD
The name of the replica set.
=======
The number of operations that are currently queued and waiting for the read lock.

>>>>>>> upstream/master

type: long

type: keyword

--

*`mongodb.status.global_lock.current_queue.writers`*::
+
--
<<<<<<< HEAD
Reflects the current time according to the server that processed the replSetGetStatus command.
=======
The number of operations that are currently queued and waiting for the write lock.

>>>>>>> upstream/master

type: long

type: date

--

[float]
=== active_clients

The number of connected clients and the read and write operations performed by these clients.



*`mongodb.status.global_lock.active_clients.total`*::
+
--
<<<<<<< HEAD
Information, from the viewpoint of this member, regarding the most recent operation that has been written to a majority of replica set members.
=======
Total number of the active client connections performing read or write operations.

>>>>>>> upstream/master

type: long

type: long

--

*`mongodb.status.global_lock.active_clients.readers`*::
+
--
<<<<<<< HEAD
Information, from the viewpoint of this member, regarding the most recent operation that has been applied to this member of the replica set.
=======
The number of the active client connections performing read operations.

>>>>>>> upstream/master

type: long

type: long

--

*`mongodb.status.global_lock.active_clients.writers`*::
+
--
<<<<<<< HEAD
Information, from the viewpoint of this member, regarding the most recent operation that has been written to the journal of this member of the replica set.
=======
The number of the active client connections performing write operations.

>>>>>>> upstream/master

type: long

type: long

--

[float]
<<<<<<< HEAD
=== lag
=======
=== locks
>>>>>>> upstream/master

A document that reports for each lock <type>, data on lock <mode>s. The possible lock <type>s are global, database, collection, metadata and oplog. The possible <mode>s are r, w, R and W which respresent shared, exclusive, intent shared and intent exclusive.
locks.<type>.acquire.count.<mode> shows the number of times the lock was acquired in the specified mode. locks.<type>.wait.count.<mode> shows the number of times the locks.acquireCount lock acquisitions encountered waits because the locks were held in a conflicting mode. locks.<type>.wait.us.<mode> shows the cumulative wait time in microseconds for the lock acquisitions. locks.<type>.deadlock.count.<mode> shows the number of times the lock acquisitions encountered deadlocks.




*`mongodb.status.locks.global.acquire.count.r`*::
+
--
Difference between optime of primary and slowest secondary

<<<<<<< HEAD

type: long

format: duration

=======
>>>>>>> upstream/master
--

*`mongodb.status.locks.global.acquire.count.w`*::
+
--
Difference between optime of primary and fastest secondary

<<<<<<< HEAD

type: long

format: duration

--

[float]
=== headroom

Difference between the primary's oplog window and the replication lag of the secondary



*`mongodb.replstatus.headroom.max`*::
=======
--

*`mongodb.status.locks.global.acquire.count.R`*::
>>>>>>> upstream/master
+
--
Difference between primary's oplog window and the replication lag of the fastest secondary

<<<<<<< HEAD

type: long

format: duration

=======
>>>>>>> upstream/master
--

*`mongodb.status.locks.global.acquire.count.W`*::
+
--
Difference between primary's oplog window and the replication lag of the slowest secondary

<<<<<<< HEAD

type: long

format: duration

--

[float]
=== members

Provides information about members of replica set grouped by their state



*`mongodb.replstatus.members.primary.host`*::
+
--
Host address of the primary

=======
--

*`mongodb.status.locks.global.wait.count.r`*::
+
--
type: long
>>>>>>> upstream/master

type: keyword

--

*`mongodb.status.locks.global.wait.count.w`*::
+
--
<<<<<<< HEAD
Optime of primary
=======
type: long

--
>>>>>>> upstream/master

*`mongodb.status.locks.global.wait.count.R`*::
+
--
type: long

type: keyword

--

*`mongodb.status.locks.global.wait.count.W`*::
+
--
<<<<<<< HEAD
List of secondary hosts
=======
type: long

--
>>>>>>> upstream/master

*`mongodb.status.locks.global.wait.us.r`*::
+
--
type: long

type: keyword

--

*`mongodb.status.locks.global.wait.us.w`*::
+
--
<<<<<<< HEAD
Optimes of secondaries
=======
type: long

--
>>>>>>> upstream/master

*`mongodb.status.locks.global.wait.us.R`*::
+
--
type: long

type: keyword

--

*`mongodb.status.locks.global.wait.us.W`*::
+
--
type: long

--

*`mongodb.status.locks.global.deadlock.count.r`*::
+
--
<<<<<<< HEAD
List of recovering members hosts

=======
type: long
>>>>>>> upstream/master

type: keyword

--

*`mongodb.status.locks.global.deadlock.count.w`*::
+
--
<<<<<<< HEAD
Count of members in the `recovering` state


=======
>>>>>>> upstream/master
type: long

--

*`mongodb.status.locks.global.deadlock.count.R`*::
+
--
<<<<<<< HEAD
List of members' hosts in the `unknown` state

=======
type: long
>>>>>>> upstream/master

type: keyword

--

*`mongodb.status.locks.global.deadlock.count.W`*::
+
--
<<<<<<< HEAD
Count of members with `unknown` state


=======
>>>>>>> upstream/master
type: long

--


*`mongodb.status.locks.database.acquire.count.r`*::
+
--
<<<<<<< HEAD
List of initializing members hosts

=======
type: long
>>>>>>> upstream/master

type: keyword

--

*`mongodb.status.locks.database.acquire.count.w`*::
+
--
<<<<<<< HEAD
Count of members in the `startup2` state


=======
>>>>>>> upstream/master
type: long

--

*`mongodb.status.locks.database.acquire.count.R`*::
+
--
<<<<<<< HEAD
List of arbiters hosts

=======
type: long
>>>>>>> upstream/master

type: keyword

--

*`mongodb.status.locks.database.acquire.count.W`*::
+
--
<<<<<<< HEAD
Count of arbiters


=======
>>>>>>> upstream/master
type: long

--

*`mongodb.status.locks.database.wait.count.r`*::
+
--
<<<<<<< HEAD
List of `down` members hosts

=======
type: long
>>>>>>> upstream/master

type: keyword

--

*`mongodb.status.locks.database.wait.count.w`*::
+
--
<<<<<<< HEAD
Count of `down` members


=======
>>>>>>> upstream/master
type: long

--

*`mongodb.status.locks.database.wait.count.R`*::
+
--
<<<<<<< HEAD
List of members in the `rollback` state

=======
type: long
>>>>>>> upstream/master

type: keyword

--

*`mongodb.status.locks.database.wait.count.W`*::
+
--
<<<<<<< HEAD
Count of members in the `rollback` state


=======
>>>>>>> upstream/master
type: long

--

*`mongodb.status.locks.database.wait.us.r`*::
+
--
<<<<<<< HEAD
List of members' hosts with healthy = false

=======
type: long
>>>>>>> upstream/master

type: keyword

--

*`mongodb.status.locks.database.wait.us.w`*::
+
--
<<<<<<< HEAD
Count of unhealthy members


=======
>>>>>>> upstream/master
type: long

--

<<<<<<< HEAD
[float]
=== status

MongoDB server status metrics.



*`mongodb.status.version`*::
+
--
Instance version.


type: alias

alias to: service.version
=======
*`mongodb.status.locks.database.wait.us.R`*::
+
--
type: long
>>>>>>> upstream/master

--

*`mongodb.status.locks.database.wait.us.W`*::
+
--
<<<<<<< HEAD
The current MongoDB process. Possible values are mongos or mongod.


type: alias

alias to: process.name
=======
type: long
>>>>>>> upstream/master

--

*`mongodb.status.locks.database.deadlock.count.r`*::
+
--
<<<<<<< HEAD
Instance uptime in milliseconds.


=======
>>>>>>> upstream/master
type: long

--

*`mongodb.status.locks.database.deadlock.count.w`*::
+
--
<<<<<<< HEAD
Local time as reported by the MongoDB instance.

=======
type: long
>>>>>>> upstream/master

type: date

--

*`mongodb.status.locks.database.deadlock.count.R`*::
+
--
<<<<<<< HEAD
Number of regular assertions produced by the server.


=======
>>>>>>> upstream/master
type: long

--

*`mongodb.status.locks.database.deadlock.count.W`*::
+
--
<<<<<<< HEAD
Number of warning assertions produced by the server.


=======
>>>>>>> upstream/master
type: long

--


*`mongodb.status.locks.collection.acquire.count.r`*::
+
--
<<<<<<< HEAD
Number of msg assertions produced by the server.


=======
>>>>>>> upstream/master
type: long

--

*`mongodb.status.locks.collection.acquire.count.w`*::
+
--
<<<<<<< HEAD
Number of user assertions produced by the server.


=======
>>>>>>> upstream/master
type: long

--

*`mongodb.status.locks.collection.acquire.count.R`*::
+
--
<<<<<<< HEAD
Number of rollovers assertions produced by the server.


=======
>>>>>>> upstream/master
type: long

--

<<<<<<< HEAD
[float]
=== connections

Data regarding the current status of incoming connections and availability of the database server.



*`mongodb.status.connections.current`*::
+
--
The number of connections to the database server from clients. This number includes the current shell session. Consider the value of `available` to add more context to this datum.


=======
*`mongodb.status.locks.collection.acquire.count.W`*::
+
--
>>>>>>> upstream/master
type: long

--

*`mongodb.status.locks.collection.wait.count.r`*::
+
--
<<<<<<< HEAD
The number of unused available incoming connections the database can provide.


=======
>>>>>>> upstream/master
type: long

--

*`mongodb.status.locks.collection.wait.count.w`*::
+
--
<<<<<<< HEAD
A count of all incoming connections created to the server. This number includes connections that have since closed.


=======
>>>>>>> upstream/master
type: long

--

<<<<<<< HEAD
[float]
=== extra_info

Platform specific data.



*`mongodb.status.extra_info.heap_usage.bytes`*::
=======
*`mongodb.status.locks.collection.wait.count.R`*::
>>>>>>> upstream/master
+
--
The total size in bytes of heap space used by the database process. Only available on Unix/Linux.

<<<<<<< HEAD

type: long

format: bytes

=======
>>>>>>> upstream/master
--

*`mongodb.status.locks.collection.wait.count.W`*::
+
--
<<<<<<< HEAD
The total number of page faults that require disk operations. Page faults refer to operations that require the database server to access data that isn't available in active memory.


=======
>>>>>>> upstream/master
type: long

--

<<<<<<< HEAD
[float]
=== global_lock

Reports on lock state of the database.



*`mongodb.status.global_lock.total_time.us`*::
+
--
The time, in microseconds, since the database last started and created the globalLock. This is roughly equivalent to total server uptime.


=======
*`mongodb.status.locks.collection.wait.us.r`*::
+
--
>>>>>>> upstream/master
type: long

--

<<<<<<< HEAD
[float]
=== current_queue

The number of operations queued because of a lock.



*`mongodb.status.global_lock.current_queue.total`*::
+
--
The total number of operations queued waiting for the lock (i.e., the sum of current_queue.readers and current_queue.writers).


=======
*`mongodb.status.locks.collection.wait.us.w`*::
+
--
>>>>>>> upstream/master
type: long

--

*`mongodb.status.locks.collection.wait.us.R`*::
+
--
<<<<<<< HEAD
The number of operations that are currently queued and waiting for the read lock.


=======
>>>>>>> upstream/master
type: long

--

*`mongodb.status.locks.collection.wait.us.W`*::
+
--
<<<<<<< HEAD
The number of operations that are currently queued and waiting for the write lock.


=======
>>>>>>> upstream/master
type: long

--

<<<<<<< HEAD
[float]
=== active_clients

The number of connected clients and the read and write operations performed by these clients.



*`mongodb.status.global_lock.active_clients.total`*::
+
--
Total number of the active client connections performing read or write operations.


=======
*`mongodb.status.locks.collection.deadlock.count.r`*::
+
--
>>>>>>> upstream/master
type: long

--

*`mongodb.status.locks.collection.deadlock.count.w`*::
+
--
<<<<<<< HEAD
The number of the active client connections performing read operations.


=======
>>>>>>> upstream/master
type: long

--

*`mongodb.status.locks.collection.deadlock.count.R`*::
+
--
<<<<<<< HEAD
The number of the active client connections performing write operations.


=======
>>>>>>> upstream/master
type: long

--

<<<<<<< HEAD
[float]
=== locks

A document that reports for each lock <type>, data on lock <mode>s. The possible lock <type>s are global, database, collection, metadata and oplog. The possible <mode>s are r, w, R and W which respresent shared, exclusive, intent shared and intent exclusive.
locks.<type>.acquire.count.<mode> shows the number of times the lock was acquired in the specified mode. locks.<type>.wait.count.<mode> shows the number of times the locks.acquireCount lock acquisitions encountered waits because the locks were held in a conflicting mode. locks.<type>.wait.us.<mode> shows the cumulative wait time in microseconds for the lock acquisitions. locks.<type>.deadlock.count.<mode> shows the number of times the lock acquisitions encountered deadlocks.

=======
*`mongodb.status.locks.collection.deadlock.count.W`*::
+
--
type: long
>>>>>>> upstream/master

--


*`mongodb.status.locks.meta_data.acquire.count.r`*::
+
--
type: long

--

*`mongodb.status.locks.meta_data.acquire.count.w`*::
+
--
type: long

--

*`mongodb.status.locks.meta_data.acquire.count.R`*::
+
--
type: long

--

*`mongodb.status.locks.meta_data.acquire.count.W`*::
+
--
type: long

--

*`mongodb.status.locks.meta_data.wait.count.r`*::
+
--
type: long

--

*`mongodb.status.locks.meta_data.wait.count.w`*::
+
--
type: long

--

*`mongodb.status.locks.meta_data.wait.count.R`*::
+
--
type: long

--

*`mongodb.status.locks.meta_data.wait.count.W`*::
+
--
type: long

--

*`mongodb.status.locks.meta_data.wait.us.r`*::
+
--
type: long

--

*`mongodb.status.locks.meta_data.wait.us.w`*::
+
--
type: long

--

*`mongodb.status.locks.meta_data.wait.us.R`*::
+
--
type: long

--

*`mongodb.status.locks.meta_data.wait.us.W`*::
+
--
type: long

--

*`mongodb.status.locks.meta_data.deadlock.count.r`*::
+
--
type: long

--

*`mongodb.status.locks.meta_data.deadlock.count.w`*::
+
--
type: long

--

*`mongodb.status.locks.meta_data.deadlock.count.R`*::
+
--
type: long

--

*`mongodb.status.locks.meta_data.deadlock.count.W`*::
+
--
type: long

--


*`mongodb.status.locks.oplog.acquire.count.r`*::
+
--
type: long

--

*`mongodb.status.locks.oplog.acquire.count.w`*::
+
--
type: long

--

*`mongodb.status.locks.oplog.acquire.count.R`*::
+
--
type: long

--

*`mongodb.status.locks.oplog.acquire.count.W`*::
+
--
type: long

--

*`mongodb.status.locks.oplog.wait.count.r`*::
+
--
type: long

--

*`mongodb.status.locks.oplog.wait.count.w`*::
+
--
type: long

--

*`mongodb.status.locks.oplog.wait.count.R`*::
+
--
type: long

--

*`mongodb.status.locks.oplog.wait.count.W`*::
+
--
type: long

--

*`mongodb.status.locks.oplog.wait.us.r`*::
+
--
type: long

--

*`mongodb.status.locks.oplog.wait.us.w`*::
+
--
type: long

--

*`mongodb.status.locks.oplog.wait.us.R`*::
+
--
type: long

--

*`mongodb.status.locks.oplog.wait.us.W`*::
+
--
type: long

--

*`mongodb.status.locks.oplog.deadlock.count.r`*::
+
--
type: long

--

*`mongodb.status.locks.oplog.deadlock.count.w`*::
+
--
type: long

--

*`mongodb.status.locks.oplog.deadlock.count.R`*::
+
--
type: long

--

*`mongodb.status.locks.oplog.deadlock.count.W`*::
+
--
type: long

--

[float]
=== network

Platform specific data.



*`mongodb.status.network.in.bytes`*::
+
--
The amount of network traffic, in bytes, received by this database.


type: long

format: bytes

--

*`mongodb.status.network.out.bytes`*::
+
--
The amount of network traffic, in bytes, sent from this database.


type: long

format: bytes

--

*`mongodb.status.network.requests`*::
+
--
The total number of requests received by the server.


type: long

--

[float]
=== ops.latencies

Operation latencies for the database as a whole. Only mongod instances report this metric.



*`mongodb.status.ops.latencies.reads.latency`*::
+
--
Total combined latency in microseconds.


type: long

--

*`mongodb.status.ops.latencies.reads.count`*::
+
--
Total number of read operations performed on the collection since startup.


type: long

--

*`mongodb.status.ops.latencies.writes.latency`*::
+
--
Total combined latency in microseconds.


type: long

--

*`mongodb.status.ops.latencies.writes.count`*::
+
--
Total number of write operations performed on the collection since startup.


type: long

--

*`mongodb.status.ops.latencies.commands.latency`*::
+
--
Total combined latency in microseconds.


type: long

--

*`mongodb.status.ops.latencies.commands.count`*::
+
--
Total number of commands performed on the collection since startup.


type: long

--

[float]
=== ops.counters

An overview of database operations by type.



*`mongodb.status.ops.counters.insert`*::
+
--
The total number of insert operations received since the mongod instance last started.


type: long

--

*`mongodb.status.ops.counters.query`*::
+
--
The total number of queries received since the mongod instance last started.


type: long

--

*`mongodb.status.ops.counters.update`*::
+
--
The total number of update operations received since the mongod instance last started.


type: long

--

*`mongodb.status.ops.counters.delete`*::
+
--
The total number of delete operations received since the mongod instance last started.


type: long

--

*`mongodb.status.ops.counters.getmore`*::
+
--
The total number of getmore operations received since the mongod instance last started.


type: long

--

*`mongodb.status.ops.counters.command`*::
+
--
The total number of commands issued to the database since the mongod instance last started.


type: long

--

[float]
=== ops.replicated

An overview of database replication operations by type.



*`mongodb.status.ops.replicated.insert`*::
+
--
The total number of replicated insert operations received since the mongod instance last started.


type: long

--

*`mongodb.status.ops.replicated.query`*::
+
--
The total number of replicated queries received since the mongod instance last started.


type: long

--

*`mongodb.status.ops.replicated.update`*::
+
--
The total number of replicated update operations received since the mongod instance last started.


type: long

--

*`mongodb.status.ops.replicated.delete`*::
+
--
The total number of replicated delete operations received since the mongod instance last started.


type: long

--

*`mongodb.status.ops.replicated.getmore`*::
+
--
The total number of replicated getmore operations received since the mongod instance last started.


type: long

--

*`mongodb.status.ops.replicated.command`*::
+
--
The total number of replicated commands issued to the database since the mongod instance last started.


type: long

--

[float]
=== memory

Data about the current memory usage of the mongod server.



*`mongodb.status.memory.bits`*::
+
--
Either 64 or 32, depending on which target architecture was specified during the mongod compilation process.


type: long

--

*`mongodb.status.memory.resident.mb`*::
+
--
The amount of RAM, in megabytes (MB), currently used by the database process.


type: long

--

*`mongodb.status.memory.virtual.mb`*::
+
--
The amount, in megabytes (MB), of virtual memory used by the mongod process.


type: long

--

*`mongodb.status.memory.mapped.mb`*::
+
--
The amount of mapped memory, in megabytes (MB), used by the database. Because MongoDB uses memory-mapped files, this value is likely to be to be roughly equivalent to the total size of your database or databases.


type: long

--

*`mongodb.status.memory.mapped_with_journal.mb`*::
+
--
The amount of mapped memory, in megabytes (MB), including the memory used for journaling.


type: long

--

*`mongodb.status.write_backs_queued`*::
+
--
True when there are operations from a mongos instance queued for retrying.


type: boolean

--

*`mongodb.status.storage_engine.name`*::
+
--
A string that represents the name of the current storage engine.


type: keyword

--

[float]
=== wired_tiger

Statistics about the WiredTiger storage engine.



[float]
=== concurrent_transactions

Statistics about the transactions currently in progress.



*`mongodb.status.wired_tiger.concurrent_transactions.write.out`*::
+
--
Number of concurrent write transaction in progress.


type: long

--

*`mongodb.status.wired_tiger.concurrent_transactions.write.available`*::
+
--
Number of concurrent write tickets available.


type: long

--

*`mongodb.status.wired_tiger.concurrent_transactions.write.total_tickets`*::
+
--
Number of total write tickets.


type: long

--

*`mongodb.status.wired_tiger.concurrent_transactions.read.out`*::
+
--
Number of concurrent read transaction in progress.


type: long

--

*`mongodb.status.wired_tiger.concurrent_transactions.read.available`*::
+
--
Number of concurrent read tickets available.


type: long

--

*`mongodb.status.wired_tiger.concurrent_transactions.read.total_tickets`*::
+
--
Number of total read tickets.


type: long

--

[float]
=== cache

Statistics about the cache and page evictions from the cache.



*`mongodb.status.wired_tiger.cache.maximum.bytes`*::
+
--
Maximum cache size.


type: long

format: bytes

--

*`mongodb.status.wired_tiger.cache.used.bytes`*::
+
--
Size in byte of the data currently in cache.


type: long

format: bytes

--

*`mongodb.status.wired_tiger.cache.dirty.bytes`*::
+
--
Size in bytes of the dirty data in the cache.


type: long

format: bytes

--

*`mongodb.status.wired_tiger.cache.pages.read`*::
+
--
Number of pages read into the cache.


type: long

--

*`mongodb.status.wired_tiger.cache.pages.write`*::
+
--
Number of pages written from the cache.


type: long

--

*`mongodb.status.wired_tiger.cache.pages.evicted`*::
+
--
Number of pages evicted from the cache.


type: long

--

[float]
=== log

Statistics about the write ahead log used by WiredTiger.



*`mongodb.status.wired_tiger.log.size.bytes`*::
+
--
Total log size in bytes.


type: long

format: bytes

--

*`mongodb.status.wired_tiger.log.write.bytes`*::
+
--
Number of bytes written into the log.


type: long

format: bytes

--

*`mongodb.status.wired_tiger.log.max_file_size.bytes`*::
+
--
Maximum file size.


type: long

format: bytes

--

*`mongodb.status.wired_tiger.log.flushes`*::
+
--
Number of flush operations.


type: long

--

*`mongodb.status.wired_tiger.log.writes`*::
+
--
Number of write operations.


type: long

--

*`mongodb.status.wired_tiger.log.scans`*::
+
--
Number of scan operations.


type: long

--

*`mongodb.status.wired_tiger.log.syncs`*::
+
--
Number of sync operations.


type: long

--

[float]
<<<<<<< HEAD
=== network
=======
=== background_flushing
>>>>>>> upstream/master

Data about the process MongoDB uses to write data to disk. This data is only available for instances that use the MMAPv1 storage engine.



*`mongodb.status.background_flushing.flushes`*::
+
--
<<<<<<< HEAD
The amount of network traffic, in bytes, received by this database.


type: long

format: bytes
=======
A counter that collects the number of times the database has flushed all writes to disk.


type: long

--

*`mongodb.status.background_flushing.total.ms`*::
+
--
The total number of milliseconds (ms) that the mongod processes have spent writing (i.e. flushing) data to disk. Because this is an absolute value, consider the value of `flushes` and `average_ms` to provide better context for this datum.


type: long
>>>>>>> upstream/master

--

*`mongodb.status.background_flushing.average.ms`*::
+
--
<<<<<<< HEAD
The amount of network traffic, in bytes, sent from this database.


type: long

format: bytes
=======
The average time spent flushing to disk per flush event.


type: long

--

*`mongodb.status.background_flushing.last.ms`*::
+
--
The amount of time, in milliseconds, that the last flush operation took to complete.


type: long
>>>>>>> upstream/master

--

*`mongodb.status.background_flushing.last_finished`*::
+
--
<<<<<<< HEAD
The total number of requests received by the server.
=======
A timestamp of the last completed flush operation.

>>>>>>> upstream/master

type: date

type: long

--

[float]
<<<<<<< HEAD
=== ops.latencies
=======
=== journaling
>>>>>>> upstream/master

Data about the journaling-related operations and performance. Journaling information only appears for mongod instances that use the MMAPv1 storage engine and have journaling enabled.



*`mongodb.status.journaling.commits`*::
+
--
<<<<<<< HEAD
Total combined latency in microseconds.
=======
The number of transactions written to the journal during the last journal group commit interval.

>>>>>>> upstream/master

type: long

type: long

--

*`mongodb.status.journaling.journaled.mb`*::
+
--
<<<<<<< HEAD
Total number of read operations performed on the collection since startup.
=======
The amount of data in megabytes (MB) written to journal during the last journal group commit interval.

>>>>>>> upstream/master

type: long

type: long

--

*`mongodb.status.journaling.write_to_data_files.mb`*::
+
--
<<<<<<< HEAD
Total combined latency in microseconds.
=======
The amount of data in megabytes (MB) written from journal to the data files during the last journal group commit interval.

>>>>>>> upstream/master

type: long

type: long

--

*`mongodb.status.journaling.compression`*::
+
--
<<<<<<< HEAD
Total number of write operations performed on the collection since startup.
=======
The compression ratio of the data written to the journal.

>>>>>>> upstream/master

type: long

type: long

--

*`mongodb.status.journaling.commits_in_write_lock`*::
+
--
<<<<<<< HEAD
Total combined latency in microseconds.
=======
Count of the commits that occurred while a write lock was held. Commits in a write lock indicate a MongoDB node under a heavy write load and call for further diagnosis.

>>>>>>> upstream/master

type: long

type: long

--

*`mongodb.status.journaling.early_commits`*::
+
--
<<<<<<< HEAD
Total number of commands performed on the collection since startup.
=======
The number of times MongoDB requested a commit before the scheduled journal group commit interval.

>>>>>>> upstream/master

type: long

type: long

--

[float]
<<<<<<< HEAD
=== ops.counters
=======
=== times
>>>>>>> upstream/master

Information about the performance of the mongod instance during the various phases of journaling in the last journal group commit interval.



*`mongodb.status.journaling.times.dt.ms`*::
+
--
<<<<<<< HEAD
The total number of insert operations received since the mongod instance last started.


type: long

--

*`mongodb.status.ops.counters.query`*::
+
--
The total number of queries received since the mongod instance last started.


=======
The amount of time over which MongoDB collected the times data. Use this field to provide context to the other times field values.


>>>>>>> upstream/master
type: long

--

*`mongodb.status.journaling.times.prep_log_buffer.ms`*::
+
--
<<<<<<< HEAD
The total number of update operations received since the mongod instance last started.
=======
The amount of time spent preparing to write to the journal. Smaller values indicate better journal performance.

>>>>>>> upstream/master

type: long

type: long

--

*`mongodb.status.journaling.times.write_to_journal.ms`*::
+
--
<<<<<<< HEAD
The total number of delete operations received since the mongod instance last started.
=======
The amount of time spent actually writing to the journal. File system speeds and device interfaces can affect performance.

>>>>>>> upstream/master

type: long

type: long

--

*`mongodb.status.journaling.times.write_to_data_files.ms`*::
+
--
<<<<<<< HEAD
The total number of getmore operations received since the mongod instance last started.
=======
The amount of time spent writing to data files after journaling. File system speeds and device interfaces can affect performance.

>>>>>>> upstream/master

type: long

type: long

--

*`mongodb.status.journaling.times.remap_private_view.ms`*::
+
--
<<<<<<< HEAD
The total number of commands issued to the database since the mongod instance last started.
=======
The amount of time spent remapping copy-on-write memory mapped views. Smaller values indicate better journal performance.

>>>>>>> upstream/master

type: long

type: long

--

<<<<<<< HEAD
[float]
=== ops.replicated

An overview of database replication operations by type.



*`mongodb.status.ops.replicated.insert`*::
+
--
The total number of replicated insert operations received since the mongod instance last started.
=======
*`mongodb.status.journaling.times.commits.ms`*::
+
--
The amount of time spent for commits.

>>>>>>> upstream/master

type: long

type: long

--

*`mongodb.status.journaling.times.commits_in_write_lock.ms`*::
+
--
<<<<<<< HEAD
The total number of replicated queries received since the mongod instance last started.
=======
The amount of time spent for commits that occurred while a write lock was held.

>>>>>>> upstream/master

type: long

type: long

--

<<<<<<< HEAD
*`mongodb.status.ops.replicated.update`*::
+
--
The total number of replicated update operations received since the mongod instance last started.


type: long

--

*`mongodb.status.ops.replicated.delete`*::
+
--
The total number of replicated delete operations received since the mongod instance last started.
=======
[[exported-fields-mssql]]
== MSSQL fields

MS SQL module


[float]
=== mssql

The root field containing all MSSQL fields


[float]
=== database
>>>>>>> upstream/master

The database that the metrics is being referred to

<<<<<<< HEAD
type: long

--
=======
>>>>>>> upstream/master

*`mssql.database.id`*::
+
--
<<<<<<< HEAD
The total number of replicated getmore operations received since the mongod instance last started.
=======
Unique ID of the database inside MSSQL
>>>>>>> upstream/master

type: long

type: long

--

*`mssql.database.name`*::
+
--
<<<<<<< HEAD
The total number of replicated commands issued to the database since the mongod instance last started.
=======
Name of the database
>>>>>>> upstream/master

type: keyword

type: long

--

[float]
<<<<<<< HEAD
=== memory

Data about the current memory usage of the mongod server.
=======
=== performance
>>>>>>> upstream/master

performance metricset fetches information about the Performance Counters


*`mssql.performance.page_splits_per_sec`*::
+
--
<<<<<<< HEAD
Either 64 or 32, depending on which target architecture was specified during the mongod compilation process.
=======
Number of page splits per second that occur as the result of overflowing index pages.
>>>>>>> upstream/master

type: long

type: long

--

*`mssql.performance.lock_waits_per_sec`*::
+
--
<<<<<<< HEAD
The amount of RAM, in megabytes (MB), currently used by the database process.
=======
Number of lock requests per second that required the caller to wait.
>>>>>>> upstream/master

type: long

type: long

--

*`mssql.performance.user_connections`*::
+
--
<<<<<<< HEAD
The amount, in megabytes (MB), of virtual memory used by the mongod process.
=======
Total number of user connections

type: long

--

*`mssql.performance.transactions`*::
+
--
Total number of transactions
>>>>>>> upstream/master

type: long

type: long

--

*`mssql.performance.active_temp_tables`*::
+
--
<<<<<<< HEAD
The amount of mapped memory, in megabytes (MB), used by the database. Because MongoDB uses memory-mapped files, this value is likely to be to be roughly equivalent to the total size of your database or databases.
=======
Number of temporary tables/table variables in use.

type: long

--

*`mssql.performance.connections_reset_per_sec`*::
+
--
Total number of logins started from the connection pool.
>>>>>>> upstream/master

type: long

type: long

--

*`mssql.performance.logins_per_sec`*::
+
--
<<<<<<< HEAD
The amount of mapped memory, in megabytes (MB), including the memory used for journaling.
=======
Total number of logins started per second. This does not include pooled connections.

type: long

--

*`mssql.performance.logouts_per_sec`*::
+
--
Total number of logout operations started per second.
>>>>>>> upstream/master

type: long

type: long

--

*`mssql.performance.recompilations_per_sec`*::
+
--
<<<<<<< HEAD
True when there are operations from a mongos instance queued for retrying.
=======
Number of statement recompiles per second. Counts the number of times statement recompiles are triggered. Generally, you want the recompiles to be low.
>>>>>>> upstream/master

type: long

type: boolean

--

*`mssql.performance.compilations_per_sec`*::
+
--
<<<<<<< HEAD
A string that represents the name of the current storage engine.
=======
Number of SQL compilations per second. Indicates the number of times the compile code path is entered. Includes compiles caused by statement-level recompilations in SQL Server. After SQL Server user activity is stable, this value reaches a steady state.
>>>>>>> upstream/master

type: long

type: keyword

--

<<<<<<< HEAD
[float]
=== wired_tiger
=======
*`mssql.performance.batch_requests_per_sec`*::
+
--
Number of Transact-SQL command batches received per second. This statistic is affected by all constraints (such as I/O, number of users, cache size, complexity of requests, and so on). High batch requests mean good throughput.
>>>>>>> upstream/master

type: long

--


[float]
<<<<<<< HEAD
=== concurrent_transactions

Statistics about the transactions currently in progress.
=======
=== cache_hit
>>>>>>> upstream/master

Indicates the percentage of pages found in the buffer cache without having to read from disk.


*`mssql.performance.buffer.cache_hit.pct`*::
+
--
<<<<<<< HEAD
Number of concurrent write transaction in progress.


type: long

--
=======
The ratio is the total number of cache hits divided by the total number of cache lookups over the last few thousand page accesses. After a long period of time, the ratio moves very little. Because reading from the cache is much less expensive than reading from disk, you want this ratio to be high

type: double
>>>>>>> upstream/master

--
<<<<<<< HEAD
Number of concurrent write tickets available.
=======

[float]
=== page_life_expectancy
>>>>>>> upstream/master

Indicates the number of seconds a page will stay in the buffer pool without references.

<<<<<<< HEAD
type: long

--
=======
>>>>>>> upstream/master

*`mssql.performance.buffer.page_life_expectancy.sec`*::
+
--
<<<<<<< HEAD
Number of total write tickets.
=======
Indicates the number of seconds a page will stay in the buffer pool without references (in seconds).
>>>>>>> upstream/master

type: long

type: long

--

*`mssql.performance.buffer.checkpoint_pages_per_sec`*::
+
--
<<<<<<< HEAD
Number of concurrent read transaction in progress.
=======
Indicates the number of pages flushed to disk per second by a checkpoint or other operation that require all dirty pages to be flushed.
>>>>>>> upstream/master

type: long

type: long

--

*`mssql.performance.buffer.database_pages`*::
+
--
<<<<<<< HEAD
Number of concurrent read tickets available.
=======
Indicates the number of pages in the buffer pool with database content.
>>>>>>> upstream/master

type: long

type: long

--

*`mssql.performance.buffer.target_pages`*::
+
--
<<<<<<< HEAD
Number of total read tickets.
=======
Ideal number of pages in the buffer pool.
>>>>>>> upstream/master

type: long

type: long

--

[float]
<<<<<<< HEAD
=== cache
=======
=== transaction_log
>>>>>>> upstream/master

transaction_log metricset will fetch information about the operation and transaction log of each database from a MSSQL instance


[float]
=== space_usage

<<<<<<< HEAD
*`mongodb.status.wired_tiger.cache.maximum.bytes`*::
+
--
Maximum cache size.


type: long

format: bytes
=======
Space usage information for the transaction log


[float]
=== since_last_backup

The amount of space used since the last log backup
>>>>>>> upstream/master


*`mssql.transaction_log.space_usage.since_last_backup.bytes`*::
+
--
<<<<<<< HEAD
Size in byte of the data currently in cache.


type: long

format: bytes
=======
The amount of space used since the last log backup in bytes

type: long

--

[float]
=== total

The size of the log
>>>>>>> upstream/master


*`mssql.transaction_log.space_usage.total.bytes`*::
+
--
<<<<<<< HEAD
Size in bytes of the dirty data in the cache.


type: long

format: bytes
=======
The size of the log in bytes

type: long

--

[float]
=== used

The occupied size of the log
>>>>>>> upstream/master


*`mssql.transaction_log.space_usage.used.bytes`*::
+
--
<<<<<<< HEAD
Number of pages read into the cache.
=======
The occupied size of the log in bytes
>>>>>>> upstream/master

type: long

type: long

--

*`mssql.transaction_log.space_usage.used.pct`*::
+
--
<<<<<<< HEAD
Number of pages written from the cache.


type: long

--
=======
A percentage of the occupied size of the log as a percent of the total log size

type: float
>>>>>>> upstream/master

--
<<<<<<< HEAD
Number of pages evicted from the cache.
=======

[float]
=== stats
>>>>>>> upstream/master

Returns summary level attributes and information on transaction log files of databases. Use this information for monitoring and diagnostics of transaction log health.

<<<<<<< HEAD
type: long

--

[float]
=== log

Statistics about the write ahead log used by WiredTiger.
=======

[float]
=== active_size
>>>>>>> upstream/master

Total active transaction log size.


*`mssql.transaction_log.stats.active_size.bytes`*::
+
--
<<<<<<< HEAD
Total log size in bytes.


type: long

format: bytes
=======
Total active transaction log size in bytes

type: long
>>>>>>> upstream/master

--

*`mssql.transaction_log.stats.backup_time`*::
+
--
<<<<<<< HEAD
Number of bytes written into the log.


type: long

format: bytes
=======
Last transaction log backup time.
>>>>>>> upstream/master

type: date

--
<<<<<<< HEAD
Maximum file size.


type: long

format: bytes
=======

[float]
=== recovery_size

Log size since log recovery log sequence number (LSN).
>>>>>>> upstream/master


*`mssql.transaction_log.stats.recovery_size.bytes`*::
+
--
<<<<<<< HEAD
Number of flush operations.


type: long

--
=======
Log size in bytes since log recovery log sequence number (LSN).

type: long
>>>>>>> upstream/master

--
<<<<<<< HEAD
Number of write operations.
=======

[float]
=== since_last_checkpoint
>>>>>>> upstream/master

Log size since last checkpoint log sequence number (LSN).

<<<<<<< HEAD
type: long

--
=======
>>>>>>> upstream/master

*`mssql.transaction_log.stats.since_last_checkpoint.bytes`*::
+
--
<<<<<<< HEAD
Number of scan operations.
=======
Log size in bytes since last checkpoint log sequence number (LSN).

type: long

--

[float]
=== total_size
>>>>>>> upstream/master

Total transaction log size.

<<<<<<< HEAD
type: long

--
=======
>>>>>>> upstream/master

*`mssql.transaction_log.stats.total_size.bytes`*::
+
--
<<<<<<< HEAD
Number of sync operations.
=======
Total transaction log size in bytes.
>>>>>>> upstream/master

type: long

type: long

--

<<<<<<< HEAD
[float]
=== background_flushing
=======
[[exported-fields-munin]]
== Munin fields
>>>>>>> upstream/master

Munin node metrics exporter



*`munin.metrics.*`*::
+
--
<<<<<<< HEAD
A counter that collects the number of times the database has flushed all writes to disk.
=======
Metrics exposed by a plugin of a munin node agent.

>>>>>>> upstream/master

type: object

type: long

--

*`munin.plugin.name`*::
+
--
<<<<<<< HEAD
The total number of milliseconds (ms) that the mongod processes have spent writing (i.e. flushing) data to disk. Because this is an absolute value, consider the value of `flushes` and `average_ms` to provide better context for this datum.
=======
Name of the plugin collecting these metrics.

>>>>>>> upstream/master

type: keyword

type: long

--

<<<<<<< HEAD
*`mongodb.status.background_flushing.average.ms`*::
+
--
The average time spent flushing to disk per flush event.
=======

[[exported-fields-mysql]]
== MySQL fields
>>>>>>> upstream/master

MySQL server status metrics collected from MySQL.

<<<<<<< HEAD
type: long

--

*`mongodb.status.background_flushing.last.ms`*::
+
--
The amount of time, in milliseconds, that the last flush operation took to complete.
=======


[float]
=== mysql
>>>>>>> upstream/master

`mysql` contains the metrics that were obtained from MySQL query.

<<<<<<< HEAD
type: long

--

*`mongodb.status.background_flushing.last_finished`*::
+
--
A timestamp of the last completed flush operation.


type: date

--

[float]
=== journaling
=======


[float]
=== galera_status

`galera_status` contains the metrics that were obtained by the status SQL query on Galera.



[float]
=== apply
>>>>>>> upstream/master

Apply status fields.



*`mysql.galera_status.apply.oooe`*::
+
--
<<<<<<< HEAD
The number of transactions written to the journal during the last journal group commit interval.
=======
How often applier started write-set applying out-of-order (parallelization efficiency).

>>>>>>> upstream/master

type: double

type: long

--

*`mysql.galera_status.apply.oool`*::
+
--
<<<<<<< HEAD
The amount of data in megabytes (MB) written to journal during the last journal group commit interval.
=======
How often write-set was so slow to apply that write-set with higher seqno's were applied earlier. Values closer to 0 refer to a greater gap between slow and fast write-sets.

>>>>>>> upstream/master

type: double

type: long

--

*`mysql.galera_status.apply.window`*::
+
--
<<<<<<< HEAD
The amount of data in megabytes (MB) written from journal to the data files during the last journal group commit interval.
=======
Average distance between highest and lowest concurrently applied seqno.

>>>>>>> upstream/master

type: double

type: long

--

[float]
=== cert

Certification status fields.



*`mysql.galera_status.cert.deps_distance`*::
+
--
<<<<<<< HEAD
The compression ratio of the data written to the journal.
=======
Average distance between highest and lowest seqno value that can be possibly applied in parallel (potential degree of parallelization).

>>>>>>> upstream/master

type: double

type: long

--

*`mysql.galera_status.cert.index_size`*::
+
--
<<<<<<< HEAD
Count of the commits that occurred while a write lock was held. Commits in a write lock indicate a MongoDB node under a heavy write load and call for further diagnosis.
=======
The number of entries in the certification index.

>>>>>>> upstream/master

type: long

type: long

--

*`mysql.galera_status.cert.interval`*::
+
--
<<<<<<< HEAD
The number of times MongoDB requested a commit before the scheduled journal group commit interval.
=======
Average number of transactions received while a transaction replicates.

>>>>>>> upstream/master

type: double

type: long

--

[float]
<<<<<<< HEAD
=== times
=======
=== cluster
>>>>>>> upstream/master

Cluster status fields.



*`mysql.galera_status.cluster.conf_id`*::
+
--
<<<<<<< HEAD
The amount of time over which MongoDB collected the times data. Use this field to provide context to the other times field values.
=======
Total number of cluster membership changes happened.

>>>>>>> upstream/master

type: long

type: long

--

*`mysql.galera_status.cluster.size`*::
+
--
<<<<<<< HEAD
The amount of time spent preparing to write to the journal. Smaller values indicate better journal performance.
=======
Current number of members in the cluster.

>>>>>>> upstream/master

type: long

type: long

--

*`mysql.galera_status.cluster.status`*::
+
--
<<<<<<< HEAD
The amount of time spent actually writing to the journal. File system speeds and device interfaces can affect performance.
=======
Status of this cluster component. That is, whether the node is part of a PRIMARY or NON_PRIMARY component.

>>>>>>> upstream/master

type: keyword

type: long

--

<<<<<<< HEAD
*`mongodb.status.journaling.times.write_to_data_files.ms`*::
+
--
The amount of time spent writing to data files after journaling. File system speeds and device interfaces can affect performance.


type: long

--
=======
[float]
=== commit

Commit status fields.


>>>>>>> upstream/master

*`mysql.galera_status.commit.oooe`*::
+
--
<<<<<<< HEAD
The amount of time spent remapping copy-on-write memory mapped views. Smaller values indicate better journal performance.
=======
How often a transaction was committed out of order.

>>>>>>> upstream/master

type: double

type: long

--

*`mysql.galera_status.commit.window`*::
+
--
<<<<<<< HEAD
The amount of time spent for commits.
=======
Average distance between highest and lowest concurrently committed seqno.

>>>>>>> upstream/master

type: long

type: long

--

*`mysql.galera_status.connected`*::
+
--
<<<<<<< HEAD
The amount of time spent for commits that occurred while a write lock was held.
=======
If the value is OFF, the node has not yet connected to any of the cluster components. This may be due to misconfiguration. Check the error log for proper diagnostics.

>>>>>>> upstream/master

type: keyword

type: long

--

[float]
<<<<<<< HEAD
=== mssql

The root field containing all MSSQL fields


[float]
=== database
=======
=== evs

Evs Fields.
>>>>>>> upstream/master



*`mysql.galera_status.evs.evict`*::
+
--
<<<<<<< HEAD
Unique ID of the database inside MSSQL
=======
Lists the UUID's of all nodes evicted from the cluster. Evicted nodes cannot rejoin the cluster until you restart their mysqld processes.


type: keyword
>>>>>>> upstream/master

type: long

--

*`mysql.galera_status.evs.state`*::
+
--
<<<<<<< HEAD
Name of the database
=======
Shows the internal state of the EVS Protocol.


type: keyword
>>>>>>> upstream/master

type: keyword

--

[float]
<<<<<<< HEAD
=== performance
=======
=== flow_ctl
>>>>>>> upstream/master

Flow Control fields.



*`mysql.galera_status.flow_ctl.paused`*::
+
--
<<<<<<< HEAD
Number of page splits per second that occur as the result of overflowing index pages.
=======
The fraction of time since the last FLUSH STATUS command that replication was paused due to flow control. In other words, how much the slave lag is slowing down the cluster.


type: double
>>>>>>> upstream/master

type: long

--

*`mysql.galera_status.flow_ctl.paused_ns`*::
+
--
<<<<<<< HEAD
Number of lock requests per second that required the caller to wait.

type: long

--

*`mssql.performance.user_connections`*::
+
--
Total number of user connections

=======
The total time spent in a paused state measured in nanoseconds.


>>>>>>> upstream/master
type: long

--

*`mysql.galera_status.flow_ctl.recv`*::
+
--
<<<<<<< HEAD
Total number of transactions

type: long

--

*`mssql.performance.active_temp_tables`*::
+
--
Number of temporary tables/table variables in use.

=======
Returns the number of FC_PAUSE events the node has received, including those the node has sent. Unlike most status variables, the counter for this one does not reset every time you run the query.


>>>>>>> upstream/master
type: long

--

*`mysql.galera_status.flow_ctl.sent`*::
+
--
<<<<<<< HEAD
Total number of logins started from the connection pool.

type: long

--

*`mssql.performance.logins_per_sec`*::
+
--
Total number of logins started per second. This does not include pooled connections.

=======
Returns the number of FC_PAUSE events the node has sent. Unlike most status variables, the counter for this one does not reset every time you run the query.


>>>>>>> upstream/master
type: long

--

*`mysql.galera_status.last_committed`*::
+
--
<<<<<<< HEAD
Total number of logout operations started per second.

type: long

--

*`mssql.performance.recompilations_per_sec`*::
+
--
Number of statement recompiles per second. Counts the number of times statement recompiles are triggered. Generally, you want the recompiles to be low.

=======
The sequence number, or seqno, of the last committed transaction.


>>>>>>> upstream/master
type: long

--

<<<<<<< HEAD
*`mssql.performance.compilations_per_sec`*::
+
--
Number of SQL compilations per second. Indicates the number of times the compile code path is entered. Includes compiles caused by statement-level recompilations in SQL Server. After SQL Server user activity is stable, this value reaches a steady state.

type: long

--
=======
[float]
=== local

Node specific Cluster status fields.

>>>>>>> upstream/master


*`mysql.galera_status.local.bf_aborts`*::
+
--
<<<<<<< HEAD
Number of Transact-SQL command batches received per second. This statistic is affected by all constraints (such as I/O, number of users, cache size, complexity of requests, and so on). High batch requests mean good throughput.
=======
Total number of local transactions that were aborted by slave transactions while in execution.


type: long
>>>>>>> upstream/master

type: long

--

*`mysql.galera_status.local.cert_failures`*::
+
--
Total number of local transactions that failed certification test.

<<<<<<< HEAD
[float]
=== cache_hit
=======
>>>>>>> upstream/master

type: long

--

*`mysql.galera_status.local.commits`*::
+
--
<<<<<<< HEAD
The ratio is the total number of cache hits divided by the total number of cache lookups over the last few thousand page accesses. After a long period of time, the ratio moves very little. Because reading from the cache is much less expensive than reading from disk, you want this ratio to be high
=======
Total number of local transactions committed.


type: long
>>>>>>> upstream/master

type: double

--

[float]
<<<<<<< HEAD
=== page_life_expectancy
=======
=== recv
>>>>>>> upstream/master

Node specific recv fields.



*`mysql.galera_status.local.recv.queue`*::
+
--
<<<<<<< HEAD
Indicates the number of seconds a page will stay in the buffer pool without references (in seconds).
=======
Current (instantaneous) length of the recv queue.


type: long
>>>>>>> upstream/master

type: long

--

*`mysql.galera_status.local.recv.queue_avg`*::
+
--
<<<<<<< HEAD
Indicates the number of pages flushed to disk per second by a checkpoint or other operation that require all dirty pages to be flushed.
=======
Recv queue length averaged over interval since the last FLUSH STATUS command. Values considerably larger than 0.0 mean that the node cannot apply write-sets as fast as they are received and will generate a lot of replication throttling.


type: double
>>>>>>> upstream/master

type: long

--

*`mysql.galera_status.local.recv.queue_max`*::
+
--
<<<<<<< HEAD
Indicates the number of pages in the buffer pool with database content.
=======
The maximum length of the recv queue since the last FLUSH STATUS command.


type: long
>>>>>>> upstream/master

type: long

--

*`mysql.galera_status.local.recv.queue_min`*::
+
--
<<<<<<< HEAD
Ideal number of pages in the buffer pool.

type: long

=======
The minimum length of the recv queue since the last FLUSH STATUS command.


type: long

--

*`mysql.galera_status.local.replays`*::
+
>>>>>>> upstream/master
--
Total number of transaction replays due to asymmetric lock granularity.

<<<<<<< HEAD
[float]
=== transaction_log
=======
>>>>>>> upstream/master

type: long

--

[float]
<<<<<<< HEAD
=== space_usage

Space usage information for the transaction log


[float]
=== since_last_backup
=======
=== send

Node specific sent fields.
>>>>>>> upstream/master



*`mysql.galera_status.local.send.queue`*::
+
--
<<<<<<< HEAD
The amount of space used since the last log backup in bytes

type: long

=======
Current (instantaneous) length of the send queue.


type: long

--

*`mysql.galera_status.local.send.queue_avg`*::
+
>>>>>>> upstream/master
--
Send queue length averaged over time since the last FLUSH STATUS command. Values considerably larger than 0.0 indicate replication throttling or network throughput issue.

<<<<<<< HEAD
[float]
=== total
=======
>>>>>>> upstream/master

type: double

--

*`mysql.galera_status.local.send.queue_max`*::
+
--
<<<<<<< HEAD
The size of the log in bytes

type: long

=======
The maximum length of the send queue since the last FLUSH STATUS command.


type: long

--

*`mysql.galera_status.local.send.queue_min`*::
+
>>>>>>> upstream/master
--
The minimum length of the send queue since the last FLUSH STATUS command.

<<<<<<< HEAD
[float]
=== used
=======
>>>>>>> upstream/master

type: long

--

*`mysql.galera_status.local.state`*::
+
--
<<<<<<< HEAD
The occupied size of the log in bytes
=======
Internal Galera Cluster FSM state number.


type: keyword
>>>>>>> upstream/master

type: long

--

*`mysql.galera_status.ready`*::
+
--
<<<<<<< HEAD
A percentage of the occupied size of the log as a percent of the total log size
=======
Whether the server is ready to accept queries.


type: keyword
>>>>>>> upstream/master

type: float

--

[float]
<<<<<<< HEAD
=== stats

Returns summary level attributes and information on transaction log files of databases. Use this information for monitoring and diagnostics of transaction log health.


[float]
=== active_size
=======
=== received

Write-Set receive status fields.
>>>>>>> upstream/master



*`mysql.galera_status.received.count`*::
+
--
<<<<<<< HEAD
Total active transaction log size in bytes

type: long

--
=======
Total number of write-sets received from other nodes.


type: long
>>>>>>> upstream/master

--
<<<<<<< HEAD
Last transaction log backup time.

type: date

--

[float]
=== recovery_size

Log size since log recovery log sequence number (LSN).


*`mssql.transaction_log.stats.recovery_size.bytes`*::
+
--
Log size in bytes since log recovery log sequence number (LSN).

=======

*`mysql.galera_status.received.bytes`*::
+
--
Total size of write-sets received from other nodes.


>>>>>>> upstream/master
type: long

--

[float]
<<<<<<< HEAD
=== since_last_checkpoint

Log size since last checkpoint log sequence number (LSN).
=======
=== repl
>>>>>>> upstream/master

Replication status fields.

<<<<<<< HEAD
*`mssql.transaction_log.stats.since_last_checkpoint.bytes`*::
+
--
Log size in bytes since last checkpoint log sequence number (LSN).

type: long

=======


*`mysql.galera_status.repl.data_bytes`*::
+
>>>>>>> upstream/master
--
Total size of data replicated.

<<<<<<< HEAD
[float]
=== total_size
=======
>>>>>>> upstream/master

type: long

--

*`mysql.galera_status.repl.keys`*::
+
--
<<<<<<< HEAD
Total transaction log size in bytes.
=======
Total number of keys replicated.


type: long
>>>>>>> upstream/master

type: long

--

*`mysql.galera_status.repl.keys_bytes`*::
+
--
Total size of keys replicated.


type: long

--

*`mysql.galera_status.repl.other_bytes`*::
+
--
<<<<<<< HEAD
Metrics exposed by a plugin of a munin node agent.
=======
Total size of other bits replicated.

>>>>>>> upstream/master

type: long

type: object

--

*`mysql.galera_status.repl.count`*::
+
--
<<<<<<< HEAD
Name of the plugin collecting these metrics.
=======
Total number of write-sets replicated (sent to other nodes).

>>>>>>> upstream/master

type: long

type: keyword

--

*`mysql.galera_status.repl.bytes`*::
+
--
Total size of write-sets replicated.


type: long

--

[float]
<<<<<<< HEAD
=== mysql
=======
=== status
>>>>>>> upstream/master

`status` contains the metrics that were obtained by the status SQL query.



[float]
<<<<<<< HEAD
=== galera_status
=======
=== aborted
>>>>>>> upstream/master

Aborted status fields.



<<<<<<< HEAD
[float]
=== apply
=======
*`mysql.status.aborted.clients`*::
+
--
The number of connections that were aborted because the client died without closing the connection properly.
>>>>>>> upstream/master


type: long

--

*`mysql.status.aborted.connects`*::
+
--
<<<<<<< HEAD
How often applier started write-set applying out-of-order (parallelization efficiency).
=======
The number of failed attempts to connect to the MySQL server.

>>>>>>> upstream/master

type: long

type: double

--

[float]
=== binlog




*`mysql.status.binlog.cache.disk_use`*::
+
--
<<<<<<< HEAD
How often write-set was so slow to apply that write-set with higher seqno's were applied earlier. Values closer to 0 refer to a greater gap between slow and fast write-sets.
=======

>>>>>>> upstream/master

type: long

type: double

--

*`mysql.status.binlog.cache.use`*::
+
--
<<<<<<< HEAD
Average distance between highest and lowest concurrently applied seqno.
=======

>>>>>>> upstream/master

type: long

type: double

--

[float]
<<<<<<< HEAD
=== cert
=======
=== bytes
>>>>>>> upstream/master

Bytes stats.



*`mysql.status.bytes.received`*::
+
--
<<<<<<< HEAD
Average distance between highest and lowest seqno value that can be possibly applied in parallel (potential degree of parallelization).


type: double

--

*`mysql.galera_status.cert.index_size`*::
+
--
The number of entries in the certification index.

=======
The number of bytes received from all clients.


type: long

format: bytes
>>>>>>> upstream/master

type: long

--

*`mysql.status.bytes.sent`*::
+
--
<<<<<<< HEAD
Average number of transactions received while a transaction replicates.
=======
The number of bytes sent to all clients.

>>>>>>> upstream/master

type: long

format: bytes

type: double

--

[float]
<<<<<<< HEAD
=== cluster
=======
=== threads
>>>>>>> upstream/master

Threads stats.



*`mysql.status.threads.cached`*::
+
--
<<<<<<< HEAD
Total number of cluster membership changes happened.


type: long

--

*`mysql.galera_status.cluster.size`*::
+
--
Current number of members in the cluster.


=======
The number of cached threads.


>>>>>>> upstream/master
type: long

--

*`mysql.status.threads.created`*::
+
--
<<<<<<< HEAD
Status of this cluster component. That is, whether the node is part of a PRIMARY or NON_PRIMARY component.


type: keyword

--

[float]
=== commit
=======
The number of created threads.
>>>>>>> upstream/master


type: long

--

*`mysql.status.threads.connected`*::
+
--
<<<<<<< HEAD
How often a transaction was committed out of order.
=======
The number of connected threads.

>>>>>>> upstream/master

type: long

type: double

--

*`mysql.status.threads.running`*::
+
--
<<<<<<< HEAD
Average distance between highest and lowest concurrently committed seqno.
=======
The number of running threads.

>>>>>>> upstream/master

type: long

type: long

--

*`mysql.status.connections`*::
+
--
<<<<<<< HEAD
If the value is OFF, the node has not yet connected to any of the cluster components. This may be due to misconfiguration. Check the error log for proper diagnostics.
=======

>>>>>>> upstream/master

type: long

type: keyword

--

[float]
<<<<<<< HEAD
=== evs
=======
=== created
>>>>>>> upstream/master




*`mysql.status.created.tmp.disk_tables`*::
+
--
<<<<<<< HEAD
Lists the UUID's of all nodes evicted from the cluster. Evicted nodes cannot rejoin the cluster until you restart their mysqld processes.
=======

>>>>>>> upstream/master

type: long

type: keyword

--

*`mysql.status.created.tmp.files`*::
+
--


type: long

--

*`mysql.status.created.tmp.tables`*::
+
--
<<<<<<< HEAD
Shows the internal state of the EVS Protocol.
=======

>>>>>>> upstream/master

type: long

type: keyword

--

[float]
<<<<<<< HEAD
=== flow_ctl
=======
=== delayed
>>>>>>> upstream/master




*`mysql.status.delayed.errors`*::
+
--
<<<<<<< HEAD
The fraction of time since the last FLUSH STATUS command that replication was paused due to flow control. In other words, how much the slave lag is slowing down the cluster.
=======

>>>>>>> upstream/master

type: long

type: double

--

*`mysql.status.delayed.insert_threads`*::
+
--
<<<<<<< HEAD
The total time spent in a paused state measured in nanoseconds.
=======

>>>>>>> upstream/master

type: long

type: long

--

*`mysql.status.delayed.writes`*::
+
--
<<<<<<< HEAD
Returns the number of FC_PAUSE events the node has received, including those the node has sent. Unlike most status variables, the counter for this one does not reset every time you run the query.
=======

>>>>>>> upstream/master

type: long

type: long

--

*`mysql.status.flush_commands`*::
+
--
<<<<<<< HEAD
Returns the number of FC_PAUSE events the node has sent. Unlike most status variables, the counter for this one does not reset every time you run the query.
=======

>>>>>>> upstream/master

type: long

type: long

--

*`mysql.status.max_used_connections`*::
+
--
<<<<<<< HEAD
The sequence number, or seqno, of the last committed transaction.
=======

>>>>>>> upstream/master

type: long

type: long

--

[float]
<<<<<<< HEAD
=== local
=======
=== open
>>>>>>> upstream/master




*`mysql.status.open.files`*::
+
--
<<<<<<< HEAD
Total number of local transactions that were aborted by slave transactions while in execution.
=======

>>>>>>> upstream/master

type: long

type: long

--

*`mysql.status.open.streams`*::
+
--
<<<<<<< HEAD
Total number of local transactions that failed certification test.
=======

>>>>>>> upstream/master

type: long

type: long

--

*`mysql.status.open.tables`*::
+
--
<<<<<<< HEAD
Total number of local transactions committed.
=======


type: long

--

*`mysql.status.opened_tables`*::
+
--
>>>>>>> upstream/master


type: long

--

[float]
<<<<<<< HEAD
=== recv
=======
=== command
>>>>>>> upstream/master




*`mysql.status.command.delete`*::
+
--
<<<<<<< HEAD
Current (instantaneous) length of the recv queue.
=======
The number of DELETE queries since startup.

>>>>>>> upstream/master

type: long

type: long

--

*`mysql.status.command.insert`*::
+
--
<<<<<<< HEAD
Recv queue length averaged over interval since the last FLUSH STATUS command. Values considerably larger than 0.0 mean that the node cannot apply write-sets as fast as they are received and will generate a lot of replication throttling.
=======
The number of INSERT queries since startup.

>>>>>>> upstream/master

type: long

type: double

--

*`mysql.status.command.select`*::
+
--
<<<<<<< HEAD
The maximum length of the recv queue since the last FLUSH STATUS command.
=======
The number of SELECT queries since startup.

>>>>>>> upstream/master

type: long

type: long

--

*`mysql.status.command.update`*::
+
--
<<<<<<< HEAD
The minimum length of the recv queue since the last FLUSH STATUS command.
=======
The number of UPDATE queries since startup.

>>>>>>> upstream/master

type: long

type: long

--

*`mysql.status.queries`*::
+
--
<<<<<<< HEAD
Total number of transaction replays due to asymmetric lock granularity.
=======
The number of statements executed by the server. This variable includes statements executed within stored programs, unlike the Questions variable. It does not count COM_PING or COM_STATISTICS commands.


type: long

--

*`mysql.status.questions`*::
+
--
The number of statements executed by the server. This includes only statements sent to the server by clients and not statements executed within stored programs, unlike the Queries variable. This variable does not count COM_PING, COM_STATISTICS, COM_STMT_PREPARE, COM_STMT_CLOSE, or COM_STMT_RESET commands.

>>>>>>> upstream/master

type: long

type: long

--

[float]
<<<<<<< HEAD
=== send
=======
=== handler
>>>>>>> upstream/master




*`mysql.status.handler.commit`*::
+
--
<<<<<<< HEAD
Current (instantaneous) length of the send queue.
=======
The number of internal COMMIT statements.

>>>>>>> upstream/master

type: long

type: long

--

*`mysql.status.handler.delete`*::
+
--
<<<<<<< HEAD
Send queue length averaged over time since the last FLUSH STATUS command. Values considerably larger than 0.0 indicate replication throttling or network throughput issue.
=======
The number of times that rows have been deleted from tables.

>>>>>>> upstream/master

type: long

type: double

--

*`mysql.status.handler.external_lock`*::
+
--
<<<<<<< HEAD
The maximum length of the send queue since the last FLUSH STATUS command.
=======
The server increments this variable for each call to its external_lock() function, which generally occurs at the beginning and end of access to a table instance.

>>>>>>> upstream/master

type: long

type: long

--

*`mysql.status.handler.mrr_init`*::
+
--
<<<<<<< HEAD
The minimum length of the send queue since the last FLUSH STATUS command.
=======
The number of times the server uses a storage engine's own Multi-Range Read implementation for table access.

>>>>>>> upstream/master

type: long

type: long

--

*`mysql.status.handler.prepare`*::
+
--
<<<<<<< HEAD
Internal Galera Cluster FSM state number.
=======
A counter for the prepare phase of two-phase commit operations.

>>>>>>> upstream/master

type: long

type: keyword

--

[float]
=== read




*`mysql.status.handler.read.first`*::
+
--
<<<<<<< HEAD
Whether the server is ready to accept queries.
=======
The number of times the first entry in an index was read.

>>>>>>> upstream/master

type: long

type: keyword

--

<<<<<<< HEAD
[float]
=== received
=======
*`mysql.status.handler.read.key`*::
+
--
The number of requests to read a row based on a key.
>>>>>>> upstream/master


type: long

--

*`mysql.status.handler.read.last`*::
+
--
<<<<<<< HEAD
Total number of write-sets received from other nodes.
=======
The number of requests to read the last key in an index. 

>>>>>>> upstream/master

type: long

type: long

--

*`mysql.status.handler.read.next`*::
+
--
<<<<<<< HEAD
Total size of write-sets received from other nodes.
=======
The number of requests to read the next row in key order.

>>>>>>> upstream/master

type: long

type: long

--

<<<<<<< HEAD
[float]
=== repl
=======
*`mysql.status.handler.read.prev`*::
+
--
The number of requests to read the previous row in key order.
>>>>>>> upstream/master


type: long

--

*`mysql.status.handler.read.rnd`*::
+
--
<<<<<<< HEAD
Total size of data replicated.
=======
The number of requests to read a row based on a fixed position. 

>>>>>>> upstream/master

type: long

type: long

--

*`mysql.status.handler.read.rnd_next`*::
+
--
<<<<<<< HEAD
Total number of keys replicated.
=======
The number of requests to read the next row in the data file. 

>>>>>>> upstream/master

type: long

type: long

--

*`mysql.status.handler.rollback`*::
+
--
<<<<<<< HEAD
Total size of keys replicated.
=======
The number of requests for a storage engine to perform a rollback operation.

>>>>>>> upstream/master

type: long

type: long

--

*`mysql.status.handler.savepoint`*::
+
--
<<<<<<< HEAD
Total size of other bits replicated.
=======
The number of requests for a storage engine to place a savepoint.

>>>>>>> upstream/master

type: long

type: long

--

*`mysql.status.handler.savepoint_rollback`*::
+
--
<<<<<<< HEAD
Total number of write-sets replicated (sent to other nodes).
=======
The number of requests for a storage engine to roll back to a savepoint.

>>>>>>> upstream/master

type: long

type: long

--

*`mysql.status.handler.update`*::
+
--
<<<<<<< HEAD
Total size of write-sets replicated.
=======
The number of requests to update a row in a table.


type: long

--

*`mysql.status.handler.write`*::
+
--
The number of requests to insert a row in a table.

>>>>>>> upstream/master

type: long

type: long

--

[float]
<<<<<<< HEAD
=== status
=======
=== innodb
>>>>>>> upstream/master




[float]
<<<<<<< HEAD
=== aborted
=======
=== buffer_pool
>>>>>>> upstream/master




*`mysql.status.innodb.buffer_pool.dump_status`*::
+
--
<<<<<<< HEAD
The number of connections that were aborted because the client died without closing the connection properly.
=======
The progress of an operation to record the pages held in the InnoDB buffer pool, triggered by the setting of innodb_buffer_pool_dump_at_shutdown or innodb_buffer_pool_dump_now.

>>>>>>> upstream/master

type: long

type: long

--

*`mysql.status.innodb.buffer_pool.load_status`*::
+
--
<<<<<<< HEAD
The number of failed attempts to connect to the MySQL server.
=======
The progress of an operation to warm up the InnoDB buffer pool by reading in a set of pages corresponding to an earlier point in time, triggered by the setting of innodb_buffer_pool_load_at_startup or innodb_buffer_pool_load_now.

>>>>>>> upstream/master

type: long

type: long

--

[float]
<<<<<<< HEAD
=== binlog
=======
=== bytes
>>>>>>> upstream/master




*`mysql.status.innodb.buffer_pool.bytes.data`*::
+
--
<<<<<<< HEAD
=======
The total number of bytes in the InnoDB buffer pool containing data. 
>>>>>>> upstream/master


type: long

--

*`mysql.status.innodb.buffer_pool.bytes.dirty`*::
+
--
<<<<<<< HEAD
=======
The total current number of bytes held in dirty pages in the InnoDB buffer pool.
>>>>>>> upstream/master


type: long

--

[float]
<<<<<<< HEAD
=== bytes
=======
=== pages
>>>>>>> upstream/master




*`mysql.status.innodb.buffer_pool.pages.data`*::
+
--
<<<<<<< HEAD
The number of bytes received from all clients.


type: long

format: bytes
=======
he number of pages in the InnoDB buffer pool containing data.


type: long
>>>>>>> upstream/master

--

*`mysql.status.innodb.buffer_pool.pages.dirty`*::
+
--
<<<<<<< HEAD
The number of bytes sent to all clients.


type: long

format: bytes

--

[float]
=== threads

Threads stats.



*`mysql.status.threads.cached`*::
+
--
The number of cached threads.
=======
The current number of dirty pages in the InnoDB buffer pool.


type: long

--

*`mysql.status.innodb.buffer_pool.pages.flushed`*::
+
--
The number of requests to flush pages from the InnoDB buffer pool.

>>>>>>> upstream/master

type: long

type: long

--

*`mysql.status.innodb.buffer_pool.pages.free`*::
+
--
<<<<<<< HEAD
The number of created threads.
=======
The number of free pages in the InnoDB buffer pool.

>>>>>>> upstream/master

type: long

type: long

--

*`mysql.status.innodb.buffer_pool.pages.latched`*::
+
--
<<<<<<< HEAD
The number of connected threads.
=======
The number of latched pages in the InnoDB buffer pool.

>>>>>>> upstream/master

type: long

type: long

--

*`mysql.status.innodb.buffer_pool.pages.misc`*::
+
--
<<<<<<< HEAD
The number of running threads.
=======
The number of pages in the InnoDB buffer pool that are busy because they have been allocated for administrative overhead, such as row locks or the adaptive hash index.

>>>>>>> upstream/master

type: long

type: long

--

*`mysql.status.innodb.buffer_pool.pages.total`*::
+
--
<<<<<<< HEAD
=======
The total size of the InnoDB buffer pool, in pages.
>>>>>>> upstream/master


type: long

--

[float]
<<<<<<< HEAD
=== created
=======
=== read
>>>>>>> upstream/master




*`mysql.status.innodb.buffer_pool.read.ahead`*::
+
--
<<<<<<< HEAD
=======
The number of pages read into the InnoDB buffer pool by the read-ahead background thread.
>>>>>>> upstream/master


type: long

--

*`mysql.status.innodb.buffer_pool.read.ahead_evicted`*::
+
--
<<<<<<< HEAD
=======
The number of pages read into the InnoDB buffer pool by the read-ahead background thread that were subsequently evicted without having been accessed by queries.
>>>>>>> upstream/master


type: long

--

*`mysql.status.innodb.buffer_pool.read.ahead_rnd`*::
+
--
<<<<<<< HEAD
=======
The number of "random" read-aheads initiated by InnoDB.


type: long
>>>>>>> upstream/master

--

*`mysql.status.innodb.buffer_pool.read.requests`*::
+
--
The number of logical read requests.

type: long

type: long

--

[float]
<<<<<<< HEAD
=== delayed
=======
=== pool
>>>>>>> upstream/master




*`mysql.status.innodb.buffer_pool.pool.reads`*::
+
--
<<<<<<< HEAD
=======
The number of logical reads that InnoDB could not satisfy from the buffer pool, and had to read directly from disk.
>>>>>>> upstream/master


type: long

--

*`mysql.status.innodb.buffer_pool.pool.resize_status`*::
+
--
<<<<<<< HEAD
=======
The status of an operation to resize the InnoDB buffer pool dynamically, triggered by setting the innodb_buffer_pool_size parameter dynamically.
>>>>>>> upstream/master


type: long

--

*`mysql.status.innodb.buffer_pool.pool.wait_free`*::
+
--
<<<<<<< HEAD
=======
Normally, writes to the InnoDB buffer pool happen in the background. When InnoDB needs to read or create a page and no clean pages are available, InnoDB flushes some dirty pages first and waits for that operation to finish. This counter counts instances of these waits.
>>>>>>> upstream/master


type: long

--

*`mysql.status.innodb.buffer_pool.write_requests`*::
+
--
<<<<<<< HEAD
=======
The number of writes done to the InnoDB buffer pool.
>>>>>>> upstream/master


type: long

--

<<<<<<< HEAD
*`mysql.status.max_used_connections`*::
+
--
=======
[[exported-fields-nats]]
== Nats fields
>>>>>>> upstream/master

nats Module

type: long


[float]
<<<<<<< HEAD
=== open
=======
=== nats
>>>>>>> upstream/master

`nats` contains statistics that were read from Nats



*`nats.server.id`*::
+
--
<<<<<<< HEAD


type: long
=======
The server ID


type: keyword
>>>>>>> upstream/master

--

*`nats.server.time`*::
+
--
<<<<<<< HEAD


type: long
=======
Server time of metric creation


type: date
>>>>>>> upstream/master

--

[float]
=== connections

Contains nats connection related metrics



*`nats.connections.total`*::
+
--
<<<<<<< HEAD


type: long
=======
The number of currently active clients


type: integer
>>>>>>> upstream/master

--

[float]
=== routes

Contains nats route related metrics



*`nats.routes.total`*::
+
--
<<<<<<< HEAD


type: long
=======
The number of registered routes


type: integer
>>>>>>> upstream/master

--

[float]
<<<<<<< HEAD
=== command
=======
=== stats
>>>>>>> upstream/master

Contains nats var related metrics



*`nats.stats.uptime`*::
+
--
<<<<<<< HEAD
The number of DELETE queries since startup.
=======
The period the server is up (sec)

>>>>>>> upstream/master

type: long

format: duration

type: long

--

*`nats.stats.mem.bytes`*::
+
--
<<<<<<< HEAD
The number of INSERT queries since startup.


type: long
=======
The current memory usage of NATS process


type: long

format: bytes

--

*`nats.stats.cores`*::
+
--
The number of logical cores the NATS process runs on


type: integer
>>>>>>> upstream/master

--

*`nats.stats.cpu`*::
+
--
<<<<<<< HEAD
The number of SELECT queries since startup.
=======
The current cpu usage of NATs process

>>>>>>> upstream/master

type: scaled_float

format: percent

type: long

--

*`nats.stats.total_connections`*::
+
--
<<<<<<< HEAD
The number of UPDATE queries since startup.
=======
The number of totally created clients

>>>>>>> upstream/master

type: long

type: long

--

*`nats.stats.remotes`*::
+
--
The number of registered remotes


type: integer

--

[float]
<<<<<<< HEAD
=== nats
=======
=== in
>>>>>>> upstream/master

The amount of incoming data



*`nats.stats.in.messages`*::
+
--
<<<<<<< HEAD
The server ID
=======
The amount of incoming messages

>>>>>>> upstream/master

type: long

type: keyword

--

*`nats.stats.in.bytes`*::
+
--
<<<<<<< HEAD
Server time of metric creation
=======
The amount of incoming bytes

>>>>>>> upstream/master

type: long

format: bytes

type: date

--

[float]
<<<<<<< HEAD
=== connections
=======
=== out
>>>>>>> upstream/master

The amount of outgoing data



*`nats.stats.out.messages`*::
+
--
<<<<<<< HEAD
The number of currently active clients
=======
The amount of outgoing messages

>>>>>>> upstream/master

type: long

type: integer

--

<<<<<<< HEAD
[float]
=== routes
=======
*`nats.stats.out.bytes`*::
+
--
The amount of outgoing bytes
>>>>>>> upstream/master


type: long

format: bytes

--

*`nats.stats.slow_consumers`*::
+
--
<<<<<<< HEAD
The number of registered routes
=======
The number of slow consumers currently on NATS

>>>>>>> upstream/master

type: long

type: integer

--

[float]
<<<<<<< HEAD
=== stats
=======
=== http
>>>>>>> upstream/master

The http metrics of NATS server



<<<<<<< HEAD
*`nats.stats.uptime`*::
+
--
The period the server is up (sec)


type: long
=======
[float]
=== req_stats

The requests statistics

>>>>>>> upstream/master

format: duration

[float]
=== uri

The request distribution on monitoring URIS



*`nats.stats.http.req_stats.uri.routez`*::
+
--
<<<<<<< HEAD
The current memory usage of NATS process


type: long

format: bytes
=======
The number of hits on routez monitoring uri


type: long
>>>>>>> upstream/master

--

*`nats.stats.http.req_stats.uri.connz`*::
+
--
<<<<<<< HEAD
The number of logical cores the NATS process runs on
=======
The number of hits on connz monitoring uri

>>>>>>> upstream/master

type: long

type: integer

--

*`nats.stats.http.req_stats.uri.varz`*::
+
--
<<<<<<< HEAD
The current cpu usage of NATs process


type: scaled_float

format: percent
=======
The number of hits on varz monitoring uri


type: long
>>>>>>> upstream/master

--

*`nats.stats.http.req_stats.uri.subsz`*::
+
--
<<<<<<< HEAD
The number of totally created clients
=======
The number of hits on subsz monitoring uri

>>>>>>> upstream/master

type: long

type: long

--

*`nats.stats.http.req_stats.uri.root`*::
+
--
<<<<<<< HEAD
The number of registered remotes
=======
The number of hits on root monitoring uri

>>>>>>> upstream/master

type: long

type: integer

--

[float]
<<<<<<< HEAD
=== in
=======
=== subscriptions
>>>>>>> upstream/master

Contains nats subscriptions related metrics



*`nats.subscriptions.total`*::
+
--
<<<<<<< HEAD
The amount of incoming messages
=======
The number of active subscriptions

>>>>>>> upstream/master

type: integer

type: long

--

*`nats.subscriptions.inserts`*::
+
--
<<<<<<< HEAD
The amount of incoming bytes


type: long

format: bytes

--

[float]
=== out
=======
The number of insert operations in subscriptions list


type: long

--

*`nats.subscriptions.removes`*::
+
--
The number of remove operations in subscriptions list


type: long

--

*`nats.subscriptions.matches`*::
+
--
The number of times a match is found for a subscription
>>>>>>> upstream/master


type: long

--

*`nats.subscriptions.cache.size`*::
+
--
<<<<<<< HEAD
The amount of outgoing messages
=======
The number of result sets in the cache

>>>>>>> upstream/master

type: integer

type: long

--

*`nats.subscriptions.cache.hit_rate`*::
+
--
<<<<<<< HEAD
The amount of outgoing bytes


type: long

format: bytes
=======
The rate matches are being retrieved from cache


type: scaled_float

format: percent

--

*`nats.subscriptions.cache.fanout.max`*::
+
--
The maximum fanout served by cache


type: integer
>>>>>>> upstream/master

--

*`nats.subscriptions.cache.fanout.avg`*::
+
--
<<<<<<< HEAD
The number of slow consumers currently on NATS
=======
The average fanout served by cache

>>>>>>> upstream/master

type: double

type: long

--

<<<<<<< HEAD
[float]
=== http
=======
[[exported-fields-nginx]]
== Nginx fields
>>>>>>> upstream/master

Nginx server status metrics collected from various modules.



[float]
<<<<<<< HEAD
=== req_stats
=======
=== nginx
>>>>>>> upstream/master

`nginx` contains the metrics that were scraped from nginx.



[float]
<<<<<<< HEAD
=== uri
=======
=== stubstatus
>>>>>>> upstream/master

`stubstatus` contains the metrics that were scraped from the ngx_http_stub_status_module status page.



*`nginx.stubstatus.hostname`*::
+
--
<<<<<<< HEAD
The number of hits on routez monitoring uri
=======
Nginx hostname.

>>>>>>> upstream/master

type: keyword

type: long

--

*`nginx.stubstatus.active`*::
+
--
<<<<<<< HEAD
The number of hits on connz monitoring uri
=======
The current number of active client connections including Waiting connections.

>>>>>>> upstream/master

type: long

type: long

--

*`nginx.stubstatus.accepts`*::
+
--
<<<<<<< HEAD
The number of hits on varz monitoring uri
=======
The total number of accepted client connections.

>>>>>>> upstream/master

type: long

type: long

--

*`nginx.stubstatus.handled`*::
+
--
<<<<<<< HEAD
The number of hits on subsz monitoring uri
=======
The total number of handled client connections.

>>>>>>> upstream/master

type: long

type: long

--

*`nginx.stubstatus.dropped`*::
+
--
<<<<<<< HEAD
The number of hits on root monitoring uri
=======
The total number of dropped client connections.

>>>>>>> upstream/master

type: long

type: long

--

<<<<<<< HEAD
[float]
=== subscriptions

Contains nats subscriptions related metrics



*`nats.subscriptions.total`*::
+
--
The number of active subscriptions
=======
*`nginx.stubstatus.requests`*::
+
--
The total number of client requests.

>>>>>>> upstream/master

type: long

type: integer

--

*`nginx.stubstatus.current`*::
+
--
<<<<<<< HEAD
The number of insert operations in subscriptions list
=======
The current number of client requests.

>>>>>>> upstream/master

type: long

type: long

--

*`nginx.stubstatus.reading`*::
+
--
<<<<<<< HEAD
The number of remove operations in subscriptions list
=======
The current number of connections where Nginx is reading the request header.

>>>>>>> upstream/master

type: long

type: long

--

*`nginx.stubstatus.writing`*::
+
--
<<<<<<< HEAD
The number of times a match is found for a subscription
=======
The current number of connections where Nginx is writing the response back to the client.

>>>>>>> upstream/master

type: long

type: long

--

*`nginx.stubstatus.waiting`*::
+
--
<<<<<<< HEAD
The number of result sets in the cache
=======
The current number of idle client connections waiting for a request.

>>>>>>> upstream/master

type: long

type: integer

--

<<<<<<< HEAD
*`nats.subscriptions.cache.hit_rate`*::
+
--
The rate matches are being retrieved from cache


type: scaled_float

format: percent
=======
[[exported-fields-oracle]]
== Oracle fields

Oracle database module


[float]
=== oracle
>>>>>>> upstream/master

Oracle module

<<<<<<< HEAD
*`nats.subscriptions.cache.fanout.max`*::
+
--
The maximum fanout served by cache
=======

[float]
=== tablespace
>>>>>>> upstream/master

tablespace

<<<<<<< HEAD
type: integer

--
=======
>>>>>>> upstream/master

*`oracle.tablespace.name`*::
+
--
<<<<<<< HEAD
The average fanout served by cache
=======
Tablespace name
>>>>>>> upstream/master

type: keyword

type: double

--

[float]
<<<<<<< HEAD
=== nginx

`nginx` contains the metrics that were scraped from nginx.

=======
=== data_file
>>>>>>> upstream/master

Database files information

<<<<<<< HEAD
[float]
=== stubstatus
=======
>>>>>>> upstream/master

*`oracle.tablespace.data_file.id`*::
+
--
Tablespace unique identifier

type: long

--

*`oracle.tablespace.data_file.name`*::
+
--
<<<<<<< HEAD
Nginx hostname.
=======
Filename of the data file

type: keyword

--
>>>>>>> upstream/master

[float]
=== size

<<<<<<< HEAD
type: keyword

--
=======
Size information about the file
>>>>>>> upstream/master


*`oracle.tablespace.data_file.size.max.bytes`*::
+
--
<<<<<<< HEAD
The current number of active client connections including Waiting connections.
=======
Maximum file size in bytes

type: long
>>>>>>> upstream/master

format: bytes

type: long

--

*`oracle.tablespace.data_file.size.bytes`*::
+
--
<<<<<<< HEAD
The total number of accepted client connections.
=======
Size of the file in bytes

type: long
>>>>>>> upstream/master

format: bytes

type: long

--

*`oracle.tablespace.data_file.size.free.bytes`*::
+
--
<<<<<<< HEAD
The total number of handled client connections.
=======
The size of the file available for user data. The actual size of the file minus this value is used to store file related metadata.

>>>>>>> upstream/master

type: long

format: bytes

type: long

--

*`oracle.tablespace.data_file.status`*::
+
--
<<<<<<< HEAD
The total number of dropped client connections.
=======
'File status: AVAILABLE or INVALID (INVALID means that the file number is not in use, for example, a file in a tablespace that was dropped)'

>>>>>>> upstream/master

type: keyword

type: long

--

*`oracle.tablespace.data_file.online_status`*::
+
--
<<<<<<< HEAD
The total number of client requests.


type: long

--
=======
Last known online status of the data file. One of SYSOFF, SYSTEM, OFFLINE, ONLINE or RECOVER.

type: keyword
>>>>>>> upstream/master

--
<<<<<<< HEAD
The current number of client requests.
=======

[float]
=== space
>>>>>>> upstream/master

Tablespace space usage information

<<<<<<< HEAD
type: long

--
=======
>>>>>>> upstream/master

*`oracle.tablespace.space.free.bytes`*::
+
--
<<<<<<< HEAD
The current number of connections where Nginx is reading the request header.
=======
Tablespace total free space available, in bytes.

type: long
>>>>>>> upstream/master

format: bytes

type: long

--

*`oracle.tablespace.space.used.bytes`*::
+
--
<<<<<<< HEAD
The current number of connections where Nginx is writing the response back to the client.
=======
Tablespace used space, in bytes.

type: long
>>>>>>> upstream/master

format: bytes

type: long

--

*`oracle.tablespace.space.total.bytes`*::
+
--
<<<<<<< HEAD
The current number of idle client connections waiting for a request.
=======
Tablespace total size, in bytes.

type: long
>>>>>>> upstream/master

format: bytes

type: long

--

[[exported-fields-php_fpm]]
== PHP_FPM fields

PHP-FPM server status metrics collected from PHP-FPM.



[float]
=== php_fpm

`php_fpm` contains the metrics that were obtained from PHP-FPM status page call.



[float]
=== pool

`pool` contains the metrics that were obtained from the PHP-FPM process pool.



*`php_fpm.pool.name`*::
+
--
The name of the pool.


type: keyword

--

[float]
=== pool

`pool` contains the metrics that were obtained from the PHP-FPM process pool.



*`php_fpm.pool.process_manager`*::
+
--
Static, dynamic or ondemand.


type: keyword

--

[float]
=== connections

Connection state specific statistics.



*`php_fpm.pool.connections.accepted`*::
+
--
The number of incoming requests that the PHP-FPM server has accepted; when a connection is accepted it is removed from the listen queue.


type: long

--

*`php_fpm.pool.connections.queued`*::
+
--
The current number of connections that have been initiated, but not yet accepted. If this value is non-zero it typically means that all the available server processes are currently busy, and there are no processes available to serve the next request. Raising `pm.max_children` (provided the server can handle it) should help keep this number low. This property follows from the fact that PHP-FPM listens via a socket (TCP or file based), and thus inherits some of the characteristics of sockets.


type: long

--

*`php_fpm.pool.connections.max_listen_queue`*::
+
--
The maximum number of requests in the queue of pending connections since FPM has started.


type: long

--

*`php_fpm.pool.connections.listen_queue_len`*::
+
--
The size of the socket queue of pending connections.


type: long

--

[float]
=== processes

Process state specific statistics.



*`php_fpm.pool.processes.idle`*::
+
--
The number of servers in the `waiting to process` state (i.e. not currently serving a page). This value should fall between the `pm.min_spare_servers` and `pm.max_spare_servers` values when the process manager is `dynamic`.


type: long

--

*`php_fpm.pool.processes.active`*::
+
--
The number of servers current processing a page - the minimum is `1` (so even on a fully idle server, the result will be not read `0`).


type: long

--

*`php_fpm.pool.processes.total`*::
+
--
The number of idle + active processes.


type: long

--

*`php_fpm.pool.processes.max_active`*::
+
--
The maximum number of active processes since FPM has started.


type: long

--

*`php_fpm.pool.processes.max_children_reached`*::
+
--
Number of times, the process limit has been reached, when pm tries to start more children (works only for pm 'dynamic' and 'ondemand').


type: long

--

*`php_fpm.pool.slow_requests`*::
+
--
The number of times a request execution time has exceeded `request_slowlog_timeout`.


type: long

--

*`php_fpm.pool.start_since`*::
+
--
Number of seconds since FPM has started.


type: long

--

*`php_fpm.pool.start_time`*::
+
--
The date and time FPM has started.
<<<<<<< HEAD


type: date
=======
>>>>>>> upstream/master

format: epoch_second

type: date

--

[float]
=== process

process contains the metrics that were obtained from the PHP-FPM process.



*`php_fpm.process.pid`*::
+
--
The PID of the process


type: alias

alias to: process.pid

--

*`php_fpm.process.state`*::
+
--
The state of the process (Idle, Running, etc)


type: keyword

--

*`php_fpm.process.start_time`*::
+
--
The date and time the process has started
<<<<<<< HEAD


type: date
=======
>>>>>>> upstream/master

format: epoch_second

type: date

--

*`php_fpm.process.start_since`*::
+
--
The number of seconds since the process has started


type: integer

--

*`php_fpm.process.requests`*::
+
--
The number of requests the process has served


type: integer

--

*`php_fpm.process.request_duration`*::
+
--
The duration in microseconds (1 million in a second) of the current request (my own definition)


type: integer

--

*`php_fpm.process.request_method`*::
+
--
The request method (GET, POST, etc) (of the current request)


type: alias

alias to: http.request.method

--

*`php_fpm.process.request_uri`*::
+
--
The request URI with the query string (of the current request)


type: alias

alias to: url.original

--

*`php_fpm.process.content_length`*::
+
--
The content length of the request (only with POST) (of the current request)


type: alias

alias to: http.response.body.bytes

--

*`php_fpm.process.user`*::
+
--
The user (PHP_AUTH_USER) (or - if not set) (for the current request)


type: alias

alias to: user.name

--

*`php_fpm.process.script`*::
+
--
The main script called (or - if not set) (for the current request)


type: keyword

--

*`php_fpm.process.last_request_cpu`*::
+
--
The max amount of memory the last request consumed (it is always 0 if the process is not in Idle state because memory calculation is done when the request processing has terminated)


type: long

--

*`php_fpm.process.last_request_memory`*::
+
--
The content length of the request (only with POST) (of the current request)


type: integer

--

[[exported-fields-postgresql]]
== PostgreSQL fields

Metrics collected from PostgreSQL servers.



[float]
=== postgresql

PostgreSQL metrics.



[float]
=== activity

One document per server process, showing information related to the current activity of that process, such as state and current query. Collected by querying pg_stat_activity.



*`postgresql.activity.database.oid`*::
+
--
OID of the database this backend is connected to.


type: long

--

*`postgresql.activity.database.name`*::
+
--
Name of the database this backend is connected to.


type: keyword

--

*`postgresql.activity.pid`*::
+
--
Process ID of this backend.


type: long

--

*`postgresql.activity.user.id`*::
+
--
OID of the user logged into this backend.


type: long

--

*`postgresql.activity.user.name`*::
+
--
Name of the user logged into this backend.


--

*`postgresql.activity.application_name`*::
+
--
Name of the application that is connected to this backend.


--

*`postgresql.activity.client.address`*::
+
--
IP address of the client connected to this backend.


--

*`postgresql.activity.client.hostname`*::
+
--
Host name of the connected client, as reported by a reverse DNS lookup of client_addr.


--

*`postgresql.activity.client.port`*::
+
--
TCP port number that the client is using for communication with this backend, or -1 if a Unix socket is used.


type: long

--

*`postgresql.activity.backend_start`*::
+
--
Time when this process was started, i.e., when the client connected to the server.


type: date

--

*`postgresql.activity.transaction_start`*::
+
--
Time when this process' current transaction was started.


type: date

--

*`postgresql.activity.query_start`*::
+
--
Time when the currently active query was started, or if state is not active, when the last query was started.


type: date

--

*`postgresql.activity.state_change`*::
+
--
Time when the state was last changed.


type: date

--

*`postgresql.activity.waiting`*::
+
--
True if this backend is currently waiting on a lock.


type: boolean

--

*`postgresql.activity.state`*::
+
--
Current overall state of this backend. Possible values are:

  * active: The backend is executing a query.
  * idle: The backend is waiting for a new client command.
  * idle in transaction: The backend is in a transaction, but is not
    currently executing a query.
  * idle in transaction (aborted): This state is similar to idle in
    transaction, except one of the statements in the transaction caused
    an error.
  * fastpath function call: The backend is executing a fast-path function.
  * disabled: This state is reported if track_activities is disabled in this backend.


--

*`postgresql.activity.query`*::
+
--
Text of this backend's most recent query. If state is active this field shows the currently executing query. In all other states, it shows the last query that was executed.


--

[float]
=== bgwriter

Statistics about the background writer process's activity. Collected using the pg_stat_bgwriter query.



*`postgresql.bgwriter.checkpoints.scheduled`*::
+
--
Number of scheduled checkpoints that have been performed.


type: long

--

*`postgresql.bgwriter.checkpoints.requested`*::
+
--
Number of requested checkpoints that have been performed.


type: long

--

*`postgresql.bgwriter.checkpoints.times.write.ms`*::
+
--
Total amount of time that has been spent in the portion of checkpoint processing where files are written to disk, in milliseconds.


type: float

--

*`postgresql.bgwriter.checkpoints.times.sync.ms`*::
+
--
Total amount of time that has been spent in the portion of checkpoint processing where files are synchronized to disk, in milliseconds.


type: float

--

*`postgresql.bgwriter.buffers.checkpoints`*::
+
--
Number of buffers written during checkpoints.


type: long

--

*`postgresql.bgwriter.buffers.clean`*::
+
--
Number of buffers written by the background writer.


type: long

--

*`postgresql.bgwriter.buffers.clean_full`*::
+
--
Number of times the background writer stopped a cleaning scan because it had written too many buffers.


type: long

--

*`postgresql.bgwriter.buffers.backend`*::
+
--
Number of buffers written directly by a backend.


type: long

--

*`postgresql.bgwriter.buffers.backend_fsync`*::
+
--
Number of times a backend had to execute its own fsync call (normally the background writer handles those even when the backend does its own write)


type: long

--

*`postgresql.bgwriter.buffers.allocated`*::
+
--
Number of buffers allocated.


type: long

--

*`postgresql.bgwriter.stats_reset`*::
+
--
Time at which these statistics were last reset.


type: date

--

[float]
=== database

One row per database, showing database-wide statistics. Collected by querying pg_stat_database



*`postgresql.database.oid`*::
+
--
OID of the database this backend is connected to.


type: long

--

*`postgresql.database.name`*::
+
--
Name of the database this backend is connected to.


type: keyword

--

*`postgresql.database.number_of_backends`*::
+
--
Number of backends currently connected to this database.


type: long

--

*`postgresql.database.transactions.commit`*::
+
--
Number of transactions in this database that have been committed.


type: long

--

*`postgresql.database.transactions.rollback`*::
+
--
Number of transactions in this database that have been rolled back.


type: long

--

*`postgresql.database.blocks.read`*::
+
--
Number of disk blocks read in this database.


type: long

--

*`postgresql.database.blocks.hit`*::
+
--
Number of times disk blocks were found already in the buffer cache, so that a read was not necessary (this only includes hits in the PostgreSQL buffer cache, not the operating system's file system cache).


type: long

--

*`postgresql.database.blocks.time.read.ms`*::
+
--
Time spent reading data file blocks by backends in this database, in milliseconds.


type: long

--

*`postgresql.database.blocks.time.write.ms`*::
+
--
Time spent writing data file blocks by backends in this database, in milliseconds.


type: long

--

*`postgresql.database.rows.returned`*::
+
--
Number of rows returned by queries in this database.


type: long

--

*`postgresql.database.rows.fetched`*::
+
--
Number of rows fetched by queries in this database.


type: long

--

*`postgresql.database.rows.inserted`*::
+
--
Number of rows inserted by queries in this database.


type: long

--

*`postgresql.database.rows.updated`*::
+
--
Number of rows updated by queries in this database.


type: long

--

*`postgresql.database.rows.deleted`*::
+
--
Number of rows deleted by queries in this database.


type: long

--

*`postgresql.database.conflicts`*::
+
--
Number of queries canceled due to conflicts with recovery in this database.


type: long

--

*`postgresql.database.temporary.files`*::
+
--
Number of temporary files created by queries in this database. All temporary files are counted, regardless of why the temporary file was created (e.g., sorting or hashing), and regardless of the log_temp_files setting.


type: long

--

*`postgresql.database.temporary.bytes`*::
+
--
Total amount of data written to temporary files by queries in this database. All temporary files are counted, regardless of why the temporary file was created, and regardless of the log_temp_files setting.


type: long

--

*`postgresql.database.deadlocks`*::
+
--
Number of deadlocks detected in this database.


type: long

--

*`postgresql.database.stats_reset`*::
+
--
Time at which these statistics were last reset.


type: date

--

[float]
=== statement

One document per query per user per database, showing information related invocation of that query, such as cpu usage and total time. Collected by querying pg_stat_statements.



*`postgresql.statement.user.id`*::
+
--
OID of the user logged into the backend that ran the query.


type: long

--

*`postgresql.statement.database.oid`*::
+
--
OID of the database the query was run on.


type: long

--

*`postgresql.statement.query.id`*::
+
--
ID of the statement.


type: long

--

*`postgresql.statement.query.text`*::
+
--
Query text


--

*`postgresql.statement.query.calls`*::
+
--
Number of times the query has been run.


type: long

--

*`postgresql.statement.query.rows`*::
+
--
Total number of rows returned by query.


type: long

--

*`postgresql.statement.query.time.total.ms`*::
+
--
Total number of milliseconds spent running query.


type: float

--

*`postgresql.statement.query.time.min.ms`*::
+
--
Minimum number of milliseconds spent running query.


type: float

--

*`postgresql.statement.query.time.max.ms`*::
+
--
Maximum number of milliseconds spent running query.


type: float

--

*`postgresql.statement.query.time.mean.ms`*::
+
--
Mean number of milliseconds spent running query.


type: long

--

*`postgresql.statement.query.time.stddev.ms`*::
+
--
Population standard deviation of time spent running query, in milliseconds.


type: long

--

*`postgresql.statement.query.memory.shared.hit`*::
+
--
Total number of shared block cache hits by the query.


type: long

--

*`postgresql.statement.query.memory.shared.read`*::
+
--
Total number of shared block cache read by the query.


type: long

--

*`postgresql.statement.query.memory.shared.dirtied`*::
+
--
Total number of shared block cache dirtied by the query.


type: long

--

*`postgresql.statement.query.memory.shared.written`*::
+
--
Total number of shared block cache written by the query.


type: long

--

*`postgresql.statement.query.memory.local.hit`*::
+
--
Total number of local block cache hits by the query.


type: long

--

*`postgresql.statement.query.memory.local.read`*::
+
--
Total number of local block cache read by the query.


type: long

--

*`postgresql.statement.query.memory.local.dirtied`*::
+
--
Total number of local block cache dirtied by the query.


type: long

--

*`postgresql.statement.query.memory.local.written`*::
+
--
Total number of local block cache written by the query.


type: long

--

*`postgresql.statement.query.memory.temp.read`*::
+
--
Total number of temp block cache read by the query.


type: long

--

*`postgresql.statement.query.memory.temp.written`*::
+
--
Total number of temp block cache written by the query.


type: long

--

[[exported-fields-process]]
== Process fields

Process metadata fields




*`process.exe`*::
+
--
type: alias

alias to: process.executable

--

[[exported-fields-prometheus]]
== Prometheus fields

Stats scraped from a Prometheus endpoint.



*`prometheus.labels.*`*::
+
--
Prometheus metric labels


type: object

--

*`prometheus.metrics.*`*::
+
--
Prometheus metric - release: ga


type: object

--

[[exported-fields-rabbitmq]]
== RabbitMQ fields

RabbitMQ module



[float]
=== rabbitmq




*`rabbitmq.vhost`*::
+
--
Virtual host name with non-ASCII characters escaped as in C.


type: keyword

--

[float]
=== connection

connection



*`rabbitmq.connection.name`*::
+
--
The name of the connection with non-ASCII characters escaped as in C.


type: keyword

--

*`rabbitmq.connection.vhost`*::
+
--
Virtual host name with non-ASCII characters escaped as in C.


type: alias

alias to: rabbitmq.vhost

--

*`rabbitmq.connection.user`*::
+
--
User name.
<<<<<<< HEAD


type: alias
=======
>>>>>>> upstream/master


<<<<<<< HEAD
=======
type: alias

alias to: user.name

>>>>>>> upstream/master
--

*`rabbitmq.connection.node`*::
+
--
Node name.


type: alias

alias to: rabbitmq.node.name

--

*`rabbitmq.connection.channels`*::
+
--
The number of channels on the connection.


type: long

--

*`rabbitmq.connection.channel_max`*::
+
--
The maximum number of channels allowed on the connection.


type: long

--

*`rabbitmq.connection.frame_max`*::
+
--
Maximum permissible size of a frame (in bytes) to negotiate with clients.


type: long

format: bytes

--

*`rabbitmq.connection.type`*::
+
--
Type of the connection.


type: keyword

--

*`rabbitmq.connection.host`*::
+
--
Server hostname obtained via reverse DNS, or its IP address if reverse DNS failed or was disabled.


type: keyword

--

*`rabbitmq.connection.peer.host`*::
+
--
Peer hostname obtained via reverse DNS, or its IP address if reverse DNS failed or was not enabled.


type: keyword

--

*`rabbitmq.connection.port`*::
+
--
Server port.


type: long

--

*`rabbitmq.connection.peer.port`*::
+
--
Peer port.


type: long

--

*`rabbitmq.connection.packet_count.sent`*::
+
--
Number of packets sent on the connection.


type: long

--

*`rabbitmq.connection.packet_count.received`*::
+
--
Number of packets received on the connection.


type: long

--

*`rabbitmq.connection.packet_count.pending`*::
+
--
Number of packets pending on the connection.


type: long

--

*`rabbitmq.connection.octet_count.sent`*::
+
--
Number of octets sent on the connection.


type: long

--

*`rabbitmq.connection.octet_count.received`*::
+
--
Number of octets received on the connection.
<<<<<<< HEAD
=======


type: long

--

*`rabbitmq.connection.client_provided.name`*::
+
--
User specified connection name.

>>>>>>> upstream/master

type: keyword

type: long

--

[float]
=== exchange

exchange



*`rabbitmq.exchange.name`*::
+
--
The name of the queue with non-ASCII characters escaped as in C.


type: keyword

--

*`rabbitmq.exchange.vhost`*::
+
--
Virtual host name with non-ASCII characters escaped as in C.


type: alias

alias to: rabbitmq.vhost

--

*`rabbitmq.exchange.durable`*::
+
--
Whether or not the queue survives server restarts.


type: boolean

--

*`rabbitmq.exchange.auto_delete`*::
+
--
Whether the queue will be deleted automatically when no longer used.


type: boolean

--

*`rabbitmq.exchange.internal`*::
+
--
Whether the exchange is internal, i.e. cannot be directly published to by a client.


type: boolean

--

*`rabbitmq.exchange.user`*::
+
--
User who created the exchange.


type: alias

alias to: user.name

--

*`rabbitmq.exchange.messages.publish_in.count`*::
+
--
Count of messages published "in" to an exchange, i.e. not taking account of routing.


type: long

--

*`rabbitmq.exchange.messages.publish_in.details.rate`*::
+
--
How much the exchange publish-in count has changed per second in the most recent sampling interval.


type: float

--

*`rabbitmq.exchange.messages.publish_out.count`*::
+
--
Count of messages published "out" of an exchange, i.e. taking account of routing.


type: long

--

*`rabbitmq.exchange.messages.publish_out.details.rate`*::
+
--
How much the exchange publish-out count has changed per second in the most recent sampling interval.


type: float

--

[float]
=== node

node



*`rabbitmq.node.disk.free.bytes`*::
+
--
Disk free space in bytes.


type: long

format: bytes

--

*`rabbitmq.node.disk.free.limit.bytes`*::
+
--
Point at which the disk alarm will go off.


type: long

format: bytes

--

*`rabbitmq.node.fd.total`*::
+
--
File descriptors available.


type: long

--

*`rabbitmq.node.fd.used`*::
+
--
Used file descriptors.


type: long

--

*`rabbitmq.node.gc.num.count`*::
+
--
Number of GC operations.


type: long

--

*`rabbitmq.node.gc.reclaimed.bytes`*::
+
--
GC bytes reclaimed.


type: long

format: bytes

--

*`rabbitmq.node.io.file_handle.open_attempt.avg.ms`*::
+
--
File handle open avg time


type: long

--

*`rabbitmq.node.io.file_handle.open_attempt.count`*::
+
--
File handle open attempts


type: long

--

*`rabbitmq.node.io.read.avg.ms`*::
+
--
File handle read avg time


type: long

--

*`rabbitmq.node.io.read.bytes`*::
+
--
Data read in bytes


type: long

format: bytes

--

*`rabbitmq.node.io.read.count`*::
+
--
Data read operations


type: long

--

*`rabbitmq.node.io.reopen.count`*::
+
--
Data reopen operations


type: long

--

*`rabbitmq.node.io.seek.avg.ms`*::
+
--
Data seek avg time


type: long

--

*`rabbitmq.node.io.seek.count`*::
+
--
Data seek operations


type: long

--

*`rabbitmq.node.io.sync.avg.ms`*::
+
--
Data sync avg time


type: long

--

*`rabbitmq.node.io.sync.count`*::
+
--
Data sync operations


type: long

--

*`rabbitmq.node.io.write.avg.ms`*::
+
--
Data write avg time


type: long

--

*`rabbitmq.node.io.write.bytes`*::
+
--
Data write in bytes


type: long

format: bytes

--

*`rabbitmq.node.io.write.count`*::
+
--
Data write operations


type: long

--

*`rabbitmq.node.mem.limit.bytes`*::
+
--
Point at which the memory alarm will go off.


type: long

format: bytes

--

*`rabbitmq.node.mem.used.bytes`*::
+
--
Memory used in bytes.


type: long

--

*`rabbitmq.node.mnesia.disk.tx.count`*::
+
--
Number of Mnesia transactions which have been performed that required writes to disk.


type: long

--

*`rabbitmq.node.mnesia.ram.tx.count`*::
+
--
Number of Mnesia transactions which have been performed that did not require writes to disk.


type: long

--

*`rabbitmq.node.msg.store_read.count`*::
+
--
Number of messages which have been read from the message store.


type: long

--

*`rabbitmq.node.msg.store_write.count`*::
+
--
Number of messages which have been written to the message store.


type: long

--

*`rabbitmq.node.name`*::
+
--
Node name

type: keyword

--

*`rabbitmq.node.proc.total`*::
+
--
Maximum number of Erlang processes.


type: long

--

*`rabbitmq.node.proc.used`*::
+
--
Number of Erlang processes in use.


type: long

--

*`rabbitmq.node.processors`*::
+
--
Number of cores detected and usable by Erlang.


type: long

--

*`rabbitmq.node.queue.index.journal_write.count`*::
+
--
Number of records written to the queue index journal.


type: long

--

*`rabbitmq.node.queue.index.read.count`*::
+
--
Number of records read from the queue index.


type: long

--

*`rabbitmq.node.queue.index.write.count`*::
+
--
Number of records written to the queue index.


type: long

--

*`rabbitmq.node.run.queue`*::
+
--
Average number of Erlang processes waiting to run.


type: long

--

*`rabbitmq.node.socket.total`*::
+
--
File descriptors available for use as sockets.


type: long

--

*`rabbitmq.node.socket.used`*::
+
--
File descriptors used as sockets.


type: long

--

*`rabbitmq.node.type`*::
+
--
Node type.


type: keyword

--

*`rabbitmq.node.uptime`*::
+
--
Node uptime.


type: long

--

[float]
=== queue

queue



*`rabbitmq.queue.name`*::
+
--
The name of the queue with non-ASCII characters escaped as in C.


type: keyword

--

*`rabbitmq.queue.vhost`*::
+
--
Virtual host name with non-ASCII characters escaped as in C.


type: alias

alias to: rabbitmq.vhost

--

*`rabbitmq.queue.durable`*::
+
--
Whether or not the queue survives server restarts.


type: boolean

--

*`rabbitmq.queue.auto_delete`*::
+
--
Whether the queue will be deleted automatically when no longer used.


type: boolean

--

*`rabbitmq.queue.exclusive`*::
+
--
Whether the queue is exclusive (i.e. has owner_pid).


type: boolean

--

*`rabbitmq.queue.node`*::
+
--
Node name.


type: alias

alias to: rabbitmq.node.name

--

*`rabbitmq.queue.state`*::
+
--
The state of the queue. Normally 'running', but may be "{syncing, MsgCount}" if the queue is synchronising. Queues which are located on cluster nodes that are currently down will be shown with a status of 'down'.


type: keyword

--

*`rabbitmq.queue.arguments.max_priority`*::
+
--
Maximum number of priority levels for the queue to support.


type: long

--

*`rabbitmq.queue.consumers.count`*::
+
--
Number of consumers.


type: long

--

*`rabbitmq.queue.consumers.utilisation.pct`*::
+
--
Fraction of the time (between 0.0 and 1.0) that the queue is able to immediately deliver messages to consumers. This can be less than 1.0 if consumers are limited by network congestion or prefetch count.


type: long

<<<<<<< HEAD
format: percentage
=======
format: percent
>>>>>>> upstream/master

--

*`rabbitmq.queue.messages.total.count`*::
+
--
Sum of ready and unacknowledged messages (queue depth).


type: long

--

*`rabbitmq.queue.messages.total.details.rate`*::
+
--
How much the queue depth has changed per second in the most recent sampling interval.


type: float

--

*`rabbitmq.queue.messages.ready.count`*::
+
--
Number of messages ready to be delivered to clients.


type: long

--

*`rabbitmq.queue.messages.ready.details.rate`*::
+
--
How much the count of messages ready has changed per second in the most recent sampling interval.


type: float

--

*`rabbitmq.queue.messages.unacknowledged.count`*::
+
--
Number of messages delivered to clients but not yet acknowledged.


type: long

--

*`rabbitmq.queue.messages.unacknowledged.details.rate`*::
+
--
How much the count of unacknowledged messages has changed per second in the most recent sampling interval.


type: float

--

*`rabbitmq.queue.messages.persistent.count`*::
+
--
Total number of persistent messages in the queue (will always be 0 for transient queues).


type: long

--

*`rabbitmq.queue.memory.bytes`*::
+
--
Bytes of memory consumed by the Erlang process associated with the queue, including stack, heap and internal structures.


type: long

format: bytes

--

*`rabbitmq.queue.disk.reads.count`*::
+
--
Total number of times messages have been read from disk by this queue since it started.


type: long

--

*`rabbitmq.queue.disk.writes.count`*::
+
--
Total number of times messages have been written to disk by this queue since it started.


type: long

--

[[exported-fields-redis]]
== Redis fields

Redis metrics collected from Redis.



[float]
=== redis

`redis` contains the information and statistics from Redis.



[float]
=== info

`info` contains the information and statistics returned by the `INFO` command.



[float]
=== clients

Redis client stats.



*`redis.info.clients.connected`*::
+
--
Number of client connections (excluding connections from slaves).


type: long

--

*`redis.info.clients.longest_output_list`*::
+
--

deprecated[6.5.0]

Longest output list among current client connections (replaced by max_output_buffer).


type: long

--

*`redis.info.clients.max_output_buffer`*::
+
--
Longest output list among current client connections.


type: long

--

*`redis.info.clients.biggest_input_buf`*::
+
--

deprecated[6.5.0]

Biggest input buffer among current client connections (replaced by max_input_buffer).


type: long

--

*`redis.info.clients.max_input_buffer`*::
+
--
Biggest input buffer among current client connections (on redis 5.0).


type: long

--

*`redis.info.clients.blocked`*::
+
--
Number of clients pending on a blocking call (BLPOP, BRPOP, BRPOPLPUSH).


type: long

--

[float]
=== cluster

Redis cluster information.



*`redis.info.cluster.enabled`*::
+
--
Indicates that the Redis cluster is enabled.


type: boolean

--

[float]
=== cpu

Redis CPU stats



*`redis.info.cpu.used.sys`*::
+
--
System CPU consumed by the Redis server.


type: scaled_float

--

*`redis.info.cpu.used.sys_children`*::
+
--
User CPU consumed by the Redis server.


type: scaled_float

--

*`redis.info.cpu.used.user`*::
+
--
System CPU consumed by the background processes.


type: scaled_float

--

*`redis.info.cpu.used.user_children`*::
+
--
User CPU consumed by the background processes.


type: scaled_float

--

[float]
=== memory

Redis memory stats.



*`redis.info.memory.used.value`*::
+
--
<<<<<<< HEAD
=======
Total number of bytes allocated by Redis.
>>>>>>> upstream/master


type: long

<<<<<<< HEAD
format: bytes Total number of bytes allocated by Redis.
=======
format: bytes
>>>>>>> upstream/master

--

*`redis.info.memory.used.rss`*::
+
--
Number of bytes that Redis allocated as seen by the operating system (a.k.a resident set size).


type: long

format: bytes

--

*`redis.info.memory.used.peak`*::
+
--
Peak memory consumed by Redis.


type: long

format: bytes

--

*`redis.info.memory.used.lua`*::
+
--
Used memory by the Lua engine.        


type: long

format: bytes

--

*`redis.info.memory.used.dataset`*::
+
--
The size in bytes of the dataset 


type: long

format: bytes

--

*`redis.info.memory.max.value`*::
+
--
Memory limit.


type: long

format: bytes

--

*`redis.info.memory.max.policy`*::
+
--
Eviction policy to use when memory limit is reached.


type: keyword

--

*`redis.info.memory.fragmentation.ratio`*::
+
--
Ratio between used_memory_rss and used_memory


type: float

--

*`redis.info.memory.fragmentation.bytes`*::
+
--
Bytes between used_memory_rss and used_memory


type: long

format: bytes

--

*`redis.info.memory.active_defrag.is_running`*::
+
--
Flag indicating if active defragmentation is active


type: boolean

--

*`redis.info.memory.allocator`*::
+
--
Memory allocator.


type: keyword

--


*`redis.info.memory.allocator_stats.allocated`*::
+
--
Allocated memory


type: long

format: bytes

--

*`redis.info.memory.allocator_stats.active`*::
+
--
Active memeory


type: long

format: bytes

--

*`redis.info.memory.allocator_stats.resident`*::
+
--
Resident memory


type: long

format: bytes

--

*`redis.info.memory.allocator_stats.fragmentation.ratio`*::
+
--
Fragmentation ratio


type: float

--

*`redis.info.memory.allocator_stats.fragmentation.bytes`*::
+
--
Fragmented bytes


type: long

format: bytes

--

*`redis.info.memory.allocator_stats.rss.ratio`*::
+
--
Resident ratio


type: float

--

*`redis.info.memory.allocator_stats.rss.bytes`*::
+
--
Resident bytes


type: long

format: bytes

--

[float]
=== persistence

Redis CPU stats.



*`redis.info.persistence.loading`*::
+
--
Flag indicating if the load of a dump file is on-going


type: boolean

--

[float]
=== rdb

Provides information about RDB persistence



*`redis.info.persistence.rdb.last_save.changes_since`*::
+
--
Number of changes since the last dump


type: long

--

*`redis.info.persistence.rdb.last_save.time`*::
+
--
Epoch-based timestamp of last successful RDB save


type: long

--

*`redis.info.persistence.rdb.bgsave.in_progress`*::
+
--
Flag indicating a RDB save is on-going


type: boolean

--

*`redis.info.persistence.rdb.bgsave.last_status`*::
+
--
Status of the last RDB save operation


type: keyword

--

*`redis.info.persistence.rdb.bgsave.last_time.sec`*::
+
--
Duration of the last RDB save operation in seconds


type: long

format: duration

--

*`redis.info.persistence.rdb.bgsave.current_time.sec`*::
+
--
Duration of the on-going RDB save operation if any


type: long

format: duration

--

*`redis.info.persistence.rdb.copy_on_write.last_size`*::
+
--
The size in bytes of copy-on-write allocations during the last RBD save operation                


type: long

format: bytes

--

[float]
=== aof

Provides information about AOF persitence



*`redis.info.persistence.aof.enabled`*::
+
--
Flag indicating AOF logging is activated


type: boolean

--

*`redis.info.persistence.aof.rewrite.in_progress`*::
+
--
Flag indicating a AOF rewrite operation is on-going


type: boolean

--

*`redis.info.persistence.aof.rewrite.scheduled`*::
+
--
Flag indicating an AOF rewrite operation will be scheduled once the on-going RDB save is complete.


type: boolean

--

*`redis.info.persistence.aof.rewrite.last_time.sec`*::
+
--
Duration of the last AOF rewrite operation in seconds


type: long

format: duration

--

*`redis.info.persistence.aof.rewrite.current_time.sec`*::
+
--
Duration of the on-going AOF rewrite operation if any


type: long

format: duration

--

*`redis.info.persistence.aof.rewrite.buffer.size`*::
+
--
Size of the AOF rewrite buffer


type: long

format: bytes

--

*`redis.info.persistence.aof.bgrewrite.last_status`*::
+
--
Status of the last AOF rewrite operatio


type: keyword

--

*`redis.info.persistence.aof.write.last_status`*::
+
--
Status of the last write operation to the AOF


type: keyword

--

*`redis.info.persistence.aof.copy_on_write.last_size`*::
+
--
The size in bytes of copy-on-write allocations during the last RBD save operation


type: long

format: bytes

--

*`redis.info.persistence.aof.buffer.size`*::
+
--
Size of the AOF buffer


type: long

format: bytes

--

*`redis.info.persistence.aof.size.current`*::
+
--
AOF current file size             


type: long

format: bytes

--

*`redis.info.persistence.aof.size.base`*::
+
--
AOF file size on latest startup or rewrite


type: long

format: bytes

--

*`redis.info.persistence.aof.fsync.pending`*::
+
--
Number of fsync pending jobs in background I/O queue


type: long

--

*`redis.info.persistence.aof.fsync.delayed`*::
+
--
Delayed fsync counter


type: long

--

[float]
=== replication

Replication



*`redis.info.replication.role`*::
+
--
Role of the instance (can be "master", or "slave").


type: keyword

--

*`redis.info.replication.connected_slaves`*::
+
--
Number of connected slaves


type: long

--

*`redis.info.replication.master_offset`*::
+
--

deprecated[6.5]

The server's current replication offset


type: long

--

*`redis.info.replication.backlog.active`*::
+
--
Flag indicating replication backlog is active


type: long

--

*`redis.info.replication.backlog.size`*::
+
--
Total size in bytes of the replication backlog buffer


type: long

format: bytes

--

*`redis.info.replication.backlog.first_byte_offset`*::
+
--
The master offset of the replication backlog buffer          


type: long

--

*`redis.info.replication.backlog.histlen`*::
+
--
Size in bytes of the data in the replication backlog buffer


type: long

--

*`redis.info.replication.master.offset`*::
+
--
The server's current replication offset


type: long

--

*`redis.info.replication.master.second_offset`*::
+
--
The offset up to which replication IDs are accepted


type: long

--

*`redis.info.replication.master.link_status`*::
+
--
Status of the link (up/down)


type: keyword

--

*`redis.info.replication.master.last_io_seconds_ago`*::
+
--
Number of seconds since the last interaction with master


type: long

format: duration

--

*`redis.info.replication.master.sync.in_progress`*::
+
--
Indicate the master is syncing to the slave


type: boolean

--

*`redis.info.replication.master.sync.left_bytes`*::
+
--
Number of bytes left before syncing is complete


type: long

format: bytes

--

*`redis.info.replication.master.sync.last_io_seconds_ago`*::
+
--
Number of seconds since last transfer I/O during a SYNC operation


type: long

format: duration

--

*`redis.info.replication.slave.offset`*::
+
--
The replication offset of the slave instance


type: long

--

*`redis.info.replication.slave.priority`*::
+
--
The priority of the instance as a candidate for failover


type: long

--

*`redis.info.replication.slave.is_readonly`*::
+
--
Flag indicating if the slave is read-only


type: boolean

--

[float]
=== server

Server info



*`redis.info.server.version`*::
+
--
None

type: alias

alias to: service.version

--

*`redis.info.server.git_sha1`*::
+
--
None

type: keyword

--

*`redis.info.server.git_dirty`*::
+
--
None

type: keyword

--

*`redis.info.server.build_id`*::
+
--
None

type: keyword

--

*`redis.info.server.mode`*::
+
--
None

type: keyword

--

*`redis.info.server.os`*::
+
--
None

type: alias

alias to: os.full

--

*`redis.info.server.arch_bits`*::
+
--
None

type: keyword

--

*`redis.info.server.multiplexing_api`*::
+
--
None

type: keyword

--

*`redis.info.server.gcc_version`*::
+
--
None

type: keyword

--

*`redis.info.server.process_id`*::
+
--
None

type: alias

alias to: process.pid

--

*`redis.info.server.run_id`*::
+
--
None

type: keyword

--

*`redis.info.server.tcp_port`*::
+
--
None

type: long

--

*`redis.info.server.uptime`*::
+
--
None

type: long

--

*`redis.info.server.hz`*::
+
--
None

type: long

--

*`redis.info.server.lru_clock`*::
+
--
None

type: long

--

*`redis.info.server.config_file`*::
+
--
None

type: keyword

--

[float]
=== stats

Redis stats.



*`redis.info.stats.connections.received`*::
+
--
Total number of connections received.

type: long

--

*`redis.info.stats.connections.rejected`*::
+
--
Total number of connections rejected.

type: long

--

*`redis.info.stats.commands_processed`*::
+
--
Total number of commands processed.

type: long

--

*`redis.info.stats.net.input.bytes`*::
+
--
Total network input in bytes.

type: long

--

*`redis.info.stats.net.output.bytes`*::
+
--
Total network output in bytes.

type: long

--

*`redis.info.stats.instantaneous.ops_per_sec`*::
+
--
Number of commands processed per second


type: long

--

*`redis.info.stats.instantaneous.input_kbps`*::
+
--
The network's read rate per second in KB/sec


type: scaled_float

--

*`redis.info.stats.instantaneous.output_kbps`*::
+
--
The network's write rate per second in KB/sec


type: scaled_float

--

*`redis.info.stats.sync.full`*::
+
--
The number of full resyncs with slaves


type: long

--

*`redis.info.stats.sync.partial.ok`*::
+
--
The number of accepted partial resync requests


type: long

--

*`redis.info.stats.sync.partial.err`*::
+
--
The number of denied partial resync requests


type: long

--

*`redis.info.stats.keys.expired`*::
+
--
Total number of key expiration events


type: long

--

*`redis.info.stats.keys.evicted`*::
+
--
Number of evicted keys due to maxmemory limit


type: long

--

*`redis.info.stats.keyspace.hits`*::
+
--
Number of successful lookup of keys in the main dictionary


type: long

--

*`redis.info.stats.keyspace.misses`*::
+
--
Number of failed lookup of keys in the main dictionary


type: long

--

*`redis.info.stats.pubsub.channels`*::
+
--
Global number of pub/sub channels with client subscriptions


type: long

--

*`redis.info.stats.pubsub.patterns`*::
+
--
Global number of pub/sub pattern with client subscriptions


type: long

--

*`redis.info.stats.latest_fork_usec`*::
+
--
Duration of the latest fork operation in microseconds


type: long

--

*`redis.info.stats.migrate_cached_sockets`*::
+
--
The number of sockets open for MIGRATE purposes


type: long

--

*`redis.info.stats.slave_expires_tracked_keys`*::
+
--
The number of keys tracked for expiry purposes (applicable only to writable slaves)


type: long

--

*`redis.info.stats.active_defrag.hits`*::
+
--
Number of value reallocations performed by active the defragmentation process


type: long

--

*`redis.info.stats.active_defrag.misses`*::
+
--
Number of aborted value reallocations started by the active defragmentation process


type: long

--

*`redis.info.stats.active_defrag.key_hits`*::
+
--
Number of keys that were actively defragmented


type: long

--

*`redis.info.stats.active_defrag.key_misses`*::
+
--
Number of keys that were skipped by the active defragmentation process


type: long

--

*`redis.info.slowlog.count`*::
+
--
Count of slow operations


type: long

--

[float]
=== key

`key` contains information about keys.



*`redis.key.name`*::
+
--
Key name.


type: keyword

--

*`redis.key.id`*::
+
--
Unique id for this key (With the form <keyspace>:<name>).


type: keyword

--

*`redis.key.type`*::
+
--
Key type as shown by `TYPE` command.


type: keyword

--

*`redis.key.length`*::
+
--
Length of the key (Number of elements for lists, length for strings, cardinality for sets).


type: long

--

*`redis.key.expire.ttl`*::
+
--
Seconds to expire.


type: long

--

[float]
=== keyspace

`keyspace` contains the information about the keyspaces returned by the `INFO` command.



*`redis.keyspace.id`*::
+
--
Keyspace identifier.


type: keyword

--

*`redis.keyspace.avg_ttl`*::
+
--
Average ttl.


type: long

--

*`redis.keyspace.keys`*::
+
--
Number of keys in the keyspace.


type: long

--

*`redis.keyspace.expires`*::
+
--
<<<<<<< HEAD
=======


type: long
>>>>>>> upstream/master

--

[[exported-fields-statsd]]
== Statsd fields

Statsd module



*`statsd.*.count`*::
+
--
Statsd counters


type: object

--

*`statsd.*.*`*::
+
--
Statsd metrics - release: beta


<<<<<<< HEAD
type: long
=======
type: object
>>>>>>> upstream/master

--

[[exported-fields-system]]
== System fields

System status metrics, like CPU and memory usage, that are collected from the operating system.



[float]
=== system

`system` contains local system metrics.



[float]
=== core

`system-core` contains CPU metrics for a single core of a multi-core system.



*`system.core.id`*::
+
--
CPU Core number.


type: long

--

*`system.core.user.pct`*::
+
--
The percentage of CPU time spent in user space.


type: scaled_float

format: percent

--

*`system.core.user.ticks`*::
+
--
The amount of CPU time spent in user space.


type: long

--

*`system.core.system.pct`*::
+
--
The percentage of CPU time spent in kernel space.


type: scaled_float

format: percent

--

*`system.core.system.ticks`*::
+
--
The amount of CPU time spent in kernel space.


type: long

--

*`system.core.nice.pct`*::
+
--
The percentage of CPU time spent on low-priority processes.


type: scaled_float

format: percent

--

*`system.core.nice.ticks`*::
+
--
The amount of CPU time spent on low-priority processes.


type: long

--

*`system.core.idle.pct`*::
+
--
The percentage of CPU time spent idle.


type: scaled_float

format: percent

--

*`system.core.idle.ticks`*::
+
--
The amount of CPU time spent idle.


type: long

--

*`system.core.iowait.pct`*::
+
--
The percentage of CPU time spent in wait (on disk).


type: scaled_float

format: percent

--

*`system.core.iowait.ticks`*::
+
--
The amount of CPU time spent in wait (on disk).


type: long

--

*`system.core.irq.pct`*::
+
--
The percentage of CPU time spent servicing and handling hardware interrupts.


type: scaled_float

format: percent

--

*`system.core.irq.ticks`*::
+
--
The amount of CPU time spent servicing and handling hardware interrupts.


type: long

--

*`system.core.softirq.pct`*::
+
--
The percentage of CPU time spent servicing and handling software interrupts.


type: scaled_float

format: percent

--

*`system.core.softirq.ticks`*::
+
--
The amount of CPU time spent servicing and handling software interrupts.


type: long

--

*`system.core.steal.pct`*::
+
--
The percentage of CPU time spent in involuntary wait by the virtual CPU while the hypervisor was servicing another processor. Available only on Unix.


type: scaled_float

format: percent

--

*`system.core.steal.ticks`*::
+
--
The amount of CPU time spent in involuntary wait by the virtual CPU while the hypervisor was servicing another processor. Available only on Unix.


type: long

--

[float]
=== cpu

`cpu` contains local CPU stats.



*`system.cpu.cores`*::
+
--
The number of CPU cores present on the host. The non-normalized percentages will have a maximum value of `100% * cores`. The normalized percentages already take this value into account and have a maximum value of 100%.


type: long

--

*`system.cpu.user.pct`*::
+
--
The percentage of CPU time spent in user space. On multi-core systems, you can have percentages that are greater than 100%. For example, if 3 cores are at 60% use, then the `system.cpu.user.pct` will be 180%.


type: scaled_float

format: percent

--

*`system.cpu.system.pct`*::
+
--
The percentage of CPU time spent in kernel space.


type: scaled_float

format: percent

--

*`system.cpu.nice.pct`*::
+
--
The percentage of CPU time spent on low-priority processes.


type: scaled_float

format: percent

--

*`system.cpu.idle.pct`*::
+
--
The percentage of CPU time spent idle.


type: scaled_float

format: percent

--

*`system.cpu.iowait.pct`*::
+
--
The percentage of CPU time spent in wait (on disk).


type: scaled_float

format: percent

--

*`system.cpu.irq.pct`*::
+
--
The percentage of CPU time spent servicing and handling hardware interrupts.


type: scaled_float

format: percent

--

*`system.cpu.softirq.pct`*::
+
--
The percentage of CPU time spent servicing and handling software interrupts.


type: scaled_float

format: percent

--

*`system.cpu.steal.pct`*::
+
--
The percentage of CPU time spent in involuntary wait by the virtual CPU while the hypervisor was servicing another processor. Available only on Unix.


type: scaled_float

format: percent

--

*`system.cpu.total.pct`*::
+
--
The percentage of CPU time spent in states other than Idle and IOWait.


type: scaled_float

format: percent

--

*`system.cpu.user.norm.pct`*::
+
--
The percentage of CPU time spent in user space.


type: scaled_float

format: percent

--

*`system.cpu.system.norm.pct`*::
+
--
The percentage of CPU time spent in kernel space.


type: scaled_float

format: percent

--

*`system.cpu.nice.norm.pct`*::
+
--
The percentage of CPU time spent on low-priority processes.


type: scaled_float

format: percent

--

*`system.cpu.idle.norm.pct`*::
+
--
The percentage of CPU time spent idle.


type: scaled_float

format: percent

--

*`system.cpu.iowait.norm.pct`*::
+
--
The percentage of CPU time spent in wait (on disk).


type: scaled_float

format: percent

--

*`system.cpu.irq.norm.pct`*::
+
--
The percentage of CPU time spent servicing and handling hardware interrupts.


type: scaled_float

format: percent

--

*`system.cpu.softirq.norm.pct`*::
+
--
The percentage of CPU time spent servicing and handling software interrupts.


type: scaled_float

format: percent

--

*`system.cpu.steal.norm.pct`*::
+
--
The percentage of CPU time spent in involuntary wait by the virtual CPU while the hypervisor was servicing another processor. Available only on Unix.


type: scaled_float

format: percent

--

*`system.cpu.total.norm.pct`*::
+
--
The percentage of CPU time in states other than Idle and IOWait, normalised by the number of cores.


type: scaled_float

format: percent

--

*`system.cpu.user.ticks`*::
+
--
The amount of CPU time spent in user space.


type: long

--

*`system.cpu.system.ticks`*::
+
--
The amount of CPU time spent in kernel space.


type: long

--

*`system.cpu.nice.ticks`*::
+
--
The amount of CPU time spent on low-priority processes.


type: long

--

*`system.cpu.idle.ticks`*::
+
--
The amount of CPU time spent idle.


type: long

--

*`system.cpu.iowait.ticks`*::
+
--
The amount of CPU time spent in wait (on disk).


type: long

--

*`system.cpu.irq.ticks`*::
+
--
The amount of CPU time spent servicing and handling hardware interrupts.


type: long

--

*`system.cpu.softirq.ticks`*::
+
--
The amount of CPU time spent servicing and handling software interrupts.


type: long

--

*`system.cpu.steal.ticks`*::
+
--
The amount of CPU time spent in involuntary wait by the virtual CPU while the hypervisor was servicing another processor. Available only on Unix.


type: long

--

[float]
=== diskio

`disk` contains disk IO metrics collected from the operating system.



*`system.diskio.name`*::
+
--
The disk name.


type: keyword

example: sda1

--

*`system.diskio.serial_number`*::
+
--
The disk's serial number. This may not be provided by all operating systems.


type: keyword

--

*`system.diskio.read.count`*::
+
--
The total number of reads completed successfully.


type: long

--

*`system.diskio.write.count`*::
+
--
The total number of writes completed successfully.


type: long

--

*`system.diskio.read.bytes`*::
+
--
The total number of bytes read successfully. On Linux this is the number of sectors read multiplied by an assumed sector size of 512.


type: long

format: bytes

--

*`system.diskio.write.bytes`*::
+
--
The total number of bytes written successfully. On Linux this is the number of sectors written multiplied by an assumed sector size of 512.


type: long

format: bytes

--

*`system.diskio.read.time`*::
+
--
The total number of milliseconds spent by all reads.


type: long

--

*`system.diskio.write.time`*::
+
--
The total number of milliseconds spent by all writes.


type: long

--

*`system.diskio.io.time`*::
+
--
The total number of of milliseconds spent doing I/Os.


type: long

--

*`system.diskio.iostat.read.request.merges_per_sec`*::
+
--
The number of read requests merged per second that were queued to the device.


type: float

--

*`system.diskio.iostat.write.request.merges_per_sec`*::
+
--
The number of write requests merged per second that were queued to the device.


type: float

--

*`system.diskio.iostat.read.request.per_sec`*::
+
--
The number of read requests that were issued to the device per second


type: float

--

*`system.diskio.iostat.write.request.per_sec`*::
+
--
The number of write requests that were issued to the device per second


type: float

--

*`system.diskio.iostat.read.per_sec.bytes`*::
+
--
The number of Bytes read from the device per second.


type: float

format: bytes

--

*`system.diskio.iostat.read.await`*::
+
--
The average time spent for read requests issued to the device to be served.


type: float

--

*`system.diskio.iostat.write.per_sec.bytes`*::
+
--
The number of Bytes write from the device per second.


type: float

format: bytes

--

*`system.diskio.iostat.write.await`*::
+
--
The average time spent for write requests issued to the device to be served.


type: float

--

*`system.diskio.iostat.request.avg_size`*::
+
--
The average size (in sectors) of the requests that were issued to the device.
<<<<<<< HEAD
=======


type: float

--

*`system.diskio.iostat.queue.avg_size`*::
+
--
The average queue length of the requests that were issued to the device.


type: float

--

*`system.diskio.iostat.await`*::
+
--
The average time spent for requests issued to the device to be served.

>>>>>>> upstream/master

type: float

type: float

--

*`system.diskio.iostat.service_time`*::
+
--
<<<<<<< HEAD
The average queue length of the requests that were issued to the device.
=======
The average service time (in milliseconds) for I/O requests that were issued to the device.

>>>>>>> upstream/master

type: float

type: float

--

*`system.diskio.iostat.busy`*::
+
--
<<<<<<< HEAD
The average time spent for requests issued to the device to be served.
=======
Percentage of CPU time during which I/O requests were issued to the device (bandwidth utilization for the device). Device saturation occurs when this value is close to 100%.

>>>>>>> upstream/master

type: float

type: float

--

[float]
=== entropy

Available system entropy



*`system.entropy.available_bits`*::
+
--
<<<<<<< HEAD
The average service time (in milliseconds) for I/O requests that were issued to the device.
=======
The available bits of entropy

>>>>>>> upstream/master

type: long

type: float

--

*`system.entropy.pct`*::
+
--
<<<<<<< HEAD
Percentage of CPU time during which I/O requests were issued to the device (bandwidth utilization for the device). Device saturation occurs when this value is close to 100%.
=======
The percentage of available entropy, relative to the pool size of 4096

>>>>>>> upstream/master

type: scaled_float

format: percent

type: float

--

[float]
=== filesystem

`filesystem` contains local filesystem stats.



*`system.filesystem.available`*::
+
--
The disk space available to an unprivileged user in bytes.


type: long

format: bytes

--

*`system.filesystem.device_name`*::
+
--
The disk name. For example: `/dev/disk1`


type: keyword

--

*`system.filesystem.type`*::
+
--
The disk type. For example: `ext4`


type: keyword

--

*`system.filesystem.mount_point`*::
+
--
The mounting point. For example: `/`


type: keyword

--

*`system.filesystem.files`*::
+
--
The total number of file nodes in the file system.


type: long

--

*`system.filesystem.free`*::
+
--
The disk space available in bytes.


type: long

format: bytes

--

*`system.filesystem.free_files`*::
+
--
The number of free file nodes in the file system.


type: long

--

*`system.filesystem.total`*::
+
--
The total disk space in bytes.


type: long

format: bytes

--

*`system.filesystem.used.bytes`*::
+
--
The used disk space in bytes.


type: long

format: bytes

--

*`system.filesystem.used.pct`*::
+
--
The percentage of used disk space.


type: scaled_float

format: percent

--

[float]
=== fsstat

`system.fsstat` contains filesystem metrics aggregated from all mounted filesystems.



*`system.fsstat.count`*::
+
--
Number of file systems found.

type: long

--

*`system.fsstat.total_files`*::
+
--
Total number of files.

type: long

--

[float]
=== total_size

Nested file system docs.


*`system.fsstat.total_size.free`*::
+
--
Total free space.


type: long

format: bytes

--

*`system.fsstat.total_size.used`*::
+
--
Total used space.


type: long

format: bytes

--

*`system.fsstat.total_size.total`*::
+
--
Total space (used plus free).


type: long

format: bytes

--

[float]
=== load

CPU load averages.



*`system.load.1`*::
+
--
Load average for the last minute.


type: scaled_float

--

*`system.load.5`*::
+
--
Load average for the last 5 minutes.


type: scaled_float

--

*`system.load.15`*::
+
--
Load average for the last 15 minutes.


type: scaled_float

--

*`system.load.norm.1`*::
+
--
Load for the last minute divided by the number of cores.


type: scaled_float

--

*`system.load.norm.5`*::
+
--
Load for the last 5 minutes divided by the number of cores.


type: scaled_float

--

*`system.load.norm.15`*::
+
--
Load for the last 15 minutes divided by the number of cores.


type: scaled_float

--

*`system.load.cores`*::
+
--
The number of CPU cores present on the host.


type: long

--

[float]
=== memory

`memory` contains local memory stats.



*`system.memory.total`*::
+
--
Total memory.


type: long

format: bytes

--

*`system.memory.used.bytes`*::
+
--
Used memory.


type: long

format: bytes

--

*`system.memory.free`*::
+
--
The total amount of free memory in bytes. This value does not include memory consumed by system caches and buffers (see system.memory.actual.free).


type: long

format: bytes

--

*`system.memory.used.pct`*::
+
--
The percentage of used memory.


type: scaled_float

format: percent

--

[float]
=== actual

Actual memory used and free.



*`system.memory.actual.used.bytes`*::
+
--
Actual used memory in bytes. It represents the difference between the total and the available memory. The available memory depends on the OS. For more details, please check `system.actual.free`.


type: long

format: bytes

--

*`system.memory.actual.free`*::
+
--
Actual free memory in bytes. It is calculated based on the OS. On Linux it consists of the free memory plus caches and buffers. On OSX it is a sum of free memory and the inactive memory. On Windows, it is equal to `system.memory.free`.


type: long

format: bytes

--

*`system.memory.actual.used.pct`*::
+
--
The percentage of actual used memory.


type: scaled_float

format: percent

--

[float]
=== swap

This group contains statistics related to the swap memory usage on the system.


*`system.memory.swap.total`*::
+
--
Total swap memory.


type: long

format: bytes

--

*`system.memory.swap.used.bytes`*::
+
--
Used swap memory.


type: long

format: bytes

--

*`system.memory.swap.free`*::
+
--
Available swap memory.


type: long

format: bytes

--

*`system.memory.swap.used.pct`*::
+
--
The percentage of used swap memory.


type: scaled_float

format: percent

--

[float]
=== hugepages

This group contains statistics related to huge pages usage on the system.


*`system.memory.hugepages.total`*::
+
--
Number of huge pages in the pool.


type: long

format: number

--

*`system.memory.hugepages.used.bytes`*::
+
--
Memory used in allocated huge pages.


type: long

format: bytes

--

*`system.memory.hugepages.used.pct`*::
+
--
Percentage of huge pages used.


type: long

format: percent

--

*`system.memory.hugepages.free`*::
+
--
Number of available huge pages in the pool.


type: long

format: number

--

*`system.memory.hugepages.reserved`*::
+
--
Number of reserved but not allocated huge pages in the pool.


type: long

format: number

--

*`system.memory.hugepages.surplus`*::
+
--
Number of overcommited huge pages.


type: long

format: number

--

*`system.memory.hugepages.default_size`*::
+
--
Default size for huge pages.


type: long

format: bytes

--

[float]
=== network

`network` contains network IO metrics for a single network interface.



*`system.network.name`*::
+
--
The network interface name.


type: keyword

example: eth0

--

*`system.network.out.bytes`*::
+
--
The number of bytes sent.


type: long

format: bytes

--

*`system.network.in.bytes`*::
+
--
The number of bytes received.


type: long

format: bytes

--

*`system.network.out.packets`*::
+
--
The number of packets sent.


type: long

--

*`system.network.in.packets`*::
+
--
The number or packets received.


type: long

--

*`system.network.in.errors`*::
+
--
The number of errors while receiving.


type: long

--

*`system.network.out.errors`*::
+
--
The number of errors while sending.


type: long

--

*`system.network.in.dropped`*::
+
--
The number of incoming packets that were dropped.


type: long

--

*`system.network.out.dropped`*::
+
--
The number of outgoing packets that were dropped. This value is always 0 on Darwin and BSD because it is not reported by the operating system.


type: long

--

[float]
=== process

`process` contains process metadata, CPU metrics, and memory metrics.



*`system.process.name`*::
+
--
type: alias

alias to: process.name

--

*`system.process.state`*::
+
--
The process state. For example: "running".


type: keyword

--

*`system.process.pid`*::
+
--
type: alias

alias to: process.pid

--

*`system.process.ppid`*::
+
--
type: alias

alias to: process.ppid

--

*`system.process.pgid`*::
+
--
type: alias

alias to: process.pgid

--

*`system.process.cmdline`*::
+
--
The full command-line used to start the process, including the arguments separated by space.


type: keyword

--

*`system.process.username`*::
+
--
type: alias

alias to: user.name

--

*`system.process.cwd`*::
+
--
type: alias

alias to: process.working_directory

--

*`system.process.env`*::
+
--
The environment variables used to start the process. The data is available on FreeBSD, Linux, and OS X.


type: object

--

[float]
=== cpu

CPU-specific statistics per process.


*`system.process.cpu.user.ticks`*::
+
--
The amount of CPU time the process spent in user space.


type: long

--

*`system.process.cpu.total.value`*::
+
--
The value of CPU usage since starting the process.


type: long

--

*`system.process.cpu.total.pct`*::
+
--
The percentage of CPU time spent by the process since the last update. Its value is similar to the %CPU value of the process displayed by the top command on Unix systems.


type: scaled_float

format: percent

--

*`system.process.cpu.total.norm.pct`*::
+
--
The percentage of CPU time spent by the process since the last event. This value is normalized by the number of CPU cores and it ranges from 0 to 100%.


type: scaled_float

format: percent

--

*`system.process.cpu.system.ticks`*::
+
--
The amount of CPU time the process spent in kernel space.


type: long

--

*`system.process.cpu.total.ticks`*::
+
--
The total CPU time spent by the process.


type: long

--

*`system.process.cpu.start_time`*::
+
--
The time when the process was started.


type: date

--

[float]
=== memory

Memory-specific statistics per process.


*`system.process.memory.size`*::
+
--
The total virtual memory the process has.


type: long

format: bytes

--

*`system.process.memory.rss.bytes`*::
+
--
The Resident Set Size. The amount of memory the process occupied in main memory (RAM).


type: long

format: bytes

--

*`system.process.memory.rss.pct`*::
+
--
The percentage of memory the process occupied in main memory (RAM).


type: scaled_float

format: percent

--

*`system.process.memory.share`*::
+
--
The shared memory the process uses.


type: long

format: bytes

--

[float]
=== fd

File descriptor usage metrics. This set of metrics is available for Linux and FreeBSD.



*`system.process.fd.open`*::
+
--
The number of file descriptors open by the process.

type: long

--

*`system.process.fd.limit.soft`*::
+
--
The soft limit on the number of file descriptors opened by the process. The soft limit can be changed by the process at any time.


type: long

--

*`system.process.fd.limit.hard`*::
+
--
The hard limit on the number of file descriptors opened by the process. The hard limit can only be raised by root.


type: long

--

[float]
=== cgroup

Metrics and limits from the cgroup of which the task is a member. cgroup metrics are reported when the process has membership in a non-root cgroup. These metrics are only available on Linux.



*`system.process.cgroup.id`*::
+
--
The ID common to all cgroups associated with this task. If there isn't a common ID used by all cgroups this field will be absent.


type: keyword

--

*`system.process.cgroup.path`*::
+
--
The path to the cgroup relative to the cgroup subsystem's mountpoint. If there isn't a common path used by all cgroups this field will be absent.


type: keyword

--

[float]
=== cpu

The cpu subsystem schedules CPU access for tasks in the cgroup. Access can be controlled by two separate schedulers, CFS and RT. CFS stands for completely fair scheduler which proportionally divides the CPU time between cgroups based on weight. RT stands for real time scheduler which sets a maximum amount of CPU time that processes in the cgroup can consume during a given period.



*`system.process.cgroup.cpu.id`*::
+
--
ID of the cgroup.

type: keyword

--

*`system.process.cgroup.cpu.path`*::
+
--
Path to the cgroup relative to the cgroup subsystem's mountpoint.


type: keyword

--

*`system.process.cgroup.cpu.cfs.period.us`*::
+
--
Period of time in microseconds for how regularly a cgroup's access to CPU resources should be reallocated.


type: long

--

*`system.process.cgroup.cpu.cfs.quota.us`*::
+
--
Total amount of time in microseconds for which all tasks in a cgroup can run during one period (as defined by cfs.period.us).


type: long

--

*`system.process.cgroup.cpu.cfs.shares`*::
+
--
An integer value that specifies a relative share of CPU time available to the tasks in a cgroup. The value specified in the cpu.shares file must be 2 or higher.


type: long

--

*`system.process.cgroup.cpu.rt.period.us`*::
+
--
Period of time in microseconds for how regularly a cgroup's access to CPU resources is reallocated.


type: long

--

*`system.process.cgroup.cpu.rt.runtime.us`*::
+
--
Period of time in microseconds for the longest continuous period in which the tasks in a cgroup have access to CPU resources.


type: long

--

*`system.process.cgroup.cpu.stats.periods`*::
+
--
Number of period intervals (as specified in cpu.cfs.period.us) that have elapsed.


type: long

--

*`system.process.cgroup.cpu.stats.throttled.periods`*::
+
--
Number of times tasks in a cgroup have been throttled (that is, not allowed to run because they have exhausted all of the available time as specified by their quota).


type: long

--

*`system.process.cgroup.cpu.stats.throttled.ns`*::
+
--
The total time duration (in nanoseconds) for which tasks in a cgroup have been throttled.


type: long

--

[float]
=== cpuacct

CPU accounting metrics.


*`system.process.cgroup.cpuacct.id`*::
+
--
ID of the cgroup.

type: keyword

--

*`system.process.cgroup.cpuacct.path`*::
+
--
Path to the cgroup relative to the cgroup subsystem's mountpoint.


type: keyword

--

*`system.process.cgroup.cpuacct.total.ns`*::
+
--
Total CPU time in nanoseconds consumed by all tasks in the cgroup.


type: long

--

*`system.process.cgroup.cpuacct.stats.user.ns`*::
+
--
CPU time consumed by tasks in user mode.

type: long

--

*`system.process.cgroup.cpuacct.stats.system.ns`*::
+
--
CPU time consumed by tasks in user (kernel) mode.

type: long

--

*`system.process.cgroup.cpuacct.percpu`*::
+
--
CPU time (in nanoseconds) consumed on each CPU by all tasks in this cgroup.


type: object

--

[float]
=== memory

Memory limits and metrics.


*`system.process.cgroup.memory.id`*::
+
--
ID of the cgroup.

type: keyword

--

*`system.process.cgroup.memory.path`*::
+
--
Path to the cgroup relative to the cgroup subsystem's mountpoint.


type: keyword

--

*`system.process.cgroup.memory.mem.usage.bytes`*::
+
--
Total memory usage by processes in the cgroup (in bytes).


type: long

format: bytes

--

*`system.process.cgroup.memory.mem.usage.max.bytes`*::
+
--
The maximum memory used by processes in the cgroup (in bytes).


type: long

format: bytes

--

*`system.process.cgroup.memory.mem.limit.bytes`*::
+
--
The maximum amount of user memory in bytes (including file cache) that tasks in the cgroup are allowed to use.


type: long

format: bytes

--

*`system.process.cgroup.memory.mem.failures`*::
+
--
The number of times that the memory limit (mem.limit.bytes) was reached.


type: long

--

*`system.process.cgroup.memory.memsw.usage.bytes`*::
+
--
The sum of current memory usage plus swap space used by processes in the cgroup (in bytes).


type: long

format: bytes

--

*`system.process.cgroup.memory.memsw.usage.max.bytes`*::
+
--
The maximum amount of memory and swap space used by processes in the cgroup (in bytes).


type: long

format: bytes

--

*`system.process.cgroup.memory.memsw.limit.bytes`*::
+
--
The maximum amount for the sum of memory and swap usage that tasks in the cgroup are allowed to use.


type: long

format: bytes

--

*`system.process.cgroup.memory.memsw.failures`*::
+
--
The number of times that the memory plus swap space limit (memsw.limit.bytes) was reached.


type: long

--

*`system.process.cgroup.memory.kmem.usage.bytes`*::
+
--
Total kernel memory usage by processes in the cgroup (in bytes).


type: long

format: bytes

--

*`system.process.cgroup.memory.kmem.usage.max.bytes`*::
+
--
The maximum kernel memory used by processes in the cgroup (in bytes).


type: long

format: bytes

--

*`system.process.cgroup.memory.kmem.limit.bytes`*::
+
--
The maximum amount of kernel memory that tasks in the cgroup are allowed to use.


type: long

format: bytes

--

*`system.process.cgroup.memory.kmem.failures`*::
+
--
The number of times that the memory limit (kmem.limit.bytes) was reached.


type: long

--

*`system.process.cgroup.memory.kmem_tcp.usage.bytes`*::
+
--
Total memory usage for TCP buffers in bytes.


type: long

format: bytes

--

*`system.process.cgroup.memory.kmem_tcp.usage.max.bytes`*::
+
--
The maximum memory used for TCP buffers by processes in the cgroup (in bytes).


type: long

format: bytes

--

*`system.process.cgroup.memory.kmem_tcp.limit.bytes`*::
+
--
The maximum amount of memory for TCP buffers that tasks in the cgroup are allowed to use.


type: long

format: bytes

--

*`system.process.cgroup.memory.kmem_tcp.failures`*::
+
--
The number of times that the memory limit (kmem_tcp.limit.bytes) was reached.


type: long

--

*`system.process.cgroup.memory.stats.active_anon.bytes`*::
+
--
Anonymous and swap cache on active least-recently-used (LRU) list, including tmpfs (shmem), in bytes.


type: long

format: bytes

--

*`system.process.cgroup.memory.stats.active_file.bytes`*::
+
--
File-backed memory on active LRU list, in bytes.

type: long

format: bytes

--

*`system.process.cgroup.memory.stats.cache.bytes`*::
+
--
Page cache, including tmpfs (shmem), in bytes.

type: long

format: bytes

--

*`system.process.cgroup.memory.stats.hierarchical_memory_limit.bytes`*::
+
--
Memory limit for the hierarchy that contains the memory cgroup, in bytes.


type: long

format: bytes

--

*`system.process.cgroup.memory.stats.hierarchical_memsw_limit.bytes`*::
+
--
Memory plus swap limit for the hierarchy that contains the memory cgroup, in bytes.


type: long

format: bytes

--

*`system.process.cgroup.memory.stats.inactive_anon.bytes`*::
+
--
Anonymous and swap cache on inactive LRU list, including tmpfs (shmem), in bytes


type: long

format: bytes

--

*`system.process.cgroup.memory.stats.inactive_file.bytes`*::
+
--
File-backed memory on inactive LRU list, in bytes.


type: long

format: bytes

--

*`system.process.cgroup.memory.stats.mapped_file.bytes`*::
+
--
Size of memory-mapped mapped files, including tmpfs (shmem), in bytes.


type: long

format: bytes

--

*`system.process.cgroup.memory.stats.page_faults`*::
+
--
Number of times that a process in the cgroup triggered a page fault.


type: long

--

*`system.process.cgroup.memory.stats.major_page_faults`*::
+
--
Number of times that a process in the cgroup triggered a major fault. "Major" faults happen when the kernel actually has to read the data from disk.


type: long

--

*`system.process.cgroup.memory.stats.pages_in`*::
+
--
Number of pages paged into memory. This is a counter.


type: long

--

*`system.process.cgroup.memory.stats.pages_out`*::
+
--
Number of pages paged out of memory. This is a counter.


type: long

--

*`system.process.cgroup.memory.stats.rss.bytes`*::
+
--
Anonymous and swap cache (includes transparent hugepages), not including tmpfs (shmem), in bytes.


type: long

format: bytes

--

*`system.process.cgroup.memory.stats.rss_huge.bytes`*::
+
--
Number of bytes of anonymous transparent hugepages.


type: long

format: bytes

--

*`system.process.cgroup.memory.stats.swap.bytes`*::
+
--
Swap usage, in bytes.


type: long

format: bytes

--

*`system.process.cgroup.memory.stats.unevictable.bytes`*::
+
--
Memory that cannot be reclaimed, in bytes.


type: long

format: bytes

--

[float]
=== blkio

Block IO metrics.


*`system.process.cgroup.blkio.id`*::
+
--
ID of the cgroup.

type: keyword

--

*`system.process.cgroup.blkio.path`*::
+
--
Path to the cgroup relative to the cgroup subsystems mountpoint.


type: keyword

--

*`system.process.cgroup.blkio.total.bytes`*::
+
--
Total number of bytes transferred to and from all block devices by processes in the cgroup.


type: long

format: bytes

--

*`system.process.cgroup.blkio.total.ios`*::
+
--
Total number of I/O operations performed on all devices by processes in the cgroup as seen by the throttling policy.


type: long

--

[float]
=== process.summary

Summary metrics for the processes running on the host.



*`system.process.summary.total`*::
+
--
Total number of processes on this host.


type: long

--

*`system.process.summary.running`*::
+
--
Number of running processes on this host.


type: long

--

*`system.process.summary.idle`*::
+
--
Number of idle processes on this host.


type: long

--

*`system.process.summary.sleeping`*::
+
--
Number of sleeping processes on this host.


type: long

--

*`system.process.summary.stopped`*::
+
--
Number of stopped processes on this host.


type: long

--

*`system.process.summary.zombie`*::
+
--
Number of zombie processes on this host.


type: long

--

*`system.process.summary.dead`*::
+
--
Number of dead processes on this host. It's very unlikely that it will appear but in some special situations it may happen.


type: long

--

*`system.process.summary.unknown`*::
+
--
Number of processes for which the state couldn't be retrieved or is unknown.


type: long

--

[float]
=== raid

raid



*`system.raid.name`*::
+
--
Name of the device.


type: keyword

--

*`system.raid.status`*::
+
--
activity-state of the device.


type: keyword

--

*`system.raid.level`*::
+
--
The raid level of the device


type: keyword

--

*`system.raid.sync_action`*::
+
--
Current sync action, if the RAID array is redundant 


type: keyword

--

*`system.raid.disks.active`*::
+
--
Number of active disks.


type: long

--

*`system.raid.disks.total`*::
+
--
Total number of disks the device consists of.


type: long

--

*`system.raid.disks.spare`*::
+
--
Number of spared disks.


type: long

--

*`system.raid.disks.failed`*::
+
--
Number of failed disks.


type: long

--

*`system.raid.disks.states.*`*::
+
--
map of raw disk states


type: object

--

*`system.raid.blocks.total`*::
+
--
Number of blocks the device holds, in 1024-byte blocks.


type: long

--

*`system.raid.blocks.synced`*::
+
--
Number of blocks on the device that are in sync, in 1024-byte blocks.


type: long

--

[float]
=== socket

TCP sockets that are active.



*`system.socket.direction`*::
+
--
type: alias

alias to: network.direction

--

*`system.socket.family`*::
+
--
type: alias

alias to: network.type

--

*`system.socket.local.ip`*::
+
--
Local IP address. This can be an IPv4 or IPv6 address.


type: ip

example: 192.0.2.1 or 2001:0DB8:ABED:8536::1

--

*`system.socket.local.port`*::
+
--
Local port.


type: long

example: 22

--

*`system.socket.remote.ip`*::
+
--
Remote IP address. This can be an IPv4 or IPv6 address.


type: ip

example: 192.0.2.1 or 2001:0DB8:ABED:8536::1

--

*`system.socket.remote.port`*::
+
--
Remote port.


type: long

example: 22

--

*`system.socket.remote.host`*::
+
--
PTR record associated with the remote IP. It is obtained via reverse IP lookup.


type: keyword

example: 76-211-117-36.nw.example.com.

--

*`system.socket.remote.etld_plus_one`*::
+
--
The effective top-level domain (eTLD) of the remote host plus one more label. For example, the eTLD+1 for "foo.bar.golang.org." is "golang.org.". The data for determining the eTLD comes from an embedded copy of the data from http://publicsuffix.org.


type: keyword

example: example.com.

--

*`system.socket.remote.host_error`*::
+
--
Error describing the cause of the reverse lookup failure.


type: keyword

--

*`system.socket.process.pid`*::
+
--
type: alias

alias to: process.pid

--

*`system.socket.process.command`*::
+
--
type: alias

alias to: process.name

--

*`system.socket.process.cmdline`*::
+
--
Full command line


type: keyword

--

*`system.socket.process.exe`*::
+
--
type: alias

alias to: process.executable

--

*`system.socket.user.id`*::
+
--
type: alias

alias to: user.id

--

*`system.socket.user.name`*::
+
--
type: alias

alias to: user.full_name

--

[float]
=== socket.summary

Summary metrics of open sockets in the host system



[float]
=== all

All connections



*`system.socket.summary.all.count`*::
+
--
All open connections
<<<<<<< HEAD


type: integer

--
=======


type: integer

--

*`system.socket.summary.all.listening`*::
+
--
All listening ports


type: integer

--

[float]
=== tcp

All TCP connections


>>>>>>> upstream/master

*`system.socket.summary.tcp.memory`*::
+
--
<<<<<<< HEAD
All listening ports
=======
Memory used by TCP sockets in bytes, based on number of allocated pages and system page size. Corresponds to limits set in /proc/sys/net/ipv4/tcp_mem. Only available on Linux. 

>>>>>>> upstream/master

type: integer

format: bytes

type: integer

--

[float]
<<<<<<< HEAD
=== tcp
=======
=== all
>>>>>>> upstream/master

All TCP connections



<<<<<<< HEAD
*`system.socket.summary.tcp.memory`*::
+
--
Memory used by TCP sockets in bytes, based on number of allocated pages and system page size. Corresponds to limits set in /proc/sys/net/ipv4/tcp_mem. Only available on Linux. 


type: integer

format: bytes

--

[float]
=== all
=======
*`system.socket.summary.tcp.all.orphan`*::
+
--
A count of all orphaned tcp sockets. Only available on Linux.
>>>>>>> upstream/master


type: integer

--

*`system.socket.summary.tcp.all.orphan`*::
+
--
<<<<<<< HEAD
A count of all orphaned tcp sockets. Only available on Linux.


type: integer

--

*`system.socket.summary.tcp.all.count`*::
+
--
=======
>>>>>>> upstream/master
All open TCP connections


type: integer

--

*`system.socket.summary.tcp.all.listening`*::
+
--
All TCP listening ports


type: integer

--

*`system.socket.summary.tcp.all.established`*::
+
--
Number of established TCP connections


type: integer

--

*`system.socket.summary.tcp.all.close_wait`*::
+
--
Number of TCP connections in _close_wait_ state


type: integer

--

*`system.socket.summary.tcp.all.time_wait`*::
+
--
Number of TCP connections in _time_wait_ state


type: integer

--

[float]
=== udp

All UDP connections



*`system.socket.summary.udp.memory`*::
+
--
Memory used by UDP sockets in bytes, based on number of allocated pages and system page size. Corresponds to limits set in /proc/sys/net/ipv4/udp_mem. Only available on Linux. 


type: integer

format: bytes

--

[float]
=== all

All UDP connections



*`system.socket.summary.udp.all.count`*::
+
--
All open UDP connections


type: integer

--

[float]
=== uptime

`uptime` contains the operating system uptime metric.



*`system.uptime.duration.ms`*::
+
--
The OS uptime in milliseconds.


type: long

format: duration

--

[[exported-fields-traefik]]
== traefik fields

Traefik reverse proxy / load balancer metrics



[float]
=== traefik

Traefik reverse proxy / load balancer metrics



[float]
=== health

Metrics obtained from Traefik's health API endpoint



*`traefik.health.uptime.sec`*::
+
--
Uptime of Traefik instance in seconds


type: long

--

[float]
=== response

Response metrics



*`traefik.health.response.count`*::
+
--
Number of responses


type: long

--

*`traefik.health.response.avg_time.us`*::
+
--
Average response time in microseconds


type: long

--

*`traefik.health.response.status_codes.*`*::
+
--
Number of responses per status code


type: object

--

[[exported-fields-uwsgi]]
== uwsgi fields

uwsgi module



[float]
=== uwsgi




[float]
=== status

uwsgi.status metricset fields



*`uwsgi.status.total.requests`*::
+
--
Total requests handled


type: long

--

*`uwsgi.status.total.exceptions`*::
+
--
Total exceptions


type: long

--

*`uwsgi.status.total.write_errors`*::
+
--
Total requests write errors


type: long

--

*`uwsgi.status.total.read_errors`*::
+
--
Total read errors


type: long

--

*`uwsgi.status.total.pid`*::
+
--
Process id


type: long

--

*`uwsgi.status.worker.id`*::
+
--
Worker id


type: long

--

*`uwsgi.status.worker.pid`*::
+
--
Worker process id


type: long

--

*`uwsgi.status.worker.accepting`*::
+
--
State of worker, 1 if still accepting new requests otherwise 0


type: long

--

*`uwsgi.status.worker.requests`*::
+
--
Number of requests served by this worker


type: long

--

*`uwsgi.status.worker.delta_requests`*::
+
--
Number of requests served by this worker after worker is reloaded when reached MAX_REQUESTS


type: long

--

*`uwsgi.status.worker.exceptions`*::
+
--
Exceptions raised


type: long

--

*`uwsgi.status.worker.harakiri_count`*::
+
--
Dropped requests by timeout


type: long

--

*`uwsgi.status.worker.signals`*::
+
--
Emitted signals count


type: long

--

*`uwsgi.status.worker.signal_queue`*::
+
--
Number of signals waiting to be handled


type: long

--

*`uwsgi.status.worker.status`*::
+
--
Worker status (cheap, pause, sig, busy, idle)


type: keyword

--

*`uwsgi.status.worker.rss`*::
+
--
Resident Set Size. memory currently used by a process. if always zero try `--memory-report` option of uwsgi


type: keyword

--

*`uwsgi.status.worker.vsz`*::
+
--
Virtual Set Size. memory size assigned to a process. if always zero try `--memory-report` option of uwsgi


type: long

--

*`uwsgi.status.worker.running_time`*::
+
--
Process running time


type: long

--

*`uwsgi.status.worker.respawn_count`*::
+
--
Respawn count


type: long

--

*`uwsgi.status.worker.tx`*::
+
--
Transmitted size


type: long

--

*`uwsgi.status.worker.avg_rt`*::
+
--
Average response time


type: long

--

*`uwsgi.status.core.id`*::
+
--
worker ID


type: long

--

*`uwsgi.status.core.worker_pid`*::
+
--
Parent worker PID


type: long

--

*`uwsgi.status.core.requests.total`*::
+
--
Number of total requests served


type: long

--

*`uwsgi.status.core.requests.static`*::
+
--
Number of static file serves


type: long

--

*`uwsgi.status.core.requests.routed`*::
+
--
Routed requests


type: long

--

*`uwsgi.status.core.requests.offloaded`*::
+
--
Offloaded requests


type: long

--

*`uwsgi.status.core.write_errors`*::
+
--
Number of failed writes


type: long

--

*`uwsgi.status.core.read_errors`*::
+
--
Number of failed reads


type: long

--

[[exported-fields-vsphere]]
== vSphere fields

vSphere module



[float]
=== vsphere




[float]
=== datastore

datastore



*`vsphere.datastore.name`*::
+
--
Datastore name


type: keyword

--

*`vsphere.datastore.fstype`*::
+
--
Filesystem type


type: keyword

--

*`vsphere.datastore.capacity.total.bytes`*::
+
--
Total bytes of the datastore


type: long

format: bytes

--

*`vsphere.datastore.capacity.free.bytes`*::
+
--
Free bytes of the datastore


type: long

format: bytes

--

*`vsphere.datastore.capacity.used.bytes`*::
+
--
Used bytes of the datastore


type: long

format: bytes

--

*`vsphere.datastore.capacity.used.pct`*::
+
--
Used percent of the datastore


type: long

format: percent

--

[float]
=== host

host



*`vsphere.host.name`*::
+
--
Host name


type: keyword

--

*`vsphere.host.cpu.used.mhz`*::
+
--
Used CPU in Mhz


type: long

--

*`vsphere.host.cpu.total.mhz`*::
+
--
Total CPU in Mhz


type: long

--

*`vsphere.host.cpu.free.mhz`*::
+
--
Free CPU in Mhz


type: long

--

*`vsphere.host.memory.used.bytes`*::
+
--
Used Memory in bytes


type: long

format: bytes

--

*`vsphere.host.memory.total.bytes`*::
+
--
Total Memory in bytes


type: long

format: bytes

--

*`vsphere.host.memory.free.bytes`*::
+
--
Free Memory in bytes


type: long

format: bytes

--

*`vsphere.host.network_names`*::
+
--
Network names


type: keyword

--

[float]
=== virtualmachine

virtualmachine



*`vsphere.virtualmachine.host`*::
+
--
Host name


type: keyword

--

*`vsphere.virtualmachine.name`*::
+
--
Virtual Machine name
<<<<<<< HEAD
=======


type: keyword

--

*`vsphere.virtualmachine.os`*::
+
--
Virtual Machine Operating System name
>>>>>>> upstream/master


type: keyword

--

*`vsphere.virtualmachine.cpu.used.mhz`*::
+
--
Used CPU in Mhz


type: long

--

*`vsphere.virtualmachine.memory.used.guest.bytes`*::
+
--
Used Memory of Guest in bytes


type: long

format: bytes

--

*`vsphere.virtualmachine.memory.used.host.bytes`*::
+
--
Used Memory of Host in bytes


type: long

format: bytes

--

*`vsphere.virtualmachine.memory.total.guest.bytes`*::
+
--
Total Memory of Guest in bytes


type: long

format: bytes

--

*`vsphere.virtualmachine.memory.free.guest.bytes`*::
+
--
Free Memory of Guest in bytes


type: long

format: bytes

--

*`vsphere.virtualmachine.custom_fields`*::
+
--
Custom fields


type: object

--

*`vsphere.virtualmachine.network_names`*::
+
--
Network names


type: keyword

--

[[exported-fields-windows]]
== Windows fields

Module for Windows



[float]
=== windows




[float]
=== service

`service` contains the status for Windows services.



*`windows.service.id`*::
+
--
A unique ID for the service. It is a hash of the machine's GUID and the service name.


type: keyword

example: hW3NJFc1Ap

--

*`windows.service.name`*::
+
--
The service name.


type: keyword

example: Wecsvc

--

*`windows.service.display_name`*::
+
--
The display name of the service.


type: keyword

example: Windows Event Collector

--

*`windows.service.start_type`*::
+
--
The startup type of the service. The possible values are `Automatic`, `Boot`, `Disabled`, `Manual`, and `System`.


type: keyword

--

*`windows.service.start_name`*::
+
--
Account name under which a service runs.


type: keyword

example: NT AUTHORITY\LocalService

--

*`windows.service.path_name`*::
+
--
Fully qualified path to the file that implements the service, including arguments.


type: keyword

example: C:\WINDOWS\system32\svchost.exe -k LocalService -p

--

*`windows.service.state`*::
+
--
The actual state of the service. The possible values are `Continuing`, `Pausing`, `Paused`, `Running`, `Starting`, `Stopping`, and `Stopped`.


type: keyword

--

*`windows.service.exit_code`*::
+
--
For `Stopped` services this is the error code that service reports when starting to stopping. This will be the generic Windows service error code unless the service provides a service-specific error code.


type: keyword

--

*`windows.service.pid`*::
+
--
For `Running` services this is the associated process PID.


type: long

example: 1092

--

*`windows.service.uptime.ms`*::
+
--
The service's uptime specified in milliseconds.


type: long

format: duration

--

[[exported-fields-zookeeper]]
== ZooKeeper fields

ZooKeeper metrics collected by the four-letter monitoring commands.



[float]
=== zookeeper

`zookeeper` contains the metrics reported by ZooKeeper commands.



[float]
=== connection

connections



*`zookeeper.connection.interest_ops`*::
+
--
Interest ops


type: long

--

*`zookeeper.connection.queued`*::
+
--
Queued connections


type: long

--

*`zookeeper.connection.received`*::
+
--
Received connections


type: long

--

*`zookeeper.connection.sent`*::
+
--
Connections sent


type: long

--

[float]
=== mntr

`mntr` contains the metrics reported by the four-letter `mntr` command.



*`zookeeper.mntr.hostname`*::
+
--
ZooKeeper hostname.


type: keyword

--

*`zookeeper.mntr.approximate_data_size`*::
+
--
Approximate size of ZooKeeper data.


type: long

--

*`zookeeper.mntr.latency.avg`*::
+
--
Average latency between ensemble hosts in milliseconds.


type: long

--

*`zookeeper.mntr.ephemerals_count`*::
+
--
Number of ephemeral znodes.


type: long

--

*`zookeeper.mntr.followers`*::
+
--
Number of followers seen by the current host.


type: long

--

*`zookeeper.mntr.max_file_descriptor_count`*::
+
--
Maximum number of file descriptors allowed for the ZooKeeper process.


type: long

--

*`zookeeper.mntr.latency.max`*::
+
--
Maximum latency in milliseconds.


type: long

--

*`zookeeper.mntr.latency.min`*::
+
--
Minimum latency in milliseconds.


type: long

--

*`zookeeper.mntr.num_alive_connections`*::
+
--
Number of connections to ZooKeeper that are currently alive.


type: long

--

*`zookeeper.mntr.open_file_descriptor_count`*::
+
--
Number of file descriptors open by the ZooKeeper process.


type: long

--

*`zookeeper.mntr.outstanding_requests`*::
+
--
Number of outstanding requests that need to be processed by the cluster.


type: long

--

*`zookeeper.mntr.packets.received`*::
+
--
Number of ZooKeeper network packets received.


type: long

--

*`zookeeper.mntr.packets.sent`*::
+
--
Number of ZooKeeper network packets sent.


type: long

--

*`zookeeper.mntr.pending_syncs`*::
+
--
Number of pending syncs to carry out to ZooKeeper ensemble followers.


type: long

--

*`zookeeper.mntr.server_state`*::
+
--
Role in the ZooKeeper ensemble.


type: keyword

--

*`zookeeper.mntr.synced_followers`*::
+
--
Number of synced followers reported when a node server_state is leader.


type: long

--

*`zookeeper.mntr.version`*::
+
--
ZooKeeper version and build string reported.


type: alias

alias to: service.version

--

*`zookeeper.mntr.watch_count`*::
+
--
Number of watches currently set on the local ZooKeeper process.


type: long

--

*`zookeeper.mntr.znode_count`*::
+
--
Number of znodes reported by the local ZooKeeper process.


type: long

--

[float]
=== server

server contains the metrics reported by the four-letter `srvr` command.


*`zookeeper.server.connections`*::
+
--
Number of clients currently connected to the server

type: long

--


*`zookeeper.server.latency.avg`*::
+
--
Average amount of time taken for the server to respond to a client request

type: long

--

*`zookeeper.server.latency.max`*::
+
--
Maximum amount of time taken for the server to respond to a client request

type: long

--

*`zookeeper.server.latency.min`*::
+
--
Minimum amount of time taken for the server to respond to a client request

type: long

--

*`zookeeper.server.mode`*::
+
--
Mode of the server. In an ensemble, this may either be leader or follower. Otherwise, it is standalone

type: keyword

--

*`zookeeper.server.node_count`*::
+
--
Total number of nodes

type: long

--

*`zookeeper.server.outstanding`*::
+
--
Number of requests queued at the server. This exceeds zero when the server receives more requests than it is able to process

type: long

--

*`zookeeper.server.received`*::
+
--
Number of requests received by the server

type: long

--

*`zookeeper.server.sent`*::
+
--
Number of requests sent by the server

type: long

--

*`zookeeper.server.version_date`*::
+
--
Date of the Zookeeper release currently in use

type: date

--

*`zookeeper.server.zxid`*::
+
--
Unique value of the Zookeeper transaction ID. The zxid consists of an epoch and a counter. It is established by the leader and is used to determine the temporal ordering of changes

type: keyword

--

*`zookeeper.server.count`*::
+
--
Total transactions of the leader in epoch

type: long

--

*`zookeeper.server.epoch`*::
+
--
Epoch value of the Zookeeper transaction ID. An epoch signifies the period in which a server is a leader

type: long

--

